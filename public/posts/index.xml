<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
	<channel>
		<title>Posts on Bruce&#39;s Blog</title>
		<link>http://www.heyuan110.com/posts/</link>
		<description>Recent content in Posts on Bruce&#39;s Blog</description>
		<generator>Hugo -- gohugo.io</generator>
		<language>zh-hans</language>
		<copyright>This work is licensed under a Creative Commons Attribution-NonCommercial 4.0 International License.</copyright>
		<lastBuildDate>Thu, 11 May 2023 21:21:55 +0800</lastBuildDate>
		<atom:link href="http://www.heyuan110.com/posts/index.xml" rel="self" type="application/rss+xml" />
		
		<item>
			<title>Test</title>
			<link>http://www.heyuan110.com/posts/test/</link>
			<pubDate>Thu, 11 May 2023 21:21:55 +0800</pubDate>
			
			<guid>http://www.heyuan110.com/posts/test/</guid>
			<description>welcome to my blog</description>
			<content type="html"><![CDATA[<p>welcome to my blog</p>
]]></content>
		</item>
		
		<item>
			<title>AWS CLI常用命令</title>
			<link>http://www.heyuan110.com/posts/linux/2020-07-04-aws-cli/</link>
			<pubDate>Sat, 04 Jul 2020 00:16:54 +0000</pubDate>
			
			<guid>http://www.heyuan110.com/posts/linux/2020-07-04-aws-cli/</guid>
			<description>AWS CLI常用命令
S3 官方参考https://docs.amazonaws.cn/cli/latest/userguide/cli-services-s3-commands.html
##查看默认的bucket aws s3 ls ##查看默认环境的abert-test内容 aws s3 ls s3://abert-test ##查看目录大小,列出每个文件大小 aws s3 ls --summarize --human-readable --recursive s3://bucket-name ##上传本地文件 aws s3 cp bstest.txt s3://abert-test ##复制文件 aws s3 cp s3://mybucket/test.txt s3://mybucket/test2.txt ##递归拷贝 aws s3 cp s3://mybucket . --recursive ##排除拷贝 aws s3 cp myDir s3://mybucket/ --recursive --exclude &amp;#34;*.jpg&amp;#34; ##拷贝并添加ACL权限控制 aws s3 cp s3://mybucket/test.txt s3://mybucket/test2.txt --acl public-read-write ## 移动 ## 将桶testbucket下面所有文件移动到testbucket2 aws s3 mv s3://testbucket/ s3//testbucket2/ --recursive #rm ##删除对象 aws s3 rm s3://mybucket/test.</description>
			<content type="html"><![CDATA[<p>AWS CLI常用命令</p>
<h2 id="s3">S3</h2>
<p>官方参考<a href="https://docs.amazonaws.cn/cli/latest/userguide/cli-services-s3-commands.html">https://docs.amazonaws.cn/cli/latest/userguide/cli-services-s3-commands.html</a></p>
<pre tabindex="0"><code>##查看默认的bucket
aws s3 ls

##查看默认环境的abert-test内容
aws s3 ls s3://abert-test

##查看目录大小,列出每个文件大小
aws s3 ls --summarize --human-readable --recursive s3://bucket-name 
 
##上传本地文件
aws s3 cp bstest.txt s3://abert-test 

##复制文件
aws s3 cp s3://mybucket/test.txt s3://mybucket/test2.txt 

##递归拷贝
aws s3 cp s3://mybucket . --recursive 

##排除拷贝
aws s3 cp myDir s3://mybucket/ --recursive --exclude &#34;*.jpg&#34;  

##拷贝并添加ACL权限控制
aws s3 cp s3://mybucket/test.txt s3://mybucket/test2.txt --acl public-read-write
 
## 移动
## 将桶testbucket下面所有文件移动到testbucket2
aws s3 mv s3://testbucket/ s3//testbucket2/ --recursive
 
#rm 
##删除对象
aws s3 rm  s3://mybucket/test.txt
 
#mb 
##创建bucket
aws s3 mb s3://newbucket
 
#rb
##删除bucket：
aws s3 rb s3://bucket-name

##删除非空：
aws s3 rb s3://bucket-name --force
</code></pre><h2 id="kinesis">Kinesis</h2>
<pre tabindex="0"><code>
##放入数据
aws kinesis put-record --stream-name Betty_Stream --partition-key 123 --data testdata
##读取数据
aws kinesis get-shard-iterator --shard-id shardId-000000000000 --shard-iterator-type TRIM_HORIZON --stream-name Betty_Stream
</code></pre><h2 id="sqs">SQS</h2>
<pre tabindex="0"><code>##读取消息
aws sqs receive-message --queue-url https://sqs.us-east-1.amazonaws.com/123456780123/MY_SQS_TEST --attribute-names All --message-attribute-names All --max-number-of-messages 1
 
##删除消息
aws sqs delete-message --queue-url https://sqs.us-east-1.amazonaws.com/123456780123/MY_SQS_TEST --receipt-handle
</code></pre><h2 id="sns">SNS</h2>
<pre tabindex="0"><code>##查看所有的IOS push
aws sns list-platform-applications 
</code></pre><h2 id="参考">参考</h2>
<p><a href="https://blog.csdn.net/zhuzixiangshui/article/details/102834366">1. AWS CLI常用命令记录</a></p>
]]></content>
		</item>
		
		<item>
			<title>Nginx报No route to host错误</title>
			<link>http://www.heyuan110.com/posts/linux/nginx/nginx-error-noroutetohost/</link>
			<pubDate>Fri, 03 Jul 2020 13:19:44 +0800</pubDate>
			
			<guid>http://www.heyuan110.com/posts/linux/nginx/nginx-error-noroutetohost/</guid>
			<description>最近调整了后端站点架构为：user-------&amp;gt;nginx proxy server--------》internal host ------(cname)----》elb host，跑一段时间后经常出现诡异的情况，访问时不时会挂掉，只要重启nginx proxy集群里所有机器的nginx就能恢复， 经过检查发现集群里部分机器往后转发时报如下错误:
2020/06/08 16:31:20 [error] 13741#0: *116374839 connect() failed (113: No route to host) while connecting to upstream, client: 2607:xxxx:969:f1f0:c3d:70ec:178f:fd24, server: localhost, request: &amp;#34;POST /v1.4/source HTTP/1.1&amp;#34;, upstream: &amp;#34;http://172.31.xx.xx:80/v1.4/source&amp;#34;, host: &amp;#34;api.xxxx.com&amp;#34; 网上搜索找到的资料都讲防火墙原因，经过仔细排查排除了。通过仔细分析出现异常时的监控发现，在异常时间点aws elb的ip发生了变化，于是将症状和云服务的SA沟通，他说AWS ELB的IP是会变化的（之前以为是固定的）， 建议nginx上的upstream需要动态去刷新，并建议使用nginx的jdomain模块来做动态解析，参考地址https://www.nginx.com/resources/wiki/modules/domain_resolve/，我们加上这个模块后重新部署nginx问题就没再出现。
其实原因很简单，nginx proxy指向域名时，nginx会缓存域名解析到的ip，如果域名对应的ip改变了而proxy nginx又没刷新缓存的ip，后面流量继续往旧ip转发，就会报错了，增加的动态解析模块指定dns和时间间隔去获取最新的ip并更新到缓存里，这样就保证了域名指向的ip变更proxy nginx能及时更新缓存ip。</description>
			<content type="html"><![CDATA[<p>最近调整了后端站点架构为：<code>user-------&gt;nginx proxy server--------》internal host ------(cname)----》elb host</code>，跑一段时间后经常出现诡异的情况，访问时不时会挂掉，只要重启nginx proxy集群里所有机器的nginx就能恢复，
经过检查发现集群里部分机器往后转发时报如下错误:</p>
<pre tabindex="0"><code> 2020/06/08 16:31:20 [error] 13741#0: *116374839 connect() failed (113: No route to host) while connecting to upstream, client: 2607:xxxx:969:f1f0:c3d:70ec:178f:fd24, server: localhost, request: &#34;POST /v1.4/source HTTP/1.1&#34;, upstream: &#34;http://172.31.xx.xx:80/v1.4/source&#34;, host: &#34;api.xxxx.com&#34;
</code></pre><p>网上搜索找到的资料都讲防火墙原因，经过仔细排查排除了。通过仔细分析出现异常时的监控发现，在异常时间点aws elb的ip发生了变化，于是将症状和云服务的SA沟通，他说AWS ELB的IP是会变化的（之前以为是固定的），
建议nginx上的upstream需要动态去刷新，并建议使用nginx的jdomain模块来做动态解析，参考地址<a href="https://www.nginx.com/resources/wiki/modules/domain_resolve/">https://www.nginx.com/resources/wiki/modules/domain_resolve/</a>，我们加上这个模块后重新部署nginx问题就没再出现。</p>
<p>其实原因很简单，nginx proxy指向域名时，nginx会缓存域名解析到的ip，如果域名对应的ip改变了而proxy nginx又没刷新缓存的ip，后面流量继续往旧ip转发，就会报错了，增加的动态解析模块指定dns和时间间隔去获取最新的ip并更新到缓存里，这样就保证了域名指向的ip变更proxy nginx能及时更新缓存ip。</p>
]]></content>
		</item>
		
		<item>
			<title>Curl命令</title>
			<link>http://www.heyuan110.com/posts/linux/2020-06-29-curl/</link>
			<pubDate>Mon, 29 Jun 2020 20:36:04 +0000</pubDate>
			
			<guid>http://www.heyuan110.com/posts/linux/2020-06-29-curl/</guid>
			<description>curl是linux下必备神器，例如：
指定IP访问URL，HTTP和HTTPS的区别：
curl -vosa &amp;quot;http://hikpai.hikvision.com/dashboard/workplace&amp;quot; -x 125.77.145.14:80
curl -vosa &amp;quot;https://125.77.145.14/dashboard/workplace&amp;quot; -H &amp;quot;host:hikpai.hikvision.com&amp;quot; -k
curl -vo /dev/null &amp;quot;https://125.77.145.14/dashboard/workplace&amp;quot; -H &amp;quot;host:hikpai.hikvision.com&amp;quot; -k
在以下选项中，(H) 表示仅适用 HTTP/HTTPS ，(F) 表示仅适用于 FTP
更多相关参数解释：
--anyauth 选择 &amp;#34;any&amp;#34; 认证方法 (H) -a, --append 添加要上传的文件 (F/SFTP) --basic 使用HTTP基础认证（Basic Authentication）(H) --cacert FILE CA 证书，用于每次请求认证 (SSL) --capath DIR CA 证书目录 (SSL) -E, --cert CERT[:PASSWD] 客户端证书文件及密码 (SSL) --cert-type TYPE 证书文件类型 (DER/PEM/ENG) (SSL) --ciphers LIST SSL 秘钥 (SSL) --compressed 请求压缩 (使用 deflate 或 gzip) -K, --config FILE 指定配置文件 --connect-timeout SECONDS 连接超时设置 -C, --continue-at OFFSET 断点续转 -b, --cookie STRING/FILE Cookies字符串或读取Cookies的文件位置 (H) -c, --cookie-jar FILE 操作结束后，要写入 Cookies 的文件位置 (H) --create-dirs 创建必要的本地目录层次结构 --crlf 在上传时将 LF 转写为 CRLF --crlfile FILE 从指定的文件获得PEM格式CRL列表 -d, --data DATA HTTP POST 数据 (H) --data-ascii DATA ASCII 编码 HTTP POST 数据 (H) --data-binary DATA binary 编码 HTTP POST 数据 (H) --data-urlencode DATA url 编码 HTTP POST 数据 (H) --delegation STRING GSS-API 委托权限 --digest 使用数字身份验证 (H) --disable-eprt 禁止使用 EPRT 或 LPRT (F) --disable-epsv 禁止使用 EPSV (F) -D, --dump-header FILE 将头信息写入指定的文件 --egd-file FILE 为随机数据设置EGD socket路径(SSL) --engine ENGINGE 加密引擎 (SSL).</description>
			<content type="html"><![CDATA[<p>curl是linux下必备神器，例如：</p>
<p>指定IP访问URL，HTTP和HTTPS的区别：</p>
<p><code>curl -vosa &quot;http://hikpai.hikvision.com/dashboard/workplace&quot; -x 125.77.145.14:80</code></p>
<p><code>curl -vosa &quot;https://125.77.145.14/dashboard/workplace&quot; -H &quot;host:hikpai.hikvision.com&quot; -k</code></p>
<p><code>curl -vo /dev/null &quot;https://125.77.145.14/dashboard/workplace&quot; -H &quot;host:hikpai.hikvision.com&quot; -k</code></p>
<p>在以下选项中，(H) 表示仅适用 HTTP/HTTPS ，(F) 表示仅适用于 FTP</p>
<p>更多相关参数解释：</p>
<pre tabindex="0"><code>    --anyauth       选择 &#34;any&#34; 认证方法 (H)
-a, --append        添加要上传的文件 (F/SFTP)
    --basic         使用HTTP基础认证（Basic Authentication）(H)
    --cacert FILE   CA 证书，用于每次请求认证 (SSL)
    --capath DIR    CA 证书目录 (SSL)
-E, --cert CERT[:PASSWD] 客户端证书文件及密码 (SSL)
    --cert-type TYPE 证书文件类型 (DER/PEM/ENG) (SSL)
    --ciphers LIST  SSL 秘钥 (SSL)
    --compressed    请求压缩 (使用 deflate 或 gzip)
-K, --config FILE   指定配置文件
    --connect-timeout SECONDS  连接超时设置
-C, --continue-at OFFSET  断点续转
-b, --cookie STRING/FILE  Cookies字符串或读取Cookies的文件位置 (H)
-c, --cookie-jar FILE  操作结束后，要写入 Cookies 的文件位置 (H)
    --create-dirs   创建必要的本地目录层次结构
    --crlf          在上传时将 LF 转写为 CRLF
    --crlfile FILE  从指定的文件获得PEM格式CRL列表
-d, --data DATA     HTTP POST 数据 (H)
    --data-ascii DATA  ASCII 编码 HTTP POST 数据 (H)
    --data-binary DATA  binary 编码 HTTP POST 数据 (H)
    --data-urlencode DATA  url 编码 HTTP POST 数据 (H)
    --delegation STRING GSS-API 委托权限
    --digest        使用数字身份验证 (H)
    --disable-eprt  禁止使用 EPRT 或 LPRT (F)
    --disable-epsv  禁止使用 EPSV (F)
-D, --dump-header FILE  将头信息写入指定的文件
    --egd-file FILE  为随机数据设置EGD socket路径(SSL)
    --engine ENGINGE  加密引擎 (SSL). &#34;--engine list&#34; 指定列表
-f, --fail          连接失败时不显示HTTP错误信息 (H)
-F, --form CONTENT  模拟 HTTP 表单数据提交（multipart POST） (H)
    --form-string STRING  模拟 HTTP 表单数据提交 (H)
    --ftp-account DATA  帐户数据提交 (F)
    --ftp-alternative-to-user COMMAND  指定替换 &#34;USER [name]&#34; 的字符串 (F)
    --ftp-create-dirs  如果不存在则创建远程目录 (F)
    --ftp-method [MULTICWD/NOCWD/SINGLECWD] 控制 CWD (F)
    --ftp-pasv      使用 PASV/EPSV 替换 PORT (F)
-P, --ftp-port ADR  使用指定 PORT 及地址替换 PASV (F)
    --ftp-skip-pasv-ip 跳过 PASV 的IP地址 (F)
    --ftp-pret      在 PASV 之前发送 PRET (drftpd) (F)
    --ftp-ssl-ccc   在认证之后发送 CCC (F)
    --ftp-ssl-ccc-mode ACTIVE/PASSIVE  设置 CCC 模式 (F)
    --ftp-ssl-control ftp 登录时需要 SSL/TLS (F)
-G, --get           使用 HTTP GET 方法发送 -d 数据  (H)
-g, --globoff       禁用的 URL 队列 及范围使用 {} 和 []
-H, --header LINE   要发送到服务端的自定义请求头 (H)
-I, --head          仅显示响应文档头
-h, --help          显示帮助
-0, --http1.0       使用 HTTP 1.0 (H)
    --ignore-content-length  忽略 HTTP Content-Length 头
-i, --include       在输出中包含协议头 (H/F)
-k, --insecure      允许连接到 SSL 站点，而不使用证书 (H)
    --interface INTERFACE  指定网络接口／地址
-4, --ipv4          将域名解析为 IPv4 地址
-6, --ipv6          将域名解析为 IPv6 地址
-j, --junk-session-cookies 读取文件中但忽略会话cookie (H)
    --keepalive-time SECONDS  keepalive 包间隔
    --key KEY       私钥文件名 (SSL/SSH)
    --key-type TYPE 私钥文件类型 (DER/PEM/ENG) (SSL)
    --krb LEVEL     启用指定安全级别的 Kerberos (F)
    --libcurl FILE  命令的libcurl等价代码
    --limit-rate RATE  限制传输速度
-l, --list-only    只列出FTP目录的名称 (F)
    --local-port RANGE  强制使用的本地端口号
-L, --location      跟踪重定向 (H)
    --location-trusted 类似 --location 并发送验证信息到其它主机 (H)
-M, --manual        显示全手动
    --mail-from FROM  从这个地址发送邮件
    --mail-rcpt TO  发送邮件到这个接收人(s)
    --mail-auth AUTH  原始电子邮件的起始地址
    --max-filesize BYTES  下载的最大文件大小 (H/F)
    --max-redirs NUM  最大重定向数 (H)
-m, --max-time SECONDS  允许的最多传输时间
    --metalink      处理指定的URL上的XML文件
    --negotiate     使用 HTTP Negotiate 认证 (H)
-n, --netrc         必须从 .netrc 文件读取用户名和密码
    --netrc-optional 使用 .netrc 或 URL; 将重写 -n 参数
    --netrc-file FILE  设置要使用的 netrc 文件名
-N, --no-buffer     禁用输出流的缓存
    --no-keepalive  禁用 connection 的 keepalive
    --no-sessionid  禁止重复使用 SSL session-ID (SSL)
    --noproxy       不使用代理的主机列表
    --ntlm          使用 HTTP NTLM 认证 (H)
-o, --output FILE   将输出写入文件，而非 stdout
    --pass PASS     传递给私钥的短语 (SSL/SSH)
    --post301       在 301 重定向后不要切换为 GET 请求 (H)
    --post302       在 302 重定向后不要切换为 GET 请求 (H)
    --post303       在 303 重定向后不要切换为 GET 请求 (H)
-#, --progress-bar  以进度条显示传输进度
    --proto PROTOCOLS  启用/禁用 指定的协议
    --proto-redir PROTOCOLS  在重定向上 启用/禁用 指定的协议
-x, --proxy [PROTOCOL://]HOST[:PORT] 在指定的端口上使用代理
    --proxy-anyauth 在代理上使用 &#34;any&#34; 认证方法 (H)
    --proxy-basic   在代理上使用 Basic 认证  (H)
    --proxy-digest  在代理上使用 Digest 认证 (H)
    --proxy-negotiate 在代理上使用 Negotiate 认证 (H)
    --proxy-ntlm    在代理上使用 NTLM 认证 (H)
-U, --proxy-user USER[:PASSWORD]  代理用户名及密码
     --proxy1.0 HOST[:PORT]  在指定的端口上使用 HTTP/1.0 代理
-p, --proxytunnel   使用HTTP代理 (用于 CONNECT)
    --pubkey KEY    公钥文件名 (SSH)
-Q, --quote CMD     在传输开始前向服务器发送命令 (F/SFTP)
    --random-file FILE  读取随机数据的文件 (SSL)
-r, --range RANGE   仅检索范围内的字节
    --raw           使用原始HTTP传输，而不使用编码 (H)
-e, --referer       Referer URL (H)
-J, --remote-header-name 从远程文件读取头信息 (H)
-O, --remote-name   将输出写入远程文件
    --remote-name-all 使用所有URL的远程文件名
-R, --remote-time   将远程文件的时间设置在本地输出上
-X, --request COMMAND  使用指定的请求命令
    --resolve HOST:PORT:ADDRESS  将 HOST:PORT 强制解析到 ADDRESS
    --retry NUM   出现问题时的重试次数
    --retry-delay SECONDS 重试时的延时时长
    --retry-max-time SECONDS  仅在指定时间段内重试
-S, --show-error    显示错误. 在选项 -s 中，当 curl 出现错误时将显示
-s, --silent        Silent模式。不输出任务内容
    --socks4 HOST[:PORT]  在指定的 host + port 上使用 SOCKS4 代理
    --socks4a HOST[:PORT]  在指定的 host + port 上使用 SOCKSa 代理
    --socks5 HOST[:PORT]  在指定的 host + port 上使用 SOCKS5 代理
    --socks5-hostname HOST[:PORT] SOCKS5 代理，指定用户名、密码
    --socks5-gssapi-service NAME  为gssapi使用SOCKS5代理服务名称
    --socks5-gssapi-nec  与NEC Socks5服务器兼容
-Y, --speed-limit RATE  在指定限速时间之后停止传输
-y, --speed-time SECONDS  指定时间之后触发限速. 默认 30
    --ssl           尝试 SSL/TLS (FTP, IMAP, POP3, SMTP)
    --ssl-reqd      需要 SSL/TLS (FTP, IMAP, POP3, SMTP)
-2, --sslv2         使用 SSLv2 (SSL)
-3, --sslv3         使用 SSLv3 (SSL)
    --ssl-allow-beast 允许的安全漏洞，提高互操作性(SSL)
    --stderr FILE   重定向 stderr 的文件位置. - means stdout
    --tcp-nodelay   使用 TCP_NODELAY 选项
-t, --telnet-option OPT=VAL  设置 telnet 选项
     --tftp-blksize VALUE  设备 TFTP BLKSIZE 选项 (必须 &gt;512)
-z, --time-cond TIME  基于时间条件的传输
-1, --tlsv1         使用 =&gt; TLSv1 (SSL)
    --tlsv1.0       使用 TLSv1.0 (SSL)
    --tlsv1.1       使用 TLSv1.1 (SSL)
    --tlsv1.2       使用 TLSv1.2 (SSL)
    --trace FILE    将 debug 信息写入指定的文件
    --trace-ascii FILE  类似 --trace 但使用16进度输出
    --trace-time    向 trace/verbose 输出添加时间戳
    --tr-encoding   请求压缩传输编码 (H)
-T, --upload-file FILE  将文件传输（上传）到指定位置
    --url URL       指定所使用的 URL
-B, --use-ascii     使用 ASCII/text 传输
-u, --user USER[:PASSWORD]  指定服务器认证用户名、密码
    --tlsuser USER  TLS 用户名
    --tlspassword STRING TLS 密码
    --tlsauthtype STRING  TLS 认证类型 (默认 SRP)
    --unix-socket FILE    通过这个 UNIX socket 域连接
-A, --user-agent STRING  要发送到服务器的 User-Agent (H)
-v, --verbose       显示详细操作信息
-V, --version       显示版本号并退出
-w, --write-out FORMAT  完成后输出什么
    --xattr        将元数据存储在扩展文件属性中
-q                 .curlrc 如果作为第一个参数无效
</code></pre>]]></content>
		</item>
		
		<item>
			<title>Traceroute命令</title>
			<link>http://www.heyuan110.com/posts/linux/2020-06-28-traceroute/</link>
			<pubDate>Sun, 28 Jun 2020 12:12:04 +0000</pubDate>
			
			<guid>http://www.heyuan110.com/posts/linux/2020-06-28-traceroute/</guid>
			<description>1. 简介 通过traceroute我们可以知道信息从你的计算机到互联网另一端的主机是走的什么路径。当然每次数据包由某一同样的出发点（source）到达某一同样的目的地(destination)走的路径可能会不一样，但基本上来说大部分时候所走的路由是相同的。linux系统中，我们称之为traceroute,在MS Windows中为tracert。 traceroute通过发送小的数据包到目的设备直到其返回，来测量其需要多长时间。一条路径上的每个设备traceroute要测3次。输出结果中包括每次测试的时间(ms)和设备的名称（如有的话）及其IP地址。
在大多数情况下，我们会在linux主机系统下，直接执行命令行：
traceroute hostname
而在Windows系统下是执行tracert的命令：
tracert hostname
2. 命令格式 traceroute[参数][主机]
3. 命令功能 traceroute指令让你追踪网络数据包的路由途径，预设数据包大小是40Bytes，用户可另行设置。
具体参数格式：traceroute [-dFlnrvx][-f&amp;lt;存活数值&amp;gt;][-g&amp;lt;网关&amp;gt;&amp;hellip;][-i&amp;lt;网络界面&amp;gt;][-m&amp;lt;存活数值&amp;gt;][-p&amp;lt;通信端口&amp;gt;][-s&amp;lt;来源地址&amp;gt;][-t&amp;lt;服务类型&amp;gt;][-w&amp;lt;超时秒数&amp;gt;][主机名称或IP地址][数据包大小]
4. 命令参数 -d 使用Socket层级的排错功能。
-f 设置第一个检测数据包的存活数值TTL的大小。
-F 设置勿离断位。
-g 设置来源路由网关，最多可设置8个。
-i 使用指定的网络界面送出数据包。
-I 使用ICMP回应取代UDP资料信息。
-m 设置检测数据包的最大存活数值TTL的大小。
-n 直接使用IP地址而非主机名称。
-p 设置UDP传输协议的通信端口。
-r 忽略普通的Routing Table，直接将数据包送到远端主机上。
-s 设置本地主机送出数据包的IP地址。
-t 设置检测数据包的TOS数值。
-v 详细显示指令的执行过程。
-w 设置等待远端主机回报的时间。
-x 开启或关闭数据包的正确性检验。
5. 工作原理 Traceroute最简单的基本用法是：traceroute hostname
Traceroute程序的设计是利用ICMP及IP header的TTL（Time To Live）栏位（field）。首先，traceroute送出一个TTL是1的IP datagram（其实，每次送出的为3个40字节的包，包括源地址，目的地址和包发出的时间标签）到目的地，当路径上的第一个路由器（router）收到这个datagram时，它将TTL减1。此时，TTL变为0了，所以该路由器会将此datagram丢掉，并送回一个「ICMP time exceeded」消息（包括发IP包的源地址，IP包的所有内容及路由器的IP地址），traceroute 收到这个消息后，便知道这个路由器存在于这个路径上，接着traceroute 再送出另一个TTL是2 的datagram，发现第2 个路由器&amp;hellip;&amp;hellip; traceroute 每次将送出的datagram的TTL 加1来发现另一个路由器，这个重复的动作一直持续到某个datagram 抵达目的地。当datagram到达目的地后，该主机并不会送回ICMP time exceeded消息，因为它已是目的地了，那么traceroute如何得知目的地到达了呢？</description>
			<content type="html"><![CDATA[<h2 id="1-简介">1. 简介</h2>
<p>通过traceroute我们可以知道信息从你的计算机到互联网另一端的主机是走的什么路径。当然每次数据包由某一同样的出发点（source）到达某一同样的目的地(destination)走的路径可能会不一样，但基本上来说大部分时候所走的路由是相同的。linux系统中，我们称之为traceroute,在MS Windows中为tracert。 traceroute通过发送小的数据包到目的设备直到其返回，来测量其需要多长时间。一条路径上的每个设备traceroute要测3次。输出结果中包括每次测试的时间(ms)和设备的名称（如有的话）及其IP地址。</p>
<p>在大多数情况下，我们会在linux主机系统下，直接执行命令行：</p>
<p><code>traceroute hostname</code></p>
<p>而在Windows系统下是执行tracert的命令：</p>
<p><code>tracert hostname</code></p>
<h2 id="2-命令格式">2. 命令格式</h2>
<p>traceroute[参数][主机]</p>
<h2 id="3-命令功能">3. 命令功能</h2>
<p>traceroute指令让你追踪网络数据包的路由途径，预设数据包大小是40Bytes，用户可另行设置。</p>
<p>具体参数格式：traceroute [-dFlnrvx][-f&lt;存活数值&gt;][-g&lt;网关&gt;&hellip;][-i&lt;网络界面&gt;][-m&lt;存活数值&gt;][-p&lt;通信端口&gt;][-s&lt;来源地址&gt;][-t&lt;服务类型&gt;][-w&lt;超时秒数&gt;][主机名称或IP地址][数据包大小]</p>
<h2 id="4-命令参数">4. 命令参数</h2>
<p>-d 使用Socket层级的排错功能。</p>
<p>-f 设置第一个检测数据包的存活数值TTL的大小。</p>
<p>-F 设置勿离断位。</p>
<p>-g 设置来源路由网关，最多可设置8个。</p>
<p>-i 使用指定的网络界面送出数据包。</p>
<p>-I 使用ICMP回应取代UDP资料信息。</p>
<p>-m 设置检测数据包的最大存活数值TTL的大小。</p>
<p>-n 直接使用IP地址而非主机名称。</p>
<p>-p 设置UDP传输协议的通信端口。</p>
<p>-r 忽略普通的Routing Table，直接将数据包送到远端主机上。</p>
<p>-s 设置本地主机送出数据包的IP地址。</p>
<p>-t 设置检测数据包的TOS数值。</p>
<p>-v 详细显示指令的执行过程。</p>
<p>-w 设置等待远端主机回报的时间。</p>
<p>-x 开启或关闭数据包的正确性检验。</p>
<h2 id="5-工作原理">5. 工作原理</h2>
<p>Traceroute最简单的基本用法是：traceroute hostname</p>
<p>Traceroute程序的设计是利用ICMP及IP header的TTL（Time To Live）栏位（field）。首先，traceroute送出一个TTL是1的IP datagram（其实，每次送出的为3个40字节的包，包括源地址，目的地址和包发出的时间标签）到目的地，当路径上的第一个路由器（router）收到这个datagram时，它将TTL减1。此时，TTL变为0了，所以该路由器会将此datagram丢掉，并送回一个「ICMP time exceeded」消息（包括发IP包的源地址，IP包的所有内容及路由器的IP地址），traceroute 收到这个消息后，便知道这个路由器存在于这个路径上，接着traceroute 再送出另一个TTL是2 的datagram，发现第2 个路由器&hellip;&hellip; traceroute 每次将送出的datagram的TTL 加1来发现另一个路由器，这个重复的动作一直持续到某个datagram 抵达目的地。当datagram到达目的地后，该主机并不会送回ICMP time exceeded消息，因为它已是目的地了，那么traceroute如何得知目的地到达了呢？</p>
<p>Traceroute在送出UDP datagrams到目的地时，它所选择送达的port number 是一个一般应用程序都不会用的号码（30000 以上），所以当此UDP datagram 到达目的地后该主机会送回一个「ICMP port unreachable」的消息，而当traceroute 收到这个消息时，便知道目的地已经到达了。所以traceroute 在Server端也是没有所谓的Daemon 程式。</p>
<p>Traceroute提取发 ICMP TTL到期消息设备的IP地址并作域名解析。每次 ，Traceroute都打印出一系列数据,包括所经过的路由设备的域名及 IP地址,三个包每次来回所花时间。</p>
<h2 id="6-例子">6. 例子</h2>
<ul>
<li>例子1：<code>traceroute www.baidu.com</code></li>
</ul>
<pre tabindex="0"><code>[root@localhost ~]# traceroute www.baidu.com
traceroute to www.baidu.com (61.135.169.125), 30 hops max, 40 byte packets
 1  192.168.74.2 (192.168.74.2)  2.606 ms  2.771 ms  2.950 ms
 2  211.151.56.57 (211.151.56.57)  0.596 ms  0.598 ms  0.591 ms
 3  211.151.227.206 (211.151.227.206)  0.546 ms  0.544 ms  0.538 ms
 4  210.77.139.145 (210.77.139.145)  0.710 ms  0.748 ms  0.801 ms
 5  202.106.42.101 (202.106.42.101)  6.759 ms  6.945 ms  7.107 ms
 6  61.148.154.97 (61.148.154.97)  718.908 ms * bt-228-025.bta.net.cn (202.106.228.25)  5.177 ms
 7  124.65.58.213 (124.65.58.213)  4.343 ms  4.336 ms  4.367 ms
 8  202.106.35.190 (202.106.35.190)  1.795 ms 61.148.156.138 (61.148.156.138)  1.899 ms  1.951 ms
 9  * * *
30  * * *
[root@localhost ~]# 
</code></pre><p>记录按序列号从1开始，每个纪录就是一跳 ，每跳表示一个网关，我们看到每行有三个时间，单位是 ms，其实就是-q的默认参数。探测数据包向每个网关发送三个数据包后，网关响应后返回的时间；如果您用 traceroute -q 4 <a href="https://www.58.com">www.58.com</a> ，表示向每个网关发送4个数据包。</p>
<p>有时我们traceroute 一台主机时，会看到有一些行是以星号表示的。出现这样的情况，可能是防火墙封掉了ICMP的返回信息，所以我们得不到什么相关的数据包返回数据。</p>
<p>有时我们在某一网关处延时比较长，有可能是某台网关比较阻塞，也可能是物理设备本身的原因。当然如果某台DNS出现问题时，不能解析主机名、域名时，也会 有延时长的现象；您可以加-n 参数来避免DNS解析，以IP格式输出数据。</p>
<p>如果在局域网中的不同网段之间，我们可以通过traceroute 来排查问题所在，是主机的问题还是网关的问题。如果我们通过远程来访问某台服务器遇到问题时，我们用到traceroute 追踪数据包所经过的网关，提交IDC服务商，也有助于解决问题；但目前看来在国内解决这样的问题是比较困难的，就是我们发现问题所在，IDC服务商也不可能帮助我们解决。</p>
<ul>
<li>
<p>实例2：跳数设置 <code>traceroute -m 10 www.baidu.com</code></p>
</li>
<li>
<p>实例3：显示IP地址，不查主机名 <code>traceroute -n www.baidu.com</code></p>
</li>
<li>
<p>实例4：探测包使用的基本UDP端口设置6888 <code>traceroute -p 6888 www.baidu.com</code></p>
</li>
<li>
<p>实例5：把探测包的个数设置为值4 <code>traceroute -q 4 www.baidu.com</code></p>
</li>
<li>
<p>实例6：绕过正常的路由表，直接发送到网络相连的主机 <code>traceroute -r www.baidu.com</code></p>
</li>
<li>
<p>实例7：把对外发探测包的等待响应时间设置为3秒 <code>traceroute -w 3 www.baidu.com</code></p>
</li>
</ul>
<h2 id="7-windows之tracert">7. Windows之tracert:</h2>
<p>格式：</p>
<p>tracert [-d] [-h maximum_hops] [-j host-list] [-w timeout] target_name</p>
<p>参数说明：</p>
<p>tracert [-d] [-h maximum_hops] [-j computer-list] [-w timeout] target_name</p>
<p>该诊断实用程序通过向目的地发送具有不同生存时间 (TL) 的 Internet 控制信息协议 (CMP) 回应报文，以确定至目的地的路由。路径上的每个路由器都要在转发该 ICMP 回应报文之前将其 TTL 值至少减 1，因此 TTL 是有效的跳转计数。当报文的 TTL 值减少到 0 时，路由器向源系统发回 ICMP 超时信息。通过发送 TTL 为 1 的第一个回应报文并且在随后的发送中每次将 TTL 值加 1，直到目标响应或达到最大 TTL 值，Tracert 可以确定路由。通过检查中间路由器发发回的 ICMP 超时 (ime Exceeded) 信息，可以确定路由器。注意，有些路由器“安静”地丢弃生存时间 (TLS) 过期的报文并且对 tracert 无效。</p>
<p>参数：</p>
<p>-d 指定不对计算机名解析地址。</p>
<p>-h maximum_hops 指定查找目标的跳转的最大数目。</p>
<p>-jcomputer-list 指定在 computer-list 中松散源路由。</p>
<p>-w timeout 等待由 timeout 对每个应答指定的毫秒数。</p>
<p>target_name 目标计算机的名称。</p>
<p>实例：</p>
<pre tabindex="0"><code>C:\Users\Administrator&gt;tracert www.58.com

Tracing route to www.58.com [221.187.111.30]
over a maximum of 30 hops:

  1     1 ms     1 ms     1 ms  10.58.156.1
  2     1 ms    &lt;1 ms    &lt;1 ms  10.10.10.1
  3     1 ms     1 ms     1 ms  211.103.193.129
  4     2 ms     2 ms     2 ms  10.255.109.129
  5     1 ms     1 ms     3 ms  124.205.98.205
  6     2 ms     2 ms     2 ms  124.205.98.253
  7     2 ms     6 ms     1 ms  202.99.1.125
  8     5 ms     6 ms     5 ms  118.186.0.113
  9   207 ms     *        *     118.186.0.106
 10     8 ms     6 ms    11 ms  124.238.226.201
 11     6 ms     7 ms     6 ms  219.148.19.177
 12    12 ms    12 ms    16 ms  219.148.18.117
 13    14 ms    17 ms    16 ms  219.148.19.125
 14    13 ms    13 ms    12 ms  202.97.80.113
 15     *        *        *     Request timed out.
 16    12 ms    12 ms    17 ms  bj141-147-82.bjtelecom.net [219.141.147.82]
 17    13 ms    13 ms    12 ms  202.97.48.2
 18     *        *        *     Request timed out.
 19    14 ms    14 ms    12 ms  221.187.224.85
 20    15 ms    13 ms    12 ms  221.187.104.2
 21     *        *        *     Request timed out.
 22    15 ms    17 ms    18 ms  221.187.111.30

Trace complete.
</code></pre>]]></content>
		</item>
		
		<item>
			<title>Linux(MacOS)命令笔记</title>
			<link>http://www.heyuan110.com/posts/linux/2020-03-19-linux-mac-commands/</link>
			<pubDate>Thu, 19 Mar 2020 10:55:52 +0000</pubDate>
			
			<guid>http://www.heyuan110.com/posts/linux/2020-03-19-linux-mac-commands/</guid>
			<description>&lt;p&gt;linux中许多常用命令是必须掌握的，很多用过没有记录下来很快就忘记，再次使用又到处搜索，本文主要列出我日常使用过的一些命令，会持续更新。&lt;/p&gt;</description>
			<content type="html"><![CDATA[<p>linux中许多常用命令是必须掌握的，很多用过没有记录下来很快就忘记，再次使用又到处搜索，本文主要列出我日常使用过的一些命令，会持续更新。</p>
<h2 id="1-netstat命令">1. netstat命令</h2>
<p>linux：</p>
<blockquote>
<p>netstat -ntlp | grep 3000</p>
</blockquote>
<blockquote>
<p>netstat -ntlp | grep nginx</p>
</blockquote>
<p><em>Tips: 注意加<code>sudo</code>赋予权限</em></p>
<p>macos:</p>
<blockquote>
<p>netstat -an | grep 3306</p>
</blockquote>
<p>3000替换成需要grep的端口号</p>
<h2 id="2-lsof命令">2. lsof命令</h2>
<p>通过list open file命令可以查看到当前打开文件，在linux中所有事物都是以文件形式存在，包括网络连接及硬件设备。</p>
<blockquote>
<p>lsof -i:80</p>
</blockquote>
<p>-i参数表示网络链接，:80指明端口号，该命令会同时列出PID，方便kill</p>
<p>查看所有进程监听的端口</p>
<blockquote>
<p>sudo lsof -i -P | grep -i &ldquo;listen&rdquo;</p>
</blockquote>
<h2 id="3-ps--aux">3. ps -aux</h2>
<blockquote>
<p>ps -aux | grep nginx</p>
</blockquote>
<p>ps命令用于查看当前正在运行的进程
如果要终止进程:</p>
<p>{% alert info %}
kill -9 [PID]
{% endalert %}</p>
<p>-9 表示强迫进程立即停止
通常用 ps 查看进程 PID ，用 kill 命令终止进程</p>
<h2 id="4-pv">4. pv</h2>
<h3 id="41-安装">4.1 安装</h3>
<p>ubuntu:</p>
<pre tabindex="0"><code>sudo apt-get install pv
</code></pre><h3 id="42-使用">4.2 使用</h3>
<ul>
<li>拷贝 <code>pv ~/a.log &gt; ~/b.log</code></li>
<li>拷贝限制速率 <code>pv -L 2m ~/a.log &gt; ~/b.log</code></li>
<li>字符一个个匀速在命令行中显示出来 <code>echo &quot;Tecmint[dot]com is a community of Linux Nerds and Geeks&quot; | pv -qL 10</code></li>
<li>压缩文件展示进度信息<code>pv ~/a.mp4 | gzip &gt; ~/a.mp4.gz</code></li>
<li>往mysql导入表 <code>pv -i 1 -p -t -e /path/test.sql | mysql -hHOST -uUSER_NAME -p DATABASE_NAME</code></li>
</ul>
<h2 id="5mac下报app损坏不可用">5.Mac下报App损坏不可用</h2>
<p>允许任何来源的应用。在系统偏好设置里，打开“安全性和隐私”，将“允许从以下位置下载的应用程序”设置为“任何来源“。这个设置已经无法在Mac OS Sierra上完成。在Mac OS Sierra上，应该进行以下操作：</p>
<p>（1）. 开启对任何来源：<code>sudo spctl --master-disable</code></p>
<p>（2）. 移除应用的安全隔离属性 <code>sudo xattr -r -d com.apple.quarantine /Applications/xxxxx.app</code></p>
<p>（3）. 重新打开app</p>]]></content>
		</item>
		
		<item>
			<title>多版本Python环境管理-Conda</title>
			<link>http://www.heyuan110.com/posts/python/2020-01-11-python-conda/</link>
			<pubDate>Sat, 11 Jan 2020 20:33:33 +0000</pubDate>
			
			<guid>http://www.heyuan110.com/posts/python/2020-01-11-python-conda/</guid>
			<description>随着Python3被越来越多开发者接受和应用，存在着需要在python2和python3环境切换的需要，利好消息，Conda能完美解决python这个问题。
Conda是什么 Anaconda安装 </description>
			<content type="html"><![CDATA[<p>随着Python3被越来越多开发者接受和应用，存在着需要在python2和python3环境切换的需要，利好消息，Conda能完美解决python这个问题。</p>
<h1 id="conda是什么">Conda是什么</h1>
<h1 id="anaconda安装">Anaconda安装</h1>
]]></content>
		</item>
		
		<item>
			<title>Docker常用命令</title>
			<link>http://www.heyuan110.com/posts/docker/2019-11-14-docker-commands/</link>
			<pubDate>Thu, 14 Nov 2019 20:37:13 +0000</pubDate>
			
			<guid>http://www.heyuan110.com/posts/docker/2019-11-14-docker-commands/</guid>
			<description>Docker常用命令记录
1. 启动、重启或停止docker服务 启动： service docker start
停止：service docker stop
重启：service docker restart
2.镜像(images) 获取镜像 docker pull [OPTIONS] NAME[:TAG|@DIGEST]
例如：docker pull ubuntu:16.04
列出镜像 查看所有镜像: docker images或docker image ls, 显示摘要docker images --digests 查看特定镜像:docker image ls xxxx或docker image xxxx 查看镜像、容器、数据卷所占用的空间:docker system df 列出虚悬镜像（仓库名和标签名为）:docker image ls -f dangling=true,清楚此类镜像docker image prune 删除镜像 命令docker image rm [OPTIONS] IMAGE [IMAGE...] 或 docker rmi -f xxxx 例如：
root@ubuntu:~# docker image ls redis REPOSITORY TAG IMAGE ID CREATED SIZE redis latest ce25c7293564 5 days ago 95MB 根据完整ID删除：docker image rm 578c3e61a98c 根据短ID删除：docker image rm 578c3 根据镜像名删除：docker image rm redis docker image ls配合删除：删除所有镜像docker image rm $(docker image ls -q),删除所有仓库名为redis的镜像docker image rm $(docker image ls -q redis) 删除所有未打 dangling 标签的镜像docker rmi $(docker images -q -f dangling=true) docker ps -a | grep &amp;ldquo;Exited&amp;rdquo; | awk &amp;lsquo;{print $1 }&amp;rsquo;|xargs docker stop docker ps -a | grep &amp;ldquo;Exited&amp;rdquo; | awk &amp;lsquo;{print $1 }&amp;rsquo;|xargs docker rm docker images|grep none|awk &amp;lsquo;{print $3 }&amp;rsquo;|xargs docker rmi</description>
			<content type="html"><![CDATA[<p>Docker常用命令记录</p>
<!-- raw HTML omitted -->
<h2 id="1-启动重启或停止docker服务">1. 启动、重启或停止docker服务</h2>
<p>启动： <code>service docker start</code></p>
<p>停止：<code>service docker stop</code></p>
<p>重启：<code>service docker restart</code></p>
<h2 id="2镜像images">2.镜像(images)</h2>
<h3 id="获取镜像">获取镜像</h3>
<p>docker pull [OPTIONS] NAME[:TAG|@DIGEST]</p>
<p>例如：<code>docker pull ubuntu:16.04</code></p>
<h3 id="列出镜像">列出镜像</h3>
<ul>
<li>查看所有镜像: <code>docker images</code>或<code>docker image ls</code>, 显示摘要<code>docker images --digests</code></li>
<li>查看特定镜像:<code>docker image ls xxxx</code>或<code>docker image xxxx</code></li>
<li>查看镜像、容器、数据卷所占用的空间:<code>docker system df</code></li>
<li>列出虚悬镜像（仓库名和标签名为<!-- raw HTML omitted -->）:<code>docker image ls -f dangling=true</code>,清楚此类镜像<code>docker image prune</code></li>
</ul>
<h3 id="删除镜像">删除镜像</h3>
<p>命令<code>docker image rm [OPTIONS] IMAGE [IMAGE...]</code> 或 <code>docker rmi -f xxxx</code>
例如：</p>
<pre tabindex="0"><code>root@ubuntu:~# docker image ls redis
REPOSITORY          TAG                 IMAGE ID            CREATED             SIZE
redis               latest              ce25c7293564        5 days ago          95MB
</code></pre><ul>
<li>根据完整ID删除：<code>docker image rm 578c3e61a98c</code></li>
<li>根据短ID删除：<code>docker image rm 578c3</code></li>
<li>根据镜像名删除：<code>docker image rm redis</code></li>
<li>docker image ls配合删除：删除所有镜像<code>docker image rm $(docker image ls -q)</code>,删除所有仓库名为redis的镜像<code>docker image rm $(docker image ls -q redis)</code></li>
<li>删除所有未打 dangling 标签的镜像<code>docker rmi $(docker images -q -f dangling=true)</code></li>
</ul>
<p>docker ps -a | grep &ldquo;Exited&rdquo; | awk &lsquo;{print $1 }&rsquo;|xargs docker stop
docker ps -a | grep &ldquo;Exited&rdquo; | awk &lsquo;{print $1 }&rsquo;|xargs docker rm
docker images|grep none|awk &lsquo;{print $3 }&rsquo;|xargs docker rmi</p>
<h2 id="3-容器container">3. 容器(container)</h2>
<h3 id="创建新容器">创建新容器</h3>
<ul>
<li>使用docker镜像nginx:latest以后台模式启动一个容器,并将容器命名为mynginx。</li>
</ul>
<pre tabindex="0"><code>root@ubuntu:~# docker run --name mynginx -d nginx:latest
参数：
--name=&#34;nginx-lb&#34;: 为容器指定一个名称；
-d: 后台运行容器，并返回容器ID；
</code></pre><ul>
<li>使用镜像nginx:latest以后台模式启动一个容器,并将容器的80端口映射到主机随机端口。</li>
</ul>
<pre tabindex="0"><code>root@ubuntu:~# docker run -P -d nginx:latest
参数：
-p: 端口映射，格式为：主机(宿主)端口:容器端口;
</code></pre><ul>
<li>使用镜像 nginx:latest，以后台模式启动一个容器,将容器的 80 端口映射到主机的 80 端口,主机的目录 /data 映射到容器的 /data。</li>
</ul>
<pre tabindex="0"><code>root@ubuntu:~# docker run -p 80:80 -v /data:/data -d nginx:latest
参数：
-v: 映射数据卷,格式为：主机目录:容器目录，注意是绝对路径;
</code></pre><ul>
<li>绑定容器的 8080 端口，并将其映射到本地主机 127.0.0.1 的 80 端口上。</li>
</ul>
<pre tabindex="0"><code>root@ubuntu:~# docker run -p 127.0.0.1:80:8080/tcp ubuntu bash
</code></pre><ul>
<li>使用镜像nginx:latest以交互模式启动一个容器,在容器内执行/bin/bash命令。</li>
</ul>
<pre tabindex="0"><code>root@ubuntu:~# docker run -it nginx:latest /bin/bash
</code></pre><p>参考<a href="http://www.runoob.com/docker/docker-run-command.html">http://www.runoob.com/docker/docker-run-command.html</a></p>
<h3 id="其他命令">其他命令：</h3>
<pre tabindex="0"><code>//查看所有容器
docker ps -a

//查看正在运行的容器
docker ps

//启动一个容器
docker start xxxx

//停止一个容器
docker stop xxxx

//杀死所有正在运行的容器
docker kill $(docker ps -a -q)

//重启一个容器
docker restart xxxx

//删除一个容器，前提是容器是stop
docker rm xxxx

//删除所有已停止容器，慎用！
docker rm $(docker ps -a -q)

//容器与主机之间的数据拷贝
将主机/www/xxxx目录拷贝到容器test-container的/www目录下：
docker cp /www/xxxx test-container:/www/
或
将主机/www/xxxx目录拷贝到容器test-container中，目录重命名为www：
docker cp /www/xxxx test-container:/www

//查看容器ip
方法1：进入容器内部，然后cat /etc/hosts
方法2：docker inspect 容器id
</code></pre><h2 id="常用docker">常用docker</h2>
<h3 id="1-grafana">1. Grafana</h3>
<pre tabindex="0"><code>//创建相关目录，和配置文件
//下载默认配置模板grafana.ini,修改defaults.ini为grafana.ini
`wget https://raw.githubusercontent.com/grafana/grafana/master/conf/defaults.ini`

//创建grafana容器
 docker run -d --name=grafana \
 -p 3000:3000 \
 -v /usr/local/programs/grafana/data:/var/lib/grafana \
 -v /usr/local/programs/grafana/log:/var/log/grafana \
 -v /usr/local/programs/grafana/conf/grafana.ini:/etc/grafana/grafana.ini \
 -e &#34;GF_SERVER_ROOT_URL=http://s1.s:3000&#34; \
 -e &#34;GF_SECURITY_ADMIN_PASSWORD=123456&#34; \
 docker.patpat.vip:9503/grafana:1.20.0:5.4.2
</code></pre><h3 id="2-portainer">2. Portainer</h3>
<pre tabindex="0"><code>docker run -d -p 9000:9000 \
    --restart=always \
    -v /var/run/docker.sock:/var/run/docker.sock \
    --name portainer \
   docker.patpat.vip:9503/portainer:1.20.0
</code></pre><h3 id="3-prometheus">3. Prometheus</h3>
<pre tabindex="0"><code>//下载默认配置
wget https://raw.githubusercontent.com/prometheus/prometheus/master/documentation/examples/prometheus.yml

//创建prometheus镜像
docker run -d --name=prometheus \
    -p 9092:9090 \
    -v /usr/local/programs/prometheus/prometheus.yml:/etc/prometheus/prometheus.yml \
    -v /usr/local/programs/prometheus/data:/prometheus-data \
    prom/prometheus

//创建带alert规则的prometheus镜像  
docker run -d --name=prometheus \
    -p 9092:9090 \
    -v /usr/local/programs/prometheus/prometheus.yml:/etc/prometheus/prometheus.yml \
    -v /usr/local/programs/prometheus/alert.rules:/etc/prometheus/alert.rules \
    -v /usr/local/programs/prometheus/data:/prometheus-data \
    prom/prometheus
    
//创建alertmanager
docker run -d --name=alertmanager \
    -p 9093:9093 \
    -v /usr/local/programs/prometheus/alertmanager/config.yml:/etc/alertmanager/config.yml \
    prom/alertmanager
    
</code></pre><h3 id="4-mysql">4. Mysql</h3>
<p>启动mysql5.6镜像</p>
<pre tabindex="0"><code>docker run -d \
-p 3306:3306 \
--name mysql \
-v /usr/local/programs/mysql/conf:/etc/mysql/conf.d \
-v /usr/local/programs/mysql/logs:/logs \
-v /usr/local/programs/mysql/data:/var/lib/mysql \
-e MYSQL_ROOT_PASSWORD=root \
docker.patpat.vip:9503/mysql:5.6.46
</code></pre><p>启动mysql5.7镜像</p>
<pre tabindex="0"><code>docker pull docker.patpat.vip:9503/mysql:5.7.28

docker run -d \
-p 3306:3306 \
--name mysql \
-v $PWD/mysql:/var/lib/mysql \
-e MYSQL_ROOT_PASSWORD=root \
docker.patpat.vip:9503/mysql:5.7.28
</code></pre><p>说明:
-p 3306:3306：将容器的3306端口映射到主机的3306端口；
-v $PWD/mysql:/var/lib/mysql：将主机当前目录下的/mysql挂载到容器的/var/lib/mysql；
-e MYSQL_ROOT_PASSWORD=password：初始化root用户的密码；
&ndash;name 给容器命名，mysql5719；
-d 表示容器在后台运行</p>
<h3 id="5-php">5. PHP</h3>
<pre tabindex="0"><code>docker run -d -p 9091:9000 --name webconsole-php \
-v /var/www/webconsole:/var/www/html/ \
-v /usr/local/programs/php7/php7-fpm/conf:/usr/local/etc/php \
-v /usr/local/programs/php7/php7-fpm/logs:/phplogs \
--privileged=true \
docker.patpat.vip:9503/php:7.2-fpm
</code></pre><h3 id="6-nginx">6. Nginx</h3>
<p>docker run -d -p 8001:80 &ndash;name webconsole-nginx <br>
-v /var/www/webconsole:/usr/share/nginx/html <br>
-v /usr/local/programs/nginx/conf.d:/etc/nginx/conf.d <br>
-v /usr/local/programs/nginx/log:/var/log/nginx <br>
&ndash;privileged=true -d docker.patpat.vip:9503/nginx:1.15</p>
<h3 id="7-mongo">7. Mongo</h3>
<pre tabindex="0"><code>docker run -d \
--name mongodb \
-p 32767:27017 \
-v /usr/local/programs/mongodb:/data/db \
docker.patpat.vip:9501/mongo:4.2.1
</code></pre><p>windows下会有写入权限问题，所以需要先创建volume，再映射</p>
<p><code>docker volume create --name=mongodata</code></p>
<p><code>docker run -d --name mongodb -p 32767:27017 -v mongodata:/data/db docker.patpat.vip:9503/mongo:4.2.1</code></p>
<p><code>docker volume</code>创建卷之后怎么查看？</p>
<p><a href="https://stackoverflow.com/questions/44358328/how-i-can-access-docker-data-volumes-on-windows-machine">https://stackoverflow.com/questions/44358328/how-i-can-access-docker-data-volumes-on-windows-machine</a></p>
<p>查看所有卷 <code>docker volume ls</code></p>
<p>查看具体某一个卷 <code>docker volume inspect xxxx</code></p>
<p>创建一个临时的环境，将docker跟目录挂载进去，登录进去后ls /var-root就可以查看所有路径文件了</p>
<p><code>docker run --rm -it -v /:/vm-root alpine:edg sh</code></p>
<h3 id="8-redis">8. Redis</h3>
<pre tabindex="0"><code>docker run --name redis -d -p 6379:6379 -v redis-data:/data docker.patpat.vip:9503/redis:5.0.3
</code></pre>]]></content>
		</item>
		
		<item>
			<title>MySQL里EXPLAIN解读</title>
			<link>http://www.heyuan110.com/posts/mysql/2019-09-06-mysql-explain/</link>
			<pubDate>Fri, 06 Sep 2019 20:10:21 +0000</pubDate>
			
			<guid>http://www.heyuan110.com/posts/mysql/2019-09-06-mysql-explain/</guid>
			<description>如何分析一条SQL执行过程?如果评价SQL执行性能好坏？EXPLAIN就是一个很好的工具，它的使用法也很简单，再SQL语句前加上EXPLAIN关键字就可以。
我用的是Mac系统IDE工具Sequel Pro。
来看第一个例子
EXPLAIN SELECT o.id,c.`customers_firstname`,c.`customers_lastname` FROM oms_orders o LEFT JOIN sys_customers c on c.id = o.user_id WHERE o.created_at &amp;gt; &amp;#39;2019-09-05&amp;#39; 执行结果： EXPLAIN列的解释：
id：SELECT 标识符，下面具体分析 select_type: SELECT 类型，下面会具体分析 table: 查询所使用的表 type: JOIN 的类型，下面会具体分析 possible_keys: 可能使用的索引，但不一定会真正使用 key: 真正使用的索引 key_len: 所使用的索引长度 ref: 与索引比较的列 rows: 预估需要扫描的行数 Extra: 额外信息 </description>
			<content type="html"><![CDATA[<p>如何分析一条SQL执行过程?如果评价SQL执行性能好坏？EXPLAIN就是一个很好的工具，它的使用法也很简单，再SQL语句前加上<code>EXPLAIN</code>关键字就可以。</p>
<p>我用的是Mac系统IDE工具Sequel Pro。</p>
<p>来看第一个例子</p>
<pre tabindex="0"><code>EXPLAIN 
SELECT o.id,c.`customers_firstname`,c.`customers_lastname`
FROM oms_orders o 
LEFT JOIN sys_customers c on c.id = o.user_id 
WHERE o.created_at &gt; &#39;2019-09-05&#39;
</code></pre><p>执行结果：
<img src="https://raw.githubusercontent.com/heyuan110/static-source/master/media/mysql/15677558489127.jpg" alt=""></p>
<p>EXPLAIN列的解释：</p>
<ul>
<li>id：SELECT 标识符，下面具体分析</li>
<li>select_type: SELECT 类型，下面会具体分析</li>
<li>table: 查询所使用的表</li>
<li>type: JOIN 的类型，下面会具体分析</li>
<li>possible_keys: 可能使用的索引，但不一定会真正使用</li>
<li>key: 真正使用的索引</li>
<li>key_len: 所使用的索引长度</li>
<li>ref: 与索引比较的列</li>
<li>rows: 预估需要扫描的行数</li>
<li>Extra: 额外信息</li>
</ul>
]]></content>
		</item>
		
		<item>
			<title>刘澜领导力十项修炼学习总结</title>
			<link>http://www.heyuan110.com/posts/management/2019-08-19-liulan-management/</link>
			<pubDate>Mon, 19 Aug 2019 21:10:21 +0000</pubDate>
			
			<guid>http://www.heyuan110.com/posts/management/2019-08-19-liulan-management/</guid>
			<description>周末两天去广州学习了刘澜老师领导力修炼课程，之前在得到APP上听过刘老师这个课，现场感受更好，老师逻辑性强，讲课生动不枯燥，理论结合案例，几乎所有场景都能代入到工作中。
领导力 领导力既是承担解决集体问题的责任，也是承担失败的责任 领导力不等于职位和头衔，领导力是领导职位的责任，领导职位是领导力的资源。没有领导职位，同样可以承担领导力的责任。
魅力不是发挥领导力的前提条件，而是你发挥了领导力之后的（被放大、被神化的）结果。 魅力往往是发挥领导力的负担。带来的副作用：
崇敬领导者，追随者不再提意见 想得到领导认同，追随者不愿提意见 因为追随者的钦佩，追随者产生领导者不会犯错的幻觉 领导者过于自信，忽视了面对的危险 依赖领导者，组织没有培养胜任的继任者 领导力十项口诀
一、我来 勇于承担责任，让我来 面对集体难题，挺身而出，让我来 对平级或上级说，让我来 对下级说，跟我来
怎么建立关于责任感，从三个维度剖析： 意义感-》是否有意义-》我想做 义务感-》是团队一份子，领导信任对我好-》我该做 信心感-》有能力能胜任-》我能做
二、我不知道 学习了领导与管理的区别，弄清除自己现在的定位(管理岗)。 管理岗需要维持团队运转，正确的做事，解决的是维持性问题，解决问题很多时候可能靠权威。 面对维持性问题即使知道答案也要说不知道，动员他人发现答案解决问题，
说我不知道四种情况：
技术性问题，我不一定知道 面对难题，过去的答案不一定管用 面对难题，动员群众发现答案 面对难题，知道也说不知道，更好动员他人找出答案主动实施 三、你觉得呢？ 密切联系群众，跟群众建立关系，通过群众了解信息。 走动式管理，高管不远离群众 多与下属沟通，注意问问题的技巧，通常一个好的问题应该是：
思想上有启发：启发对方思考 情感上有激励：正能量，激励对方（公司文化） 关系上有促进：拉进距离 行动上有推动：推动对方积极行动起来 也可参考参考盖普洛12问和GROW模型。多一些反问，让对方自己悟出来，这样能更好的去执行自己的想法。 四、我来讲个故事 讲故事比讲道理更能动员群众。 四种重要领导力故事：我是谁的故事、我们是谁的故事、我们何处去的故事、我们为什么变革的故事。 让人行动的因素即是理智，更是情感，而打动情感的两大要素：形象和距离 讲好一个故事，最好是能同时打动理智和情感。 讲故事的方式有：
用道具讲故事：借助道具拉进距离。 用仪式讲故事：例如宣誓仪式，入职欢迎仪式和升职仪式。 用行动讲故事：海尔张瑞敏砸冰箱的故事。供应商商品不合格，让Buyer和质检亲手销毁处理掉。 五、我教你 领导者三个角色：设计师、老师、仆人。 领导者需在五个层次当老师：
照我说的做 我说给你听 我做给你看 你说怎么做 你为什么这么做 推行赏识式教育，多说你能行，你做得真好。 从心理学角度在教时分外在动机和内在动机，可以从下面几个方面激发内在动机： 意义感：给他们热爱、明确、整体、挑战的目标 自主感：给他们授权 能力感：给他们指导 进步感：给他们反馈和帮助 六、为什么?（是什么原因） 决策与决定的区别： 决定：一次解决一个问题，往往没有真正解决问题，影响是个别的，暂时的，只找眼前的是什么。 决策：一次解决一批问题，真正解决、预防问题，影响是长期的，全局的，从系统中找为什么。 领导者的任务不是做很多决定，领导者的任务是把少数的决策做好。参考马云。
怎么做决策？（决策思考） 彼得圣吉说领导者要在三个层次上界定现实。
第一个层次是事件的层次，发生了什么事。 第二个层次是行为模式的层次，就是发生的事件，是不是呈现出来某种反复发生的行为模式，怎么样发生？ 第三个层次是系统结构的层次，就是反复出现的这个行为模式，是不是系统结构所导致的，为什么发生？。 要学会做决策，就要不断提升决策的层次。如果只是在第一层分析问题，就是在做决定。 在第二和三层分析问题就是决策 系统思考 从直线式思考变为圆环式思考，系统思考的三块积木：</description>
			<content type="html"><![CDATA[<p>周末两天去广州学习了刘澜老师领导力修炼课程，之前在得到APP上听过刘老师这个课，现场感受更好，老师逻辑性强，讲课生动不枯燥，理论结合案例，几乎所有场景都能代入到工作中。</p>
<h2 id="领导力">领导力</h2>
<p>领导力既是承担解决集体问题的责任，也是承担失败的责任
领导力不等于职位和头衔，领导力是领导职位的责任，领导职位是领导力的资源。没有领导职位，同样可以承担领导力的责任。</p>
<p>魅力不是发挥领导力的前提条件，而是你发挥了领导力之后的（被放大、被神化的）结果。
魅力往往是发挥领导力的负担。带来的副作用：</p>
<ul>
<li>崇敬领导者，追随者不再提意见</li>
<li>想得到领导认同，追随者不愿提意见</li>
<li>因为追随者的钦佩，追随者产生领导者不会犯错的幻觉</li>
<li>领导者过于自信，忽视了面对的危险</li>
<li>依赖领导者，组织没有培养胜任的继任者</li>
</ul>
<p>领导力十项口诀</p>
<h2 id="一我来">一、我来</h2>
<p>勇于承担责任，让我来
面对集体难题，挺身而出，让我来
对平级或上级说，让我来
对下级说，跟我来</p>
<p>怎么建立关于责任感，从三个维度剖析：
意义感-》是否有意义-》我想做
义务感-》是团队一份子，领导信任对我好-》我该做
信心感-》有能力能胜任-》我能做</p>
<h2 id="二我不知道">二、我不知道</h2>
<p>学习了领导与管理的区别，弄清除自己现在的定位(管理岗)。
管理岗需要维持团队运转，正确的做事，解决的是维持性问题，解决问题很多时候可能靠权威。
面对维持性问题即使知道答案也要说不知道，动员他人发现答案解决问题，</p>
<p>说我不知道四种情况：</p>
<ul>
<li>技术性问题，我不一定知道</li>
<li>面对难题，过去的答案不一定管用</li>
<li>面对难题，动员群众发现答案</li>
<li>面对难题，知道也说不知道，更好动员他人找出答案主动实施</li>
</ul>
<h2 id="三你觉得呢">三、你觉得呢？</h2>
<p>密切联系群众，跟群众建立关系，通过群众了解信息。
走动式管理，高管不远离群众
多与下属沟通，注意问问题的技巧，通常一个好的问题应该是：</p>
<ul>
<li>思想上有启发：启发对方思考</li>
<li>情感上有激励：正能量，激励对方（公司文化）</li>
<li>关系上有促进：拉进距离</li>
<li>行动上有推动：推动对方积极行动起来
也可参考参考盖普洛12问和GROW模型。多一些反问，让对方自己悟出来，这样能更好的去执行自己的想法。</li>
</ul>
<h2 id="四我来讲个故事">四、我来讲个故事</h2>
<p>讲故事比讲道理更能动员群众。
四种重要领导力故事：我是谁的故事、我们是谁的故事、我们何处去的故事、我们为什么变革的故事。
让人行动的因素即是理智，更是情感，而打动情感的两大要素：形象和距离
讲好一个故事，最好是能同时打动理智和情感。
讲故事的方式有：</p>
<ul>
<li>用道具讲故事：借助道具拉进距离。</li>
<li>用仪式讲故事：例如宣誓仪式，入职欢迎仪式和升职仪式。</li>
<li>用行动讲故事：海尔张瑞敏砸冰箱的故事。供应商商品不合格，让Buyer和质检亲手销毁处理掉。</li>
</ul>
<h2 id="五我教你">五、我教你</h2>
<p>领导者三个角色：设计师、老师、仆人。
领导者需在五个层次当老师：</p>
<ul>
<li>照我说的做</li>
<li>我说给你听</li>
<li>我做给你看</li>
<li>你说怎么做</li>
<li>你为什么这么做
推行赏识式教育，多说你能行，你做得真好。
从心理学角度在教时分外在动机和内在动机，可以从下面几个方面激发内在动机：</li>
<li>意义感：给他们热爱、明确、整体、挑战的目标</li>
<li>自主感：给他们授权</li>
<li>能力感：给他们指导</li>
<li>进步感：给他们反馈和帮助</li>
</ul>
<h2 id="六为什么是什么原因">六、为什么?（是什么原因）</h2>
<p>决策与决定的区别：
决定：一次解决一个问题，往往没有真正解决问题，影响是个别的，暂时的，只找眼前的是什么。
决策：一次解决一批问题，真正解决、预防问题，影响是长期的，全局的，从系统中找为什么。
领导者的任务不是做很多决定，领导者的任务是把少数的决策做好。参考马云。</p>
<p>怎么做决策？（决策思考）
彼得圣吉说领导者要在三个层次上界定现实。</p>
<ul>
<li>第一个层次是事件的层次，发生了什么事。</li>
<li>第二个层次是行为模式的层次，就是发生的事件，是不是呈现出来某种反复发生的行为模式，怎么样发生？</li>
<li>第三个层次是系统结构的层次，就是反复出现的这个行为模式，是不是系统结构所导致的，为什么发生？。
要学会做决策，就要不断提升决策的层次。如果只是在第一层分析问题，就是在做决定。
在第二和三层分析问题就是决策</li>
</ul>
<p>系统思考
从直线式思考变为圆环式思考，系统思考的三块积木：</p>
<ul>
<li>增强环路</li>
<li>调节环路</li>
<li>滞延(Delay): 可以解释为什么人不锻炼身体，为什么抽烟
决定往往带来的是症状解
决策往往对应的是根本解
症状解带来三种副作用：产生依赖、占用资源、实质伤害。尝试用调节环路分析例如：销售增长乏力、项目交付困难、招聘困难。</li>
</ul>
<p>决策思考的“为什么”是找原因。系统思考的“为什么”是找目标。</p>
<h2 id="七失败了恭喜你">七、失败了？恭喜你！</h2>
<p>平庸和伟大的分水岭，就是对待失败的态度。
以为没有犯过错的人将不会学到如何及早找出错误，并且改正
对待失败的三个镜：哈哈镜、望远镜、后视镜</p>
<p>组织对待失败的原则：</p>
<ul>
<li>尽早发现失败：大失败都是从小失败发展而来</li>
<li>鼓励报告失败：不鼓励报告失败，很多失败隐藏，日积月累变成大失败，变成系统性失败</li>
<li>深入分析失败：别上来就问’谁干的？’，参考第7条，问为什么</li>
<li>主动实验失败 ：强大大胆创新，不害怕失败，同时强调小规模试点，从失败结果中学习经验。</li>
</ul>
<p>7种失败分类</p>
<ul>
<li>a无视规章</li>
<li>b粗心大意</li>
<li>c能力不足</li>
<li>d流程缺陷</li>
<li>e已知分险</li>
<li>f难料分险</li>
<li>g探索分险</li>
</ul>
<p>好的失败：g</p>
<p>中性失败: e 、f
坏的失败：a、b、c、d</p>
<p>好的失败是我们主动追求的失败，可以学习经验。
中性失败是难以避免的失败，所以失败很正常
坏的失败是本可以避免的失败</p>
<p>所有7种失败都值得恭喜，对失败的重新定义：</p>
<ul>
<li>善意的警告</li>
<li>成功的过程</li>
<li>有益的发展</li>
<li>上天的眷顾</li>
<li>学习的机会</li>
<li>另外的机遇</li>
</ul>
<p>把失败当做学习的机会，面对失败除了恭喜，还可以说：
失败了？不要紧！
失败了？太好了！
失败了？这时好事！</p>
<h2 id="八我或你要改变什么">八、我（或你）要改变什么？</h2>
<p>什么是反思？
大多数人理解的反思是回头看，优秀的领导者不仅仅是回头看，还会在行动之前和进行中反思。
反思 = 思 + 再思</p>
<p>反思的四个要素：</p>
<ul>
<li>抽身而出：想再思的时候容易忘记之前的思，可以将之前的思写下来</li>
<li>放下情感：自己想出来的主意更喜欢，不愿意承认那可能是错的，负面情绪交织一起</li>
<li>转换角度：换人思考，将别人或自己放到对应位置</li>
<li>指导实践：反思出来的结果要能指导将来的实践</li>
</ul>
<p>反思三个层次：</p>
<ul>
<li>行动（怎么做）：小反思</li>
<li>目标（做什么）：中反思</li>
<li>信念（为什么做）：大反思</li>
</ul>
<p>信念：我们深信不疑但是难以证明的想法，主要有三种：真与假、价值观、对与错</p>
<p>优秀的领导者要不断升级反思层次，从小反思-》大反思。小反思是对行动的反思，反思该怎么改变行动，才能做得更好？它假设目标不变.</p>
<p>作为领导者不仅要对自己用这句口诀，还要对别人用这句口诀，这时变为:’你要改变什么？’</p>
<p>曾子的反思：吾日三省吾身
我自己的座右铭：常笑笑自己</p>
<h2 id="九我们是谁">九、我（们）是谁?</h2>
<p>认识自己的三性：
个性：先天+后天
文化性：后天
人性：先天</p>
<p>领导力修炼要求的人性与普通人人性对比
承担责任、直面难题《-》人们习惯于做追随者
直面难题、从失败学习《-》人们习惯于规避风险
直面难题、深思《-》人们习惯于快思考
认识自己、密切联系群众《-》人们自我感觉良好
认识自己、反思《-》人们喜欢行动胜过思考</p>
<p>认识自己个性的六个层次：</p>
<table>
<thead>
<tr>
<th>认识自己的六个层次</th>
<th>认识企业文化的六个层次</th>
</tr>
</thead>
<tbody>
<tr>
<td>身份</td>
<td>使命、愿景</td>
</tr>
<tr>
<td>信念</td>
<td>价值观</td>
</tr>
<tr>
<td>目标</td>
<td>战略</td>
</tr>
<tr>
<td>能力</td>
<td>流程</td>
</tr>
<tr>
<td>行动</td>
<td>员工行为</td>
</tr>
<tr>
<td>环境</td>
<td>环境</td>
</tr>
</tbody>
</table>
<p>越接近底层，越容易变动，高层改变往往推动底层改变，反之未必
作为领导者要多问我是谁，我们是谁。</p>
<h2 id="十我该是谁">十、我该是谁？</h2>
<p>成为自己的核心问题：确定身份，个人愿景
三环理论：
<img src="https://raw.githubusercontent.com/heyuan110/static-source/master/media/leader_power/15665561987496.jpg" alt=""></p>
<p>把自己热爱的、擅长的、机会的写出来，三个里面交叉的就是我们应该做的事情。
三环是循环的，可以相互促进转化，重新定义这三环：
热爱=深层需求，而非表面兴趣
擅长=高层能力，而非技术能力
机会=趋势，而非眼前，贡献，而非收益</p>
<p>三环中间交叉处即是人生愿景，要成就伟业、热爱优先。</p>
]]></content>
		</item>
		
		<item>
			<title>消息队列-RabbitMQ</title>
			<link>http://www.heyuan110.com/posts/middleware/2019-08-02-mq-rabbitmq/</link>
			<pubDate>Fri, 02 Aug 2019 11:47:04 +0000</pubDate>
			
			<guid>http://www.heyuan110.com/posts/middleware/2019-08-02-mq-rabbitmq/</guid>
			<description>前面文章《消息队列中间件选型》我们了解了消息队列技术选型，本文我们来学习开源消息队列RabbitMQ。
1. RabbitMQ简介 RabbitMQ是一个开源的消息代理和队列服务器，用来通过普通协议在完全不同的应用之间共享数据，RabbitMQ是使用Erlang语言来编写的，并且RabbitMQ是基于AMQP协议的。
2. RabbitMQ工作流程 RabbitMQ架构图 发布者P-Clients（Publisher）发布消息(Message)，经由交换机X（Exchange） 交换机根据路由规则将收到的消息分发给与该交换机绑定的队列(Queue) 最后RabbitMQ代理（Broker）会将消息投递（Push）给订阅了此队列的消费者(Consumer)，或者消费者按照需求自行获取(Pull)
深入理解：
(1)发布者、交换机、队列、消费者都可以有多个，因为RabbitMQ是基于网络协议AMQP，所以这个过程中发布者，交换机，队列，消费者可以处于不同的设备上。
(2)消息发布者可以给消息指定各种属性（Message Meta-data),一些属性可能被消息代理(Broker)使用，一些只能被消费者使用。消息分两部分：payload(有效载荷，传输的数据)和label(标签,exchange的名字或者说是一个tag，它描述了payload)，RabbitMQ通过label决定把Message发给哪个消费者。AMQP协议仅仅描述了label，RabbitMQ决定了如何使用label的规则。消费者在收到消息时只有payload部分，label已经被删掉，对于消费者而言是不知道谁发送的消息。
(3)从安全和可靠性角度，RabbitMQ很好实现了AMQP协议的消息确认(Message Acknowledgements)机制,当一个消息投递给消费者后，不会立即删除，直到它收到来自消费者的确认回执(Acknowledgements)后,才完成从队列里删除。
3. RabbitMQ基本概念 我们先来看一张RabbitMQ管理界面截图
这个界面包含了RabbitMQ很关键的几个概念(不是全部)
3.1 Producer（生产者） 消息生产者
3.2 Consumer（消费者） 消息消费者
3.3 Connection（连接） 无论是生产者还是消费者，都需要和RabbitMQ Broker建立连接，这个连接就是一条TCP,当不要连接时，需要优雅释放掉RabbitMQ连接,而不是直接将TCP连接关闭。后面我们可以知道使用RabbitMQ程序开头时，都是先建立TCP连接。
3.4 Channel（信道） 一旦TCP连接建立起来，客户端紧接着可以创建一个AMQP信道（Channel），每个信道都会被指派一个唯一的ID。信道是建立在Connection之上的虚拟连接，Rabbit处理的每条指令都是通过Channel完成的。一般情况程序起始建立TCP连接，第二步就是建立Channel。
为什么要用Channel，而不直接用TCP连接？
试想如果一个场景，如果一个应用程序有很多个线程需要从RabbitMQ消费或生产消息，那么必然会创建很多个TCP连接，我们知道建立一个TCP连接需要3次握手,关闭一个TCP连接需4次挥手，对于系统来说频繁建立和关闭TCP连接对于系统性能有很大影响，而且TCP连接数也有限制，也限制了系统处理高并发的能力。 Rabbitmq采用类似NIO(也称非阻塞 I/O，包含三大核心部分：Channel信道、Buffer缓冲区和 Selector选择器)的做法,选择TCP连接复用，每个线程把持一个信道，信道复用了Connection的TCP连接.当每个信道的流量不是很大时，复用单一connection可以有效节省TCP连接资源，但如果信道流量很大，复用单一connection，connection的带宽会限制消息传输。此时需创建多个connection，将信道分摊到connection中。
3.5 Exchange（交换机） 消息交换机指定消息按什么规则，路由到哪个队列去。
那为什么需要Exchange而不是直接将消息发送至队列呢？
回到与RabbitM关系紧密的AMQP协议，AMQP协议核心思想就是生产者和消费者解耦，生产者不直接将消息发送给队列。生产者不知道消息会被发到哪个队列，它只将消息发给交换机，交换机接收到消息后按照特定的规则转发到队列进行存储。 在实际应用中我们只需要定义好Exchange的路由策略，而生产者不需要关心消息发送到哪个队列或被谁消费。消费者不需要关心谁生产，只需面向队列消费消息。
Exchange定义了消息路由到Queue的规则，将各个层面的消息传递隔离开，使每一层只需要关心自己面向的下一层，降低了整体的耦合度。
创建一个新的Exchange
Virtual host:属于哪个Virtual host。 Name：名字，同一个Virtual host里面的Name不能重复。 Durability： 是否持久化，Durable：持久化。Transient：不持久化。 Auto delete：当最后一个绑定（队列或者exchange）被unbind之后，该exchange自动被删除。 Internal： 是否是内部专用exchange，是的话，就意味着我们不能往该exchange里面发消息。 Arguments： 参数，是AMQP协议留给AMQP实现做扩展使用的。 alternate_exchange配置的时候，exchange根据路由路由不到对应的队列的时候，这时候消息被路由到指定的alternate_exchange的value值配置的exchange上。 3.6 Exchange类型 （1）.Direct exchange
将消息中的Routing key与该Exchange关联的所有Binding中的Routing key进行比较，如果相等，则发送到该Binding对应的Queue中。
（2）.Topic Exchange 将消息中的Routing key与该Exchange关联的所有Binding中的Routing key进行对比，如果匹配上了，则发送到该Binding对应的Queue中。</description>
			<content type="html"><![CDATA[<p>前面文章<a href="http://www.heyuan110.com/2019-07-31-%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97%E4%B8%AD%E9%97%B4%E4%BB%B6%E9%80%89%E5%9E%8B.html">《消息队列中间件选型》</a>我们了解了消息队列技术选型，本文我们来学习开源消息队列RabbitMQ。</p>
<h2 id="1-rabbitmq简介">1. RabbitMQ简介</h2>
<p>RabbitMQ是一个开源的消息代理和队列服务器，用来通过普通协议在完全不同的应用之间共享数据，RabbitMQ是使用Erlang语言来编写的，并且RabbitMQ是基于AMQP协议的。</p>
<h2 id="2-rabbitmq工作流程">2. RabbitMQ工作流程</h2>
<p>RabbitMQ架构图
<img src="https://raw.githubusercontent.com/heyuan110/static-source/master/media/rabbitmq/15647300964346.jpg" alt=""></p>
<p>发布者P-Clients（Publisher）发布消息(Message)，经由交换机X（Exchange）
交换机根据路由规则将收到的消息分发给与该交换机绑定的队列(Queue)
最后RabbitMQ代理（Broker）会将消息投递（Push）给订阅了此队列的消费者(Consumer)，或者消费者按照需求自行获取(Pull)</p>
<p>深入理解：</p>
<p>(1)发布者、交换机、队列、消费者都可以有多个，因为RabbitMQ是基于网络协议AMQP，所以这个过程中发布者，交换机，队列，消费者可以处于不同的设备上。</p>
<p>(2)消息发布者可以给消息指定各种属性（Message Meta-data),一些属性可能被消息代理(Broker)使用，一些只能被消费者使用。消息分两部分：payload(有效载荷，传输的数据)和label(标签,exchange的名字或者说是一个tag，它描述了payload)，RabbitMQ通过label决定把Message发给哪个消费者。AMQP协议仅仅描述了label，RabbitMQ决定了如何使用label的规则。消费者在收到消息时只有payload部分，label已经被删掉，对于消费者而言是不知道谁发送的消息。</p>
<p>(3)从安全和可靠性角度，RabbitMQ很好实现了AMQP协议的消息确认(Message Acknowledgements)机制,当一个消息投递给消费者后，不会立即删除，直到它收到来自消费者的确认回执(Acknowledgements)后,才完成从队列里删除。</p>
<h2 id="3-rabbitmq基本概念">3. RabbitMQ基本概念</h2>
<p>我们先来看一张RabbitMQ管理界面截图</p>
<p><img src="https://raw.githubusercontent.com/heyuan110/static-source/master/media/rabbitmq/15647344884041.jpg" alt=""></p>
<p>这个界面包含了RabbitMQ很关键的几个概念(不是全部)</p>
<h3 id="31-producer生产者">3.1 Producer（生产者）</h3>
<p>消息生产者</p>
<h3 id="32-consumer消费者">3.2 Consumer（消费者）</h3>
<p>消息消费者</p>
<h3 id="33-connection连接">3.3 Connection（连接）</h3>
<p>无论是生产者还是消费者，都需要和RabbitMQ Broker建立连接，这个连接就是一条TCP,当不要连接时，需要优雅释放掉RabbitMQ连接,而不是直接将TCP连接关闭。后面我们可以知道使用RabbitMQ程序开头时，都是先建立TCP连接。</p>
<h3 id="34-channel信道">3.4 Channel（信道）</h3>
<p>一旦TCP连接建立起来，客户端紧接着可以创建一个AMQP信道（Channel），每个信道都会被指派一个唯一的ID。信道是建立在Connection之上的虚拟连接，Rabbit处理的每条指令都是通过Channel完成的。一般情况程序起始建立TCP连接，第二步就是建立Channel。</p>
<p><img src="https://raw.githubusercontent.com/heyuan110/static-source/master/media/rabbitmq/15647378165803.jpg" alt=""></p>
<p>为什么要用Channel，而不直接用TCP连接？</p>
<p>试想如果一个场景，如果一个应用程序有很多个线程需要从RabbitMQ消费或生产消息，那么必然会创建很多个TCP连接，我们知道建立一个TCP连接需要3次握手,关闭一个TCP连接需4次挥手，对于系统来说频繁建立和关闭TCP连接对于系统性能有很大影响，而且TCP连接数也有限制，也限制了系统处理高并发的能力。
Rabbitmq采用类似NIO(也称非阻塞 I/O，包含三大核心部分：Channel信道、Buffer缓冲区和 Selector选择器)的做法,选择TCP连接复用，每个线程把持一个信道，信道复用了Connection的TCP连接.当每个信道的流量不是很大时，复用单一connection可以有效节省TCP连接资源，但如果信道流量很大，复用单一connection，connection的带宽会限制消息传输。此时需创建多个connection，将信道分摊到connection中。</p>
<h3 id="35-exchange交换机">3.5 Exchange（交换机）</h3>
<p>消息交换机指定消息按什么规则，路由到哪个队列去。</p>
<p>那为什么需要Exchange而不是直接将消息发送至队列呢？</p>
<p>回到与RabbitM关系紧密的AMQP协议，AMQP协议核心思想就是<strong>生产者和消费者解耦</strong>，生产者不直接将消息发送给队列。生产者不知道消息会被发到哪个队列，它只将消息发给交换机，交换机接收到消息后按照特定的规则转发到队列进行存储。
<img src="https://raw.githubusercontent.com/heyuan110/static-source/master/media/rabbitmq/15647390185527.jpg" alt=""></p>
<p>在实际应用中我们只需要定义好Exchange的路由策略，而生产者不需要关心消息发送到哪个队列或被谁消费。消费者不需要关心谁生产，只需面向队列消费消息。</p>
<p>Exchange定义了消息路由到Queue的规则，将各个层面的消息传递隔离开，使每一层只需要关心自己面向的下一层，降低了整体的耦合度。</p>
<p>创建一个新的Exchange</p>
<p><img src="https://raw.githubusercontent.com/heyuan110/static-source/master/media/rabbitmq/15647425737375.jpg" alt=""></p>
<ul>
<li>Virtual host:属于哪个Virtual host。</li>
<li>Name：名字，同一个Virtual host里面的Name不能重复。</li>
<li>Durability： 是否持久化，Durable：持久化。Transient：不持久化。</li>
<li>Auto delete：当最后一个绑定（队列或者exchange）被unbind之后，该exchange自动被删除。</li>
<li>Internal： 是否是内部专用exchange，是的话，就意味着我们不能往该exchange里面发消息。</li>
<li>Arguments： 参数，是AMQP协议留给AMQP实现做扩展使用的。</li>
<li>alternate_exchange配置的时候，exchange根据路由路由不到对应的队列的时候，这时候消息被路由到指定的alternate_exchange的value值配置的exchange上。</li>
</ul>
<h3 id="36-exchange类型">3.6 Exchange类型</h3>
<p><img src="https://raw.githubusercontent.com/heyuan110/static-source/master/media/rabbitmq/15647424693007.jpg" alt=""></p>
<p><strong>（1）.Direct exchange</strong></p>
<p><img src="https://raw.githubusercontent.com/heyuan110/static-source/master/media/rabbitmq/15649763567956.jpg" alt=""></p>
<p>将消息中的Routing key与该Exchange关联的所有Binding中的Routing key进行比较，如果相等，则发送到该Binding对应的Queue中。</p>
<p><strong>（2）.Topic Exchange</strong>
<img src="https://raw.githubusercontent.com/heyuan110/static-source/master/media/rabbitmq/15649764244812.jpg" alt=""></p>
<p>将消息中的Routing key与该Exchange关联的所有Binding中的Routing key进行对比，如果匹配上了，则发送到该Binding对应的Queue中。</p>
<p><strong>（3）.Fanout Exchange</strong>
<img src="https://raw.githubusercontent.com/heyuan110/static-source/master/media/rabbitmq/15649763997958.jpg" alt=""></p>
<p>直接将消息转发到所有binding的对应queue中，这种exchange在路由转发的时候，忽略Routing key，所以fanout交换机也是转消息最快的。</p>
<p><strong>（4）.Headers Exchange</strong></p>
<p>将消息中的headers与该Exchange相关联的所有Binging中的参数进行匹配，如果匹配上了，则发送到该Binding对应的Queue中。</p>
<h3 id="37-queue队列">3.7 Queue（队列）</h3>
<p>消息队列载体，用于存储消息，每个消息都会被投入到一个或多个队列。消息消费者就是通过订阅队列来获取消息，多个消费者可订阅同一个队列，这时队列中的消息会被平均分摊给多个消费者进行处理，而不是每个消费者都收到所有消息。</p>
<h3 id="38-binding绑定">3.8 Binding（绑定）</h3>
<p>绑定，它的作用就是把Exchange和Queue按照路由规则绑定起来。</p>
<h3 id="39-routing-key路由键">3.9 Routing Key（路由键）</h3>
<p>消息发送给Exchange（交换机）时，消息将拥有一个路由键（默认为空），Exchange（交换机）根据这个路由键将消息发送到匹配的队列中。</p>
<h3 id="310-binding-key绑定键">3.10 Binding Key（绑定键）</h3>
<h3 id="311-virtual-hosts">3.11 Virtual Hosts</h3>
<p>虚拟主机，一个broker里可以开设多个vhost，用作不同用户的权限分离。</p>
<h2 id="4-rabbitmq队列模式">4. RabbitMQ队列模式</h2>
<p>所有实例采用PHP实现，引用包<a href="https://github.com/php-amqplib/php-amqplib">php-amqplib</a>,引用类：</p>
<pre tabindex="0"><code>use PhpAmqpLib\Connection\AMQPStreamConnection;
use PhpAmqpLib\Message\AMQPMessage;
</code></pre><p>完整代码：<a href="https://github.com/heyuan110/laravel-rabbitmq">https://github.com/heyuan110/laravel-rabbitmq</a></p>
<h3 id="41-简单队列模式">4.1 简单队列模式</h3>
<p><img src="https://raw.githubusercontent.com/heyuan110/static-source/master/media/rabbitmq/15649775221394.jpg" alt=""></p>
<p>功能：一个生产者P发送消息到队列，一个消费者C消费</p>
<p>生产者P代码:</p>
<pre tabindex="0"><code>    //https://www.rabbitmq.com/tutorials/tutorial-one-php.html
    public function publishSimpleMQ()
    {
        //create a connection
        $connection = new AMQPStreamConnection(&#39;172.16.166.130&#39;,&#39;5672&#39;,&#39;guest&#39;,&#39;guest&#39;,&#39;/&#39;);
        //create a channel
        $channel = $connection-&gt;channel();
        //declare a queue for us to send to; then we can publish a message to the queue
        $channel-&gt;queue_declare(&#39;hello&#39;,false,false,false,false);
        
        //create a message, publish it to the queue
        $msg = new AMQPMessage(&#34;hello world&#34;);
        $channel-&gt;basic_publish($msg,&#39;&#39;,&#39;hello&#39;);
        echo &#34; [x] Sent &#39;Hello World!&#39;\n&#34;;
        Log::info(&#34; [x] Sent &#39;Hello World!&#39;\n&#34;);

        //close channel, close connection
        $channel-&gt;close();
        $connection-&gt;close();
    }
</code></pre><p>过程：
(1). 创建连接，设置服务地址，端口，账号，vhost
(2). 使用连接创建信道
(3). 使用信道创建队列
(4). 创建消息
(5). 使用信道向队列发送消息
(6). 关闭信道，关闭连接</p>
<p>消费者C代码:</p>
<pre tabindex="0"><code>public function consumeSimpleMQ()
    {
        //create a connection
        $connection = new AMQPStreamConnection(&#39;172.16.166.130&#39;,&#39;5672&#39;,&#39;guest&#39;,&#39;guest&#39;,&#39;/&#39;);
        //create a channel
        $channel = $connection-&gt;channel();
        //declare a queue for us to send to; then we can publish a message to the queue
        $channel-&gt;queue_declare(&#39;hello&#39;,false,false,false,false);
        
        echo &#34; [*] Waiting for messages. To exit press CTRL+C\n&#34;;

        $callback = function ($msg){
            echo &#39;[x] Received &#39; . $msg-&gt;body . &#39;\n&#39;;
            Log::info(&#39;[x] Received &#39; . $msg-&gt;body . &#39;\n&#39;);
        };
        $channel-&gt;basic_consume(&#39;hello&#39;,&#39;&#39;,false,true,false,false,$callback);
        while($channel-&gt;is_consuming()){
            $channel-&gt;wait();
        }

        //close channel, close connection
        $channel-&gt;close();
        $connection-&gt;close();
    }
</code></pre><p>过程：
(1). 创建连接，设置服务地址，端口，账号，vhost
(2). 使用连接创建信道
(3). 使用信道创建队列
(4). 创建消费者监听队列，从队列中读取消息
(5). 关闭信道，关闭连接</p>
<h3 id="42-工作队列模式">4.2 工作队列模式</h3>
<p><img src="https://raw.githubusercontent.com/heyuan110/static-source/master/media/rabbitmq/15649775307431.jpg" alt=""></p>
<p>功能：一个生产者P发送消息到队列，多个消费者C消费，每个消费者获取到的消息唯一，多个消费者只有一个队列。</p>
<p>工作队列：设计思路是为了避免资源密集型任务立即执行，并必须等待它完成，相反安排任务稍后执行。将任务封装成消息，后台运行的消费者进程将获取任务并最终执行，多个消费者运行时，它们之间共享任务。</p>
<p>生产者P代码:</p>
<pre tabindex="0"><code>//https://www.rabbitmq.com/tutorials/tutorial-two-php.html
 public function produceWorkMQ()
    {
        //create a connection
        $connection = new AMQPStreamConnection(&#39;172.16.166.130&#39;,&#39;5672&#39;,&#39;guest&#39;,&#39;guest&#39;,&#39;/&#39;);
        //create a channel
        $channel = $connection-&gt;channel();
        //declare a queue for us to send to; then we can publish a message to the queue
        //set queue durable is ture，make sure that messages aren&#39;t lost
        $channel-&gt;queue_declare(&#39;hello&#39;,false,$durable=true,false,false);
                
        //create a message, publish it to the queue
        $data = $this-&gt;option(&#39;msg&#39;);
        if (empty($data)) {
            $data = &#34;Hello World!&#34;;
        }
        $msg = new AMQPMessage(
            $data,
            [&#39;delivery_mode&#39; =&gt; AMQPMessage::DELIVERY_MODE_PERSISTENT]
        );
        $channel-&gt;basic_publish($msg,&#39;&#39;,&#39;hello&#39;);
        echo &#34; [x] Sent &#39;&#34;.$data.&#34;&#39;\n&#34;;
        Log::info(&#34; [x] Sent &#39;&#34;.$data.&#34;&#39;\n&#34;);

        //close channel, close connection
        $channel-&gt;close();
        $connection-&gt;close();
    }
</code></pre><p>过程：
(1). 创建连接，设置服务地址，端口，账号，vhost
(2). 使用连接创建信道
(3). 使用信道创建队列，设置队列durable参数为true，确保在rabbitmq server停止时不丢失队列
(4). 创建消息,消息内容来自输入参数msg，设置delivery_mode为2，确保在rabbitmq server停止时不丢失消息
(5). 使用信道向队列发送消息
(6). 关闭信道，关闭连接</p>
<p>{% alert info %}
与simple队列相比，我们增加了队列和消息的持久化，确保rabbitmq server服务器停止时，队列和消息都不会丢失
{% endalert %}</p>
<p>消费者C代码:</p>
<pre tabindex="0"><code> public function consumeWorkMQ()
    {
        //create a connection
        $connection = new AMQPStreamConnection(&#39;172.16.166.130&#39;,&#39;5672&#39;,&#39;guest&#39;,&#39;guest&#39;,&#39;/&#39;);
        //create a channel
        $channel = $connection-&gt;channel();
        //declare a queue for us to send to; then we can publish a message to the queue
        //set queue durable is ture，make sure that messages aren&#39;t lost
        $channel-&gt;queue_declare(&#39;hello&#39;,false,$durable=true,false,false);
                
        echo &#34; [*] Waiting for messages. To exit press CTRL+C\n&#34;;

        $callback = function ($msg){
            echo &#39;[x] Received &#39; . $msg-&gt;body . &#39;\n&#39;;
            sleep(substr_count($msg-&gt;body, &#39;.&#39;));
            echo &#34; [x] Done\n&#34;;
            //ack notification
            $msg-&gt;delivery_info[&#39;channel&#39;]-&gt;basic_ack($msg-&gt;delivery_info[&#39;delivery_tag&#39;]);
        };

        $channel-&gt;basic_qos(null, 1, null);
        //open ack 
        $channel-&gt;basic_consume(&#39;hello&#39;,&#39;&#39;,false,$no_ack=false,false,false,$callback);
        while($channel-&gt;is_consuming()){
            $channel-&gt;wait();
        }

        //close channel, close connection
        $channel-&gt;close();
        $connection-&gt;close();
    }
</code></pre><p>过程：
(1). 创建连接，设置服务地址，端口，账号，vhost
(2). 使用连接创建信道
(3). 使用信道创建队列
(4). 设置basic_qos值为1，告诉RabbitMQ在处理并确认前一个消息之前，不要向消费者发送新消息
(5). 创建消费者监听队列，从队列中读取消息,为了确保没有消息丢失，开启了ack机制（basic_consume方法第四个参数），在消息处理完成后回调basic_ack通知rabbitmq。
(6). 关闭信道，关闭连接</p>
<p>{% alert info %}
与simple队列相比，增加了消息处理完成ack确认，避免由于消费者意外中断导致消息未正确执行完成而丢失。多个消费者C时可能出现一些消费者特别忙，一些特别闲，但是这种情况RabbitMQ并不知道，还是均匀的发送消息（原因：This happens because RabbitMQ just dispatches a message when the message enters the queue. It doesn&rsquo;t look at the number of unacknowledged messages for a consumer. It just blindly dispatches every n-th message to the n-th consumer.），这样明显是不合理的，基于调度公平原则，设置basic_qos参数为1，直到Rabbitmq收到上次消息完成的确认再推送新消息给此消费者。
{% endalert %}</p>
<h3 id="43-发布订阅模式">4.3 发布/订阅模式</h3>
<p><img src="https://raw.githubusercontent.com/heyuan110/static-source/master/media/rabbitmq/15649775451475.jpg" alt=""></p>
<p>功能：一个生产者P发送的消息会被多个消费者C消费。一个生产者，一个交换机，多个队列，多个消费者。</p>
<p>RabbitMQ种消息传递模型的核心思想是生产者永远不会将消息直接发送到队列，生产者甚至都不知道消息是否被发送到了队列。在消息传递模型中，生产者只能向交换机发送消息，交换机必须要准确知道消息将如果转发，这个转发规则类型有：direct,topic,headers,fanout，在上面的exchange type里已经详细解释。</p>
<p>4.1和4.2里我们没有提到交换机，为什么也可以给队列发消息？因为basic_publish在发送消息时其实用了默认的交换机(第二个参数设置为&rsquo;&rsquo;)，设置为默认交换机时，消息会被路由到routing_key的队列（如果队列存在）。</p>
<p>如果消息发送到没有绑定队列的交换机，消息将会丢失，交换机本身不存储消息，消息存储在队列中.</p>
<p>生产者P代码:</p>
<pre tabindex="0"><code>    // https://www.rabbitmq.com/tutorials/tutorial-three-php.html
    public function publishMQ()
    {
        //create a connection
        $connection = new AMQPStreamConnection(&#39;172.16.166.130&#39;,&#39;5672&#39;,&#39;guest&#39;,&#39;guest&#39;,&#39;/&#39;);
        //create a channel
        $channel = $connection-&gt;channel();

        //create a exchange logs, type:fanout
        $channel-&gt;exchange_declare(&#39;logs&#39;, &#39;fanout&#39;, false, false, false);

        //create a message, publish it to the queue
        $data = $this-&gt;option(&#39;msg&#39;);
        if (empty($data)) {
            $data = &#34;Hello World!&#34;;
        }
        $msg = new AMQPMessage(date(&#34;Y-m-d H:i:s &#34;).$data);

        //send a message to exchange logs
        $channel-&gt;basic_publish($msg,&#39;logs&#39;);

        echo &#34; [x] Sent &#39;&#34;.$data.&#34;&#39;\n&#34;;

        //close channel, close connection
        $channel-&gt;close();
        $connection-&gt;close();
    }
</code></pre><p>过程：
(1). 创建连接，设置服务地址，端口，账号，vhost
(2). 使用连接创建信道
(3). 使用信道创建交换机，设置交换机类型为fanout（交换机接收的所有消息无差别转发到绑定队列）
(4). 创建消息,消息内容来自输入参数msg
(5). 使用信道向交换机发送消息，注意在这里我们没有设置routing_key，也没有创建任何队列
(6). 关闭信道，关闭连接</p>
<p>消费者C代码:</p>
<pre tabindex="0"><code>    public function subscribekMQ()
    {
        //create a connection
        $connection = new AMQPStreamConnection(&#39;172.16.166.130&#39;,&#39;5672&#39;,&#39;guest&#39;,&#39;guest&#39;,&#39;/&#39;);
        //create a channel
        $channel = $connection-&gt;channel();

        //create a exchange logs, type:fanout
        $channel-&gt;exchange_declare(&#39;logs&#39;, &#39;fanout&#39;, false, false, false);

        //declare a temporary queue for us to send to;  the temporary queue is auto delete when the consumer disconnect
        list($queue_name, ,) = $channel-&gt;queue_declare(&#34;&#34;, false, false, true, false);
                
        //bind queue to exchange logs
        $channel-&gt;queue_bind($queue_name, &#39;logs&#39;);

        echo &#34; [*] Waiting for logs. To exit press CTRL+C\n&#34;;

        $callback = function ($msg) {
            echo &#39; [x] &#39;, $msg-&gt;body, &#34;\n&#34;;
        };

        //create consume
        $channel-&gt;basic_consume($queue_name, &#39;&#39;, false, true, false, false, $callback);

        while($channel-&gt;is_consuming()){
            $channel-&gt;wait();
        }

        //close channel, close connection
        $channel-&gt;close();
        $connection-&gt;close();
    }
</code></pre><p>过程：
(1). 创建连接，设置服务地址，端口，账号，vhost
(2). 使用连接创建信道
(3). 使用信道创建交换机，设置交换机类型为fanout（交换机接收的所有消息无差别转发到绑定队列）
(4). 使用信道创建临时队列，队列名字设置为空，服务器会自动创建随机队列名称（大概类似：amq.gen-RAkn-INGuKex4JMNmoTZDA），一旦订阅消费者端口，临时队列会自动删除。返回队列名称$queue_name备用。
(5). 绑定队列交换机，让发送到交换机的消息都转发到队列
(6). 创建消费者监听队列，从队列中读取消息。
(7). 关闭信道，关闭连接</p>
<p>{% alert info %}
这个DEMO可以很好帮我们理解发布订阅模式，在Console里多启动几个订阅消费者，观察rabbitmq里队列会发现多了几个临时队列，如果终止它们随即会删除。
{% endalert %}</p>
<h3 id="44-路由模式">4.4 路由模式</h3>
<p><img src="https://raw.githubusercontent.com/heyuan110/static-source/master/media/rabbitmq/15649775511731.jpg" alt=""></p>
<p>功能：生产者P发送的消息到交换机并指定routing_key，消费者将队列绑定到交换机时需要指定路由key。</p>
<p>生产者P代码:</p>
<pre tabindex="0"><code>//https://www.rabbitmq.com/tutorials/tutorial-four-php.html
public function publishMQ()
    {
        //create a connection
        $connection = new AMQPStreamConnection(&#39;172.16.166.130&#39;,&#39;5672&#39;,&#39;guest&#39;,&#39;guest&#39;,&#39;/&#39;);
        //create a channel
        $channel = $connection-&gt;channel();

        //create a exchange logs, type:direct
        $exchange_name = &#39;direct_logs&#39;;
        $echange_type = &#39;direct&#39;;
        $channel-&gt;exchange_declare($exchange_name, $echange_type, false, false, false);

        //get routing key
        $routing_key = $this-&gt;option(&#39;level&#39;);
        if (empty($routing_key)) {
            $routing_key = &#34;info&#34;;
        }

        //create a message, publish it to the queue
        $data = $this-&gt;option(&#39;msg&#39;);
        if (empty($data)) {
            $data = &#34;Hello World!&#34;;
        }
        $msg = new AMQPMessage(date(&#34;Y-m-d H:i:s &#34;).$data);

        //send a message to exchange logs
        $channel-&gt;basic_publish($msg,$exchange_name,$routing_key);

        echo &#39; [x] Sent &#39;, $routing_key, &#39;:&#39;, $data, &#34;\n&#34;;

        //close channel, close connection
        $channel-&gt;close();
        $connection-&gt;close();
    }
</code></pre><p>过程：
(1). 创建连接，设置服务地址，端口，账号，vhost
(2). 使用连接创建信道
(3). 使用信道创建交换机，设置交换机类型为direct（根据routing_key转发消息）
(4). 创建消息,消息内容来自输入参数msg
(5). 使用信道向交换机发送消息，注意设置了routing_key
(6). 关闭信道，关闭连接</p>
<p>消费者C代码:</p>
<pre tabindex="0"><code>    public function subscribekMQ()
    {
        //create a connection
        $connection = new AMQPStreamConnection(&#39;172.16.166.130&#39;,&#39;5672&#39;,&#39;guest&#39;,&#39;guest&#39;,&#39;/&#39;);
        //create a channel
        $channel = $connection-&gt;channel();

        //create a exchange logs, type:fanout
        $exchange_name = &#39;direct_logs&#39;;
        $echange_type = &#39;direct&#39;;
        $channel-&gt;exchange_declare($exchange_name, $echange_type, false, false, false);

        //declare a temporary queue for us to send to;  the temporary queue is auto delete when the consumer disconnect
        list($queue_name, ,) = $channel-&gt;queue_declare(&#34;&#34;, false, false, true, false);

        $level = $this-&gt;option(&#39;level&#39;);
        $levels = [];
        if (empty($level)) {
            $levels = [&#39;info&#39;];
        }else{
            $levels = explode(&#39;,&#39;,$level);
        }
        //bind queue to exchange logs
        foreach ($levels as $routing_key) {
            $channel-&gt;queue_bind($queue_name,$exchange_name, $routing_key);
        }
                
        echo &#34; [*] Waiting for logs. To exit press CTRL+C\n&#34;;

        $callback = function ($msg) {
            echo &#39; [x] &#39;, $msg-&gt;delivery_info[&#39;routing_key&#39;], &#39;:&#39;, $msg-&gt;body, &#34;\n&#34;;
        };

        //create consume
        $channel-&gt;basic_consume($queue_name, &#39;&#39;, false, true, false, false, $callback);

        while($channel-&gt;is_consuming()){
            $channel-&gt;wait();
        }

        //close channel, close connection
        $channel-&gt;close();
        $connection-&gt;close();
    }
</code></pre><p>过程：
(1). 创建连接，设置服务地址，端口，账号，vhost
(2). 使用连接创建信道
(3). 使用信道创建交换机，设置交换机类型为direct（根据routing_key转发消息）
(4). 使用信道创建临时队列，队列名字设置为空，服务器会自动创建随机队列名称（大概类似：amq.gen-RAkn-INGuKex4JMNmoTZDA），一旦订阅消费者端口，临时队列会自动删除。返回队列名称$queue_name备用。
(5). 根据输入的routing_key绑定队列交换机，让发送到交换机的消息根据routing_key转发到队列
(6). 创建消费者监听队列，从队列中读取消息。
(7). 关闭信道，关闭连接</p>
<p>试着运行<code>php artisan consume:routing_mq --level=&quot;info,error,warnning&quot;</code>和<code>php artisan consume:routing_mq --level=&quot;info&quot;</code>，然后在生产者端输入不同的level看看，例如：
<code>php artisan produce:routing_mq --level=error --msg=&quot;error:test data&quot;</code>和<code>php artisan produce:routing_mq --level=info --msg=&quot;info:test data&quot;</code>.</p>
<h3 id="45-通配符模式">4.5 通配符模式</h3>
<p><img src="https://raw.githubusercontent.com/heyuan110/static-source/master/media/rabbitmq/15649775560253.jpg" alt=""></p>
<p>功能：生产者P发送的消息到交换机并指定routing_key，并设置类型为topic，消费者将队列绑定到交换机时根据routing_key的值进行通配符匹配。</p>
<p>生产者P代码:</p>
<pre tabindex="0"><code>//https://www.rabbitmq.com/tutorials/tutorial-five-php.html
public function publishMQ()
    {
        //create a connection
        $connection = new AMQPStreamConnection(&#39;172.16.166.130&#39;,&#39;5672&#39;,&#39;guest&#39;,&#39;guest&#39;,&#39;/&#39;);
        //create a channel
        $channel = $connection-&gt;channel();

        //create a exchange logs, type:topic
        $exchange_name = &#39;topic_logs&#39;;
        $echange_type = &#39;topic&#39;;
        $channel-&gt;exchange_declare($exchange_name, $echange_type, false, false, false);

        //get routing key
        $routing_key = $this-&gt;option(&#39;routing_key&#39;);
        if (empty($routing_key)) {
            $routing_key = &#34;anonymous.info&#34;;
        }

        //create a message, publish it to the queue
        $data = $this-&gt;option(&#39;msg&#39;);
        if (empty($data)) {
            $data = &#34;Hello World!&#34;;
        }
        $msg = new AMQPMessage(date(&#34;Y-m-d H:i:s &#34;).$data);

        //send a message to exchange logs
        $channel-&gt;basic_publish($msg,$exchange_name,$routing_key);

        echo &#39; [x] Sent &#39;, $routing_key, &#39;:&#39;, $data, &#34;\n&#34;;

        //close channel, close connection
        $channel-&gt;close();
        $connection-&gt;close();
    }
</code></pre><p>过程：
(1). 创建连接，设置服务地址，端口，账号，vhost
(2). 使用连接创建信道
(3). 使用信道创建交换机，设置交换机类型为topic（根据routing_key转发消息）,注意和4.4里类型不一样。
(4). 创建消息,消息内容来自输入参数msg
(5). 使用信道向交换机发送消息，注意设置了routing_key
(6). 关闭信道，关闭连接</p>
<p>消费者C代码:</p>
<pre tabindex="0"><code>    public function subscribekMQ()
    {
        //create a connection
        $connection = new AMQPStreamConnection(&#39;172.16.166.130&#39;,&#39;5672&#39;,&#39;guest&#39;,&#39;guest&#39;,&#39;/&#39;);
        //create a channel
        $channel = $connection-&gt;channel();

        //create a exchange logs, type:topic
        $exchange_name = &#39;topic_logs&#39;;
        $echange_type = &#39;topic&#39;;
        $channel-&gt;exchange_declare($exchange_name, $echange_type, false, false, false);

        //declare a temporary queue for us to send to;  the temporary queue is auto delete when the consumer disconnect
        list($queue_name, ,) = $channel-&gt;queue_declare(&#34;&#34;, false, false, true, false);

        $binding_key = $this-&gt;option(&#39;binding_key&#39;);
        $binding_keys = [];
        if (empty($binding_key)) {
            $binding_keys = [&#39;info&#39;];
        }else{
            $binding_keys = explode(&#39;,&#39;,$binding_key);
        }
        //bind queue to exchange logs
        foreach ($binding_keys as $binding_key) {
            $channel-&gt;queue_bind($queue_name,$exchange_name, $binding_key);
        }
                
        echo &#34; [*] Waiting for logs. To exit press CTRL+C\n&#34;;

        $callback = function ($msg) {
            echo &#39; [x] &#39;, $msg-&gt;delivery_info[&#39;routing_key&#39;], &#39;:&#39;, $msg-&gt;body, &#34;\n&#34;;
        };

        //create consume
        $channel-&gt;basic_consume($queue_name, &#39;&#39;, false, true, false, false, $callback);

        while($channel-&gt;is_consuming()){
            $channel-&gt;wait();
        }

        //close channel, close connection
        $channel-&gt;close();
        $connection-&gt;close();
    }
</code></pre><p>过程：
(1). 创建连接，设置服务地址，端口，账号，vhost
(2). 使用连接创建信道
(3). 使用信道创建交换机，设置交换机类型为topic（根据routing_key转发消息）
(4). 使用信道创建临时队列，队列名字设置为空，服务器会自动创建随机队列名称（大概类似：amq.gen-RAkn-INGuKex4JMNmoTZDA），一旦订阅消费者端口，临时队列会自动删除。返回队列名称$queue_name备用。
(5). 根据输入的routing_key规则绑定队列交换机，让发送到交换机的消息根据routing_key通配符规则转发到队列
(6). 创建消费者监听队列，从队列中读取消息。
(7). 关闭信道，关闭连接</p>
<p>{% alert info %}
通配符模式下生产者和消费者的routing_key通配符必须是.号分隔的单词列表，例如生产者的routing_key设置为lazy.white.rabbit，与消费者routing_key设置为lazy.*.rabbit的队列匹配。</p>
<p>替换规则（注意代替的是单词，不是字符）：</p>
<ul>
<li>*(星号)代替一个单词，</li>
<li>#(井号)代替零个或多个单词</li>
</ul>
<p>当topic的routing_key设置为一个&quot;#&ldquo;时，会接收所有消息，类似fanout交换机类型。
当topic的routing_key不包含通配符*或#时，类似direct交换机类型。
{% endalert %}</p>
<p>先运行消费者：</p>
<pre tabindex="0"><code>php artisan consume:topic_mq --binding_key=&#34;*.white.dog&#34;
php artisan consume:topic_mq --binding_key=&#34;test-key&#34;
php artisan consume:topic_mq --binding_key=&#34;lazy.*.rabbit&#34;
php artisan consume:topic_mq --binding_key=&#34;lazy.#&#34;
php artisan consume:topic_mq --binding_key=&#34;*&#34;
php artisan consume:topic_mq --binding_key=&#34;#&#34;
</code></pre><p>随后运行生产者观察消费者端输出</p>
<pre tabindex="0"><code>php artisan produce:topic_mq --routing_key=&#34;quick.red.fox&#34; --msg=&#34;test1&#34;
php artisan produce:topic_mq --routing_key=&#34;lazy.red.fox&#34; --msg=&#34;test2&#34;
php artisan produce:topic_mq --routing_key=&#34;lazy.red.fox.test&#34; --msg=&#34;test3&#34;
php artisan produce:topic_mq --routing_key=&#34;quick.white.dog&#34; --msg=&#34;test4&#34;
php artisan produce:topic_mq --routing_key=&#34;test-key&#34; --msg=&#34;test5&#34;
php artisan produce:topic_mq --routing_key=&#34;test&#34; --msg=&#34;test6&#34;
</code></pre><p>通过上面生产和消费消息演示，可以快速加深理解topic通配符模式。</p>
<h3 id="46-rpc模式">4.6 RPC模式</h3>
<p><img src="https://raw.githubusercontent.com/heyuan110/static-source/master/media/rabbitmq/15649775606069.jpg" alt=""></p>
<p>RPC工作过程：</p>
<ul>
<li>当客户端启动时，创建一个匿名的独占回调队列</li>
<li>对于RPC请求，客户端发送带有两个属性的消息,reply_to设置为回调队列，correlation_id设置为每个请求的唯一值。</li>
<li>请求发送到rpc_queue队列</li>
<li>RPC服务端获取到rpc_queue队列上的请求后，执行完成，将结果通过reply_to设置的队列返回给客户端</li>
<li>客户端收到消息后，检查消息的correlation_id属性，如果和请求中的值匹配，则将响应返回给应用程序。</li>
</ul>
<p>{% alert info %}
在AMQP0-9-1协议中消息带有14个属性，大多数很少使用，但下面几个需要了解：</p>
<ol>
<li><code>delivery_mode</code>：设置为2表示消息持久化，设置为1表示临时消息</li>
<li><code>content_type</code>: 消息类型，例如json格式的可设置为：<code>application / json</code></li>
<li><code>reply_to</code>: 通常用于命名回调队列</li>
<li><code>correlation_id</code>: 将RPC的请求和响应关联起来</li>
</ol>
<p>本节参考：<a href="https://www.rabbitmq.com/tutorials/tutorial-six-php.html">https://www.rabbitmq.com/tutorials/tutorial-six-php.html</a></p>
<p>{% endalert %}</p>
<p><a href="https://github.com/rabbitmq/rabbitmq-tutorials/blob/master/php/rpc_client.php">Client</a>和<a href="https://github.com/rabbitmq/rabbitmq-tutorials/blob/master/php/rpc_server.php">Server</a>代码查看。</p>
<h2 id="5-rabbitmq安装和集群配置">5. RabbitMQ安装和集群配置</h2>
<h3 id="51-docker安装">5.1 Docker安装</h3>
<p>适合本地学习，安装简单快速，执行：</p>
<p><code>docker run -d -p 5672:5672 -p 15672:15672 --name rabbitmq rabbitmq:management</code></p>
<p>rabbitmq:management的镜像200M左右，安装完成可以在浏览器访问http://ip:15672/,默认账号密码guest/guest</p>
<h3 id="52-本地安装">5.2 本地安装</h3>
<p>Ubuntu16.04安装Shell脚本install.sh</p>
<p>直接执行</p>
<pre tabindex="0"><code>sh -c &#34;$(curl -fsSL https://raw.githubusercontent.com/heyuan110/BashShell/master/rabbitmq_install.sh)&#34;
</code></pre><p>或者拷贝源码自己建立sh文件</p>
<pre tabindex="0"><code>#!/bin/sh

# Install RabbitMQ signing key
curl -fsSL https://github.com/rabbitmq/signing-keys/releases/download/2.0/rabbitmq-release-signing-key.asc | sudo apt-key add -

# Install apt HTTPS transport
sudo apt-get install apt-transport-https

# Add Bintray repositories that provision latest RabbitMQ and Erlang 21.x releases
sudo tee /etc/apt/sources.list.d/bintray.rabbitmq.list &lt;&lt;EOF
deb http://dl.bintray.com/rabbitmq-erlang/debian xenial erlang
deb https://dl.bintray.com/rabbitmq/debian xenial main
EOF

# Update package indices
sudo apt-get update -y

# Install rabbitmq-server and its dependencies
sudo apt-get install rabbitmq-server -y --fix-missing

# Start RabbitMQ Server
# sudo service rabbitmq-server start

# RabbitMQ Server Status
# sudo service rabbitmq-server status

# Stop RabbitMQ Server
# sudo service rabbitmq-server stop

# Restart RabbitMQ Server
# sudo service rabbitmq-server restart
</code></pre><p>执行<code>sh install.sh</code>等待安装完成。刚搭建好的rabbitmq server没有任何配置文件，增加配置文件<code>vi /etc/rabbitmq/rabbitmq.config</code>,输入下面内容:</p>
<pre tabindex="0"><code>[{rabbit, [{loopback_users, []}]}].
</code></pre><p>rabbitmq默认搭建好有一个用户名guest，密码guest的用户，但只能local访问。上面的配置开启guest可外部访问,配置完重启rabbitmq。</p>
<p>Rabbit主要脚本在<code>/usr/sbin/</code>目录下，执行<code>ll rabbit*</code>查看:</p>
<pre tabindex="0"><code>root@rmq2:/usr/sbin# ll rabbitmq*
-rwxr-xr-x 1 root root 3508 Jul 29 10:37 rabbitmq-diagnostics*
-rwxr-xr-x 1 root root 3508 Jul 29 10:37 rabbitmq-plugins*
-rwxr-xr-x 1 root root 3508 Jul 29 10:37 rabbitmq-server*
-rwxr-xr-x 1 root root 3508 Jul 29 10:37 rabbitmqctl*
</code></pre><p>分为交互，服务，插件几个命令。</p>
<p><strong>WEB管理插件</strong></p>
<p>为了方便管理，RabbitMQ官方提供了一套WEB界面，需要单独开启。</p>
<p>开启：<code>rabbitmq-plugins enable rabbitmq_management</code>
禁用：<code>rabbitmq-plugins disable rabbitmq_management</code></p>
<p>打开浏览器输入<a href="http://192.168.8.131:15672">http://192.168.8.131:15672</a>，输入guest/guest账号密码.
<img src="https://raw.githubusercontent.com/heyuan110/static-source/master/media/rabbitmq/15664687172489.jpg" alt=""></p>
<h3 id="53-用户管理">5.3 用户管理</h3>
<p>可以在WEB管理界面直接操作，也可以用下面的命令行操作。</p>
<h4 id="531-添加用户">5.3.1 添加用户</h4>
<p>格式：<code>rabbitmqctl add_user &lt;username&gt; &lt;newpassword&gt;</code>
例子：创建一个bruce用户，密码为123456，这时用户没有角色和权限。</p>
<pre tabindex="0"><code>rabbitmqctl add_user bruce 123456
</code></pre><h4 id="532-查看用户列表">5.3.2 查看用户列表</h4>
<p>格式：<code>rabbitmqctl list_users</code>
例子：</p>
<pre tabindex="0"><code>root@rmq1:/usr/sbin# rabbitmqctl list_users
Listing users ...
user	tags
bruce1	[administrator]
guest	[administrator]
bruce2	[administrator]
</code></pre><h4 id="533-修改密码">5.3.3 修改密码</h4>
<p>格式：<code>rabbitmqctl change_password &lt;username&gt; &lt;newpassword&gt;</code>
例子：修改bruce用户密码<code>rabbitmqctl  change_password  bruce 0123456</code></p>
<h4 id="534-删除用户">5.3.4 删除用户</h4>
<p>格式：<code>rabbitmqctl delete_user &lt;username&gt;</code>
例子：删除bruce用户<code>rabbitmqctl  delete_user bruce</code></p>
<h4 id="534-添加角色">5.3.4 添加角色</h4>
<p>格式：<code>rabbitmqctl set_user_tags &lt;username&gt; &lt;tag&gt;</code>
例子：设置bruce为管理员<code>rabbitmqctl set_user_tags bruce administrator</code></p>
<p>上面新创建的bruce用户没有用户角色，无法访问web插件等，按上面例子设置为管理员。rabbitmq用户角色分为五类：</p>
<ul>
<li>
<p>超级管理员(administrator)
可登陆管理控制台(启用management plugin的情况下)，可查看所有的信息，并且可以对用户，策略(policy)进行操作。</p>
</li>
<li>
<p>监控者(monitoring)
可登陆管理控制台(启用management plugin的情况下)，同时可以查看rabbitmq节点的相关信息(进程数，内存使用情况，磁盘使用情况等)</p>
</li>
<li>
<p>策略制定者(policymaker)
可登陆管理控制台(启用management plugin的情况下), 同时可以对policy进行管理。但无法查看节点的相关信息。</p>
</li>
<li>
<p>普通管理者(management)
仅可登陆管理控制台(启用management plugin的情况下)，无法看到节点信息，也无法对策略进行管理。</p>
</li>
<li>
<p>其他
无法登陆管理控制台，通常就是普通的生产者和消费者。</p>
</li>
</ul>
<h4 id="535-删除角色">5.3.5 删除角色</h4>
<p>格式：<code>rabbitmqctl clear_permissions [-p VHostPath] &lt;username&gt;</code>
例子：清除bruce的角色<code>rabbitmqctl  clear_permissions  -p /  bruce</code></p>
<h4 id="534-用户授权">5.3.4 用户授权</h4>
<p>格式：<code>rabbitmqctl set_permissions [-pvhostpath] {user} {conf} {write} {read}</code>
例子：上面bruce用户设置角色后没有赋予权限，这时bruce用户只能本地登录。赋予bruce用户对vhost/中所有资源的配置，写，读权限，方便管理其中资源。</p>
<pre tabindex="0"><code>rabbitmqctl set_permissions -p &#34;/&#34;bruce &#34;.*&#34; &#34;.*&#34; &#34;.*&#34;
</code></pre><h4 id="535-查看用户授权">5.3.5 查看用户授权</h4>
<p>格式：<code>rabbitmqctl list_permissions [-p VHostPath]</code>
例子：查看vhost / 下所有用户的权限</p>
<pre tabindex="0"><code>rabbitmqctl list_permissions -p /
</code></pre><h3 id="54-集群配置">5.4 集群配置</h3>
<p>RabbitMQ有三种模式，其中两种集群模式:</p>
<ul>
<li>
<p>单机模式：不做集群，单机运行。</p>
</li>
<li>
<p>普通模式：默认集群模式，集群的所有节点具有相同元数据(队列结构)，但消息实体只存在于集群中一个节点，当存消息实体的节点崩溃后消息不可用。举例rmq1，rmq2，rmq3三个节点，生产者先在rmq2上declare一个队列test_queue2，生产者连rmq1发布消息到集群的test_queue2队列，假设消费者连rmq3消费test_queue2，rmq1突然down掉，不影响消息消费，但如果rmq2 down掉，这时消费消息报错。这种架构的缺点很明显非高可用，如果保存实体消息的机器down掉不能恢复或未做持久化，消息就丢失。上面的例子实体消息存在rmq2，消费者连接的rmq3，消息怎么传递的呢？当消费者连接rmq3时，rabbitmq会临时在rmq2、rmq3间进行消息传输，rmq3再传递给消费者。</p>
</li>
</ul>
<p><img src="https://raw.githubusercontent.com/heyuan110/static-source/master/media/rabbitmq/15669015983876.jpg" alt=""></p>
<ul>
<li>镜像模式：把需要的队列做成镜像队列，元数据（queue结构）和实体数据（message）存在于多个节点，属于RabbitMQ的<a href="https://www.rabbitmq.com/ha.html">HA(Highly Available)</a>方案.与普通模式相比，消息实体会主动在镜像节点之间同步，而不是消费者拉取数据时临时传输。镜像队列是基于普通的集群模式的,所以还是得先配置普通集群,然后才能设置镜像队列。镜像队列设置后，会分一个主节点和多个从节点，如果主节点宕机，从节点会有一个选为主节点，原先的主节点起来后会变为从节点。queue和message虽然会存在所有镜像队列中，但客户端读取时不论物理面连接的主节点还是从节点，都是从主节点读取数据，然后主节点再将queue和message的状态同步给从节点，因此多个客户端连接不同的镜像队列不会产生同一message被多次接受的情况。</li>
</ul>
<h4 id="531-配置集群普通模式">5.3.1 配置集群普通模式</h4>
<ul>
<li>
<p>(1)准备环境
三台机器：rmq1,rmq2,rmq3，对应IP分别为：192.168.8.131、192.168.8.146、192.168.9.123
环境：Ubuntu16.04</p>
</li>
<li>
<p>(2)安装Rabbitmq
用上面<a href="#5-2_%E6%9C%AC%E5%9C%B0%E5%AE%89%E8%A3%85">5.2本地安装</a>的方法在每台机器安装好RabbitMQ，并确认可以运行。开启每一台的web管理插件，并只在rmq1上创建新用户bruce/123456，授予管理员角色和权限，后面rmq2，rmq3加入集群后直接同步rmq1的用户数据。</p>
</li>
<li>
<p>（3)统一集群节点cookie
Rabbitmq集群依赖erlang集群，而erlang集群式通过cookie进行通信认证，因此配置Rabbitmq集群第一步统一节点之间的cookie，默认cookie保存在文件<code>/var/lib/rabbitmq/.erlang.cookie</code>，400只读权限。
在rmq1上执行<code>cat /var/lib/rabbitmq/.erlang.cookie</code>查看cookie值，复制出来待用。
在rmq2上调整<code>.erlang.cookie</code>文件权限为可写入600,<code>sudo chmod 600 /var/lib/rabbitmq/.erlang.cookie</code>，然后编辑cookie值<code>vi /var/lib/rabbitmq/.erlang.cookie</code>，将rmq1上复制出来的cookie值粘贴进去，<code>:wq</code>保存退出。将cookie文件权限调整为只读400，<code>sudo chmod 400 /var/lib/rabbitmq/.erlang.cookie</code>,在rmq3上同样的操作。
然后重启rmq2,rmq3的rabbitmq，执行<code>sudo service rabbitmq-server restart</code>,
这时可以分别在3台机器查看rabbitmq集群状态,<code>rabbitmqctl cluster_status</code></p>
</li>
<li>
<p>（4)将三个节点组成集群
rabbitmq-server在启动时，会一起启动节点和应用，预先设置了rabbitmq应用为standalone模式。要将一个节点加入到现有的集群中，需要停止这个应用并将节点设置为原始状态，然后再加入集群。
组建集群的方式：将rmq2加入到rmq1,将rmq3加入到rmq1
{% alert warning %}
注意：rabbitmq集群要求节点之间可以连通，<code>rabbitmqctl join_cluster rabbit@rmq1</code>中<code>rabbit@rmq1</code>的rmq1指域名（我这里直接用的hostname)，这里它解析到当前节点本地IP.打开<code>vi /etc/hosts</code>查看域名与IP对应关系，例如我们这次创建的3个节点，应该有这样的对应关系在&rsquo;/etc/hosts&rsquo;文件里：
192.168.9.123       rmq3
192.168.8.146       rmq2
192.168.8.131       rmq1
{% endalert %}
首先再rmq2上执行<code>rabbitmqctl stop_app</code>停止应用
将rmq2加入到rmq1执行<code>/usr/sbin/rabbitmqctl join_cluster rabbit@rmq1</code>
启动rmq2节点应用执行<code>rabbitmqctl start_app</code>
这时rmq1和rmq2就组成一个集群了，在任意节点执行<code>rabbitmqctl cluster_status</code>可以查看集群状态：</p>
</li>
</ul>
<pre tabindex="0"><code>root@rmq2:/home/bruce# rabbitmqctl cluster_status
Cluster status of node rabbit@rmq2 ...
[{nodes,[{disc,[rabbit@rmq1,rabbit@rmq2]}]},
 {running_nodes,[rabbit@rmq1,rabbit@rmq2]},
 {cluster_name,&lt;&lt;&#34;test-rabbitmq-cluster&#34;&gt;&gt;},
 {partitions,[]},
 {alarms,[{rabbit@rmq1,[]},{rabbit@rmq2,[]}]}]
</code></pre><p>rmq1和rmq2在一个集群，rmq1上的用户信息也同步给rmq2了，我们可以在web管理界面上刷新看一看
<img src="https://raw.githubusercontent.com/heyuan110/static-source/master/media/rabbitmq/15670857248129.jpg" alt="">
依照上面的步骤添加rmq3到rmq1.至此我们可以写demo验证一下集群普通模式下的元数据和实体消息传递方式，试着让不同节点down掉看看。</p>
<h4 id="532-配置集群镜像模式">5.3.2 配置集群镜像模式</h4>
<p>前面对于镜像模式做了说明，我们配置好了集群普通模式情况下，给集群启用策略。只需要在集群中任意节点启用策略，策略会自动同步到集群其它节点：</p>
<p>设置策略命令格式：</p>
<pre tabindex="0"><code>set_policy [-p vhostpath] {name} {pattern} {definition} [priority]

解释：
-p Vhost： 可选参数，针对指定vhost下的queue进行设置
Name: policy的名称
Pattern: queue的匹配模式(正则表达式)
Definition：镜像定义，包括三个部分ha-mode, ha-params, ha-sync-mode
        ha-mode:指明镜像队列的模式，有效值为 all/exactly/nodes
        all：表示在集群中所有的节点上进行镜像
        exactly：表示在指定个数的节点上进行镜像，节点的个数由ha-params指定
        nodes：表示在指定的节点上进行镜像，节点名称通过ha-params指定
        ha-params：ha-mode模式需要用到的参数
        ha-sync-mode：进行队列中消息的同步方式，有效值为automatic和manual，默认manual
priority：可选参数，policy的优先级
</code></pre><p>在任意节点执行：<code>rabbitmqctl set_policy ha-all &quot;^&quot; '{&quot;ha-mode&quot;:&quot;all&quot;,&quot;ha-sync-mode&quot;:&quot;automatic&quot;}'</code>，“^” 表示所匹配所有队列名称,&quot;^test&quot;为匹配名称为test的exchanges或者queue。</p>
<p>镜像模式下集群重启时，最后一个挂掉的节点应该第一个重启，如果因特殊原因（比如同时断电），而不知道哪个节点最后一个挂掉。可用以下方法重启：</p>
<p>先在一个节点上执行</p>
<pre tabindex="0"><code>$ rabbitmqctl force_boot
$ sudo service rabbitmq-server start
</code></pre><p>在其他节点上执行</p>
<pre tabindex="0"><code>$ sudo service rabbitmq-server start
</code></pre><p>查看cluster状态是否正常（要在所有节点上查询）。</p>
<pre tabindex="0"><code>rabbitmqctl cluster_status
</code></pre><p>{% alert info %}
我查了官方资料没有找到怎么看谁是master节点谁是slave节点，有一个小技巧可以试试，
使用<code>rabbitmqctl list_queues name pid slave_pids synchronised_slave_pids</code>命令
，其中name是队列名字，pid为master节点，slave_pids返回的数组里都是从节点，synchronised_slave_pids是slave节点同步情况。举个例子，集群(HA)现在有三个队列：hello、hello2、hello3，hello和hello3里没有消息，hello2队列里有6条记录，按照上面的步骤给集群增加一个rmq4节点，镜像队列中默认消息不会主动同步到新节点，这时用上面命令查看可以看到结果:</p>
<p><img src="https://raw.githubusercontent.com/heyuan110/static-source/master/media/rabbitmq/15671540122491.jpg" alt=""></p>
<p>很明显hello2消息没有同步到rmq4.
{% endalert %}</p>
<h4 id="533-配置haproxy">5.3.3 配置HAProxy</h4>
<p>基于上面例子加入HAProxy后画一个整体拓扑图如下：
<img src="https://raw.githubusercontent.com/heyuan110/static-source/master/media/rabbitmq/15674979648150.jpg" alt=""></p>
<p>采用VMware ESXi虚拟出的4台服务器，HAProxy没开新机器，和rabbit@rmq1在一台上。四个节点中2个RAM，两个DISC（如果是3个节点建议2个DISC，1个RAM）。</p>
<p>HAProxy安装：<code>sudo apt-get install haproxy</code>,安装完成查看版本<code>haproxy -v</code>,打开haproxy配置文件<code>vi /etc/haproxy/haproxy.cfg</code>,</p>
<pre tabindex="0"><code>global
        log /dev/log    local0
        log /dev/log    local1 notice
        chroot /var/lib/haproxy
        stats socket /run/haproxy/admin.sock mode 660 level admin
        stats timeout 30s
        user haproxy
        group haproxy
        daemon

        # Default SSL material locations
        ca-base /etc/ssl/certs
        crt-base /etc/ssl/private

        # Default ciphers to use on SSL-enabled listening sockets.
        # For more information, see ciphers(1SSL). This list is from:
        #  https://hynek.me/articles/hardening-your-web-servers-ssl-ciphers/
        ssl-default-bind-ciphers ECDH+AESGCM:DH+AESGCM:ECDH+AES256:DH+AES256:ECDH+AES128:DH+AES:ECDH+3DES:DH+3DES:RSA+AESGCM:RSA+AES:RSA+3DES:!aNULL:!MD5:!DSS
        ssl-default-bind-options no-sslv3
        
defaults
        log     global
        mode    http
        option  httplog
        option  dontlognull
        timeout connect 5000
        timeout client  50000
        timeout server  50000
        errorfile 400 /etc/haproxy/errors/400.http
        errorfile 403 /etc/haproxy/errors/403.http
        errorfile 408 /etc/haproxy/errors/408.http
        errorfile 500 /etc/haproxy/errors/500.http
        errorfile 502 /etc/haproxy/errors/502.http
        errorfile 503 /etc/haproxy/errors/503.http
        errorfile 504 /etc/haproxy/errors/504.http

####################################################################
listen http_front
        bind 0.0.0.0:1080
        mode http
        stats refresh 30s
        stats uri /haproxy?stats
        stats realm Haproxy Manager
        stats auth admin:admin
        #stats hide-version

####################################################################
listen rabbitmq_admin
    bind 0.0.0.0:8004
    server node1 192.168.8.131:15672
    server node2 192.168.8.146:15672
    server node3 192.168.9.123:15672
    server node3 192.168.9.226:15672

####################################################################
listen rabbitmq_cluster
    bind 0.0.0.0:5678
    option tcplog
    mode tcp
    timeout client  3h
    timeout server  3h
    option          clitcpka
    balance roundrobin
    #balance url_param userid
    #balance url_param session_id check_post 64
    #balance hdr(User-Agent)
    #balance hdr(host)
    #balance hdr(Host) use_domain_only
    #balance rdp-cookie
    #balance leastconn
    #balance source //ip
    server   node1 192.168.8.131:5672 check inter 5s rise 2 fall 3
    server   node2 192.168.8.146:5672 check inter 5s rise 2 fall 3
    server   node3 192.168.9.123:5672 check inter 5s rise 2 fall 3
    server   node3 192.168.9.226:5672 check inter 5s rise 2 fall 3
</code></pre><p>保存重启HAProxy:<code>sudo service haproxy restart</code>。
打开HAProxy管理页面（账号密码admin/admin）：http://192.168.8.131:1080/haproxy?stats
打开RabbitMQ集群地址:http://192.168.8.131:8004
RabbitMQ集群服务地址:192.168.8.131:5678，可以写demo测试下。</p>
<h4 id="5331-配置aws-elb">5.3.3.1 配置AWS ELB</h4>
<p>如果生产环境使用AWS EC2搭建RabbitMQ集群，可以利用ELB做负载均衡,在TCP层做转发，选择网络负载均衡类型.</p>
<p><img src="https://raw.githubusercontent.com/heyuan110/static-source/master/media/rabbitmq/rabbitmq-elb-flow.png" alt=""></p>
<p>rabbitmq在生产环境部署，为了安全选择internal类型，不提供对外访问。选择TCP protocol，端口5672。注意选择可用区和子网，rabbitmq机器和elb可用区子网相同。</p>
<p>Target Group的health checks选择tcp，traffic port。</p>
<p>对搭建了rabbitmq的EC2赋予相关端口访问权限。
<img src="https://raw.githubusercontent.com/heyuan110/static-source/master/media/rabbitmq/E05FF76B-4A4C-4626-BFF1-E895E9FAA10D.png" alt=""></p>
<p>端口相关功能介绍参考<a href="https://www.rabbitmq.com/networking.html">https://www.rabbitmq.com/networking.html</a></p>
<h4 id="534-集群镜像队列中节点down机">5.3.4 集群镜像队列中节点down机</h4>
<p>当slave节点down掉，除了与slave已经连接的客户端中断，不会有其它影响。
当master节点down掉，会出现下面连锁反应：
(1)与master相连的客户端中断；
(2)选举最老的slave节点为master，因为最老的slave与前任master之间的同步状态应该是最好的。若此时所有slave处于未同步状态，则未同步消息会丢失
(3)新master节点requeue所有unack消息，因为新master节点无法区分这些unack消息是否已经到达客户端，或是ack消息丢失在老master链路上，或是丢失在master组播ack消息到所有slave节点的链路上。所以基于消息可靠性，会在新master上requeue所有unack的消息，造成的后果就是客户端可能会有重复消息（客户端处理消息最好考虑幂等性）。
(4)设置了<code>x-cancel-on-ha-failover</code>参数为true的客户端会收到Consumer Cancellation Notification通知。从镜像队列消费消息的客户端如果想要知道它们消费消息的队列是否failover（故障转移）,可以将<code>x-cancel-on-ha-failover</code>设置为true，当镜像队列发生failover后，关于message已被发送到哪个客户端的信息将丢失，所有未ack的message都会被requeue(也叫redelivered flag)后重新发送。如果不设置那么客户端就无法感知到master宕机，会一直等待。</p>
<p>从上面可以看出集群中存在镜像队列时，重选master节点有风险。</p>
<h4 id="535-集群镜像队列中节点启动顺序">5.3.5 集群镜像队列中节点启动顺序</h4>
<p>镜像队列中最后一个停止的节点会是master，启动顺序必须是master先启动，如果slave先启动，它会有30s的等待时间，等待master的启动，然后加入cluster中（如果30s内master没有启动，slave会自动停止）。当所有节点因故（断电等）同时离线时，每个节点都认为自己不是最后一个停止的节点。要恢复镜像队列，可以尝试在30s之内启动所有节点。</p>
<h2 id="6-rabbitmq问题集">6. RabbitMQ问题集</h2>
<h3 id="61-如何选择rabbitmq的节点类型">6.1 如何选择RabbitMQ的节点类型？</h3>
<p>RabbitMQ对queue中message的保存有两种方式：disc和ram。
如果采用disc，则需要对exchange／queue／delivery mode都要设置成durable模式。
使用disc方式的好处是当RabbitMQ失效了，message仍然可以在重启之后恢复；
使用ram方式，RabbitMQ处理message的效率要高很多，ram和disc两种方式的效率比大概是3:1。
所以如果在有其它HA手段保障的情况下，选用ram方式是可以提高消息队列的工作效率的。</p>
<p>将节点从disc类别切换成ram（反之相同）</p>
<pre tabindex="0"><code>rabbitmqctl stop_app
rabbitmqctl change_cluster_node_type ram
rabbitmqctl start_app
</code></pre><h3 id="62-消息发送的速率超过了rabbitmq的处理能力怎么办">6.2 消息发送的速率超过了RabbitMQ的处理能力怎么办？</h3>
<p>RabbitMQ会自动减慢这个连接的速率，让client端以为网络带宽变小了，发送消息的速率会受限，从而达到流控的目的。使用<code>rabbitmqctl list_connections</code>查看连接，如果状态为“flow”，则说明这个连接处于flow-control状态。</p>
<p><em>相关参考:</em>
<em><a href="https://www.rabbitmq.com/admin-guide.html">1.RabbitMQ Admin Guide</a></em>
<em><a href="https://www.jianshu.com/p/61a90fba1d2a?utm_campaign">2.RabbitMQ手册之rabbitmqctl</a></em>
<em><a href="https://www.jianshu.com/p/498c63e4ace1">3.Ubuntu16.04搭建Rabbitmq集群</a></em>
<em><a href="https://blog.csdn.net/qq_34039315/article/details/77619736">4.RabbitMQ+HAProxy构建高可用消息队列</a></em>
<em><a href="https://blog.csdn.net/u013256816/article/details/71097186">https://blog.csdn.net/u013256816/article/details/71097186</a></em></p>
]]></content>
		</item>
		
		<item>
			<title>消息队列中间件选型</title>
			<link>http://www.heyuan110.com/posts/middleware/2019-07-31-mq/</link>
			<pubDate>Wed, 31 Jul 2019 21:26:23 +0000</pubDate>
			
			<guid>http://www.heyuan110.com/posts/middleware/2019-07-31-mq/</guid>
			<description>“消息队列”是在消息的传输过程中保存消息的容器。消息队列管理器在将消息从它的源中继到它的目标时充当中间人。队列的主要目的是提供路由并保证消息的传递；如果发送消息时接收者不可用，消息队列会保留消息，直到可以成功地传递它。
一.消息队列是什么 维基百科的解释：
消息队列（英语：Message queue）是一种进程间通信或同一进程的不同线程间的通信方式，软件的贮列用来处理一系列的输入，通常是来自用户。消息队列提供了异步的通信协议，每一个贮列中的纪录包含详细说明的数据，包含发生的时间，输入设备的种类，以及特定的输入参数，也就是说：消息的发送者和接收者不需要同时与消息队列互交。消息会保存在队列中，直到接收者取回它。 ——维基百科 解释比较官方，来看一个最简单的架构模型：
Producer：消息生产者，负责产生和发送消息到Broker； Broker：消息处理中心，负责消息存储、确认、重试等，一般其中会包含多个queue； Consumer：消息消费者，负责从 Broker 中获取消息，并进行相应处理； 消息队列是分布式系统中重要组件，使用消息队列主要是通过异步处理提高系统性能和削峰、降低系统耦合性。
下面用一个故事来理解消息队列：
小Y是攻城狮，有一天产品经理告诉他需要实现这样一个需求：&amp;ldquo;用户下单成功，给用户发送一封确认邮件&amp;rdquo;.小Y快速确认了需求，很简单嘛，加几行代码就搞定！如是在下单后调用发送邮件代码，经过本地和alpha测试，功能顺利上线。
正常运行了几天，产品经理找到小Y说观察监控数据，发现下单处理时间过长影响了转化率，小Y思考了一下，原来发邮件代码是放在下单完成代码后单线程同步阻塞的方式执行，确实有问题，于是新起了一个线程发邮件，测试通过后立即上线，下单感觉确实更顺畅了。
可是没过多久客服收到很多用户反馈没收到邮件，产品经理和小Y一起熬夜分析想办法，最后找到负责开发邮件模块的同事，负责邮件的同事说：&amp;ldquo;不用搞那么复杂，我给你提供一个类似邮局信箱的东西，你往这信箱里写上你要发送的消息，以及我们约定的地址。之后你就不用再操心了，我们自然能从约定的地址中取得消息，进行邮件的相应操作&amp;rdquo;。小Y快速按照邮件同事的建议修改了代码，并测试重新上线。
小Y后来才知道这个就是消息队列，你只需要将你想发送的消息发送到队列里，不用知道具体服务在哪，怎么执行，对应的服务自然能监听到你的发送的消息并获取过来执行。
后来其他业务也把邮件发送更换成这种方式，随着消息量增多，大量消息堆积，需要增加更多消费者来处理队列里的消息，于是便有了分布式消息处理
二.为什么要用消息队列 当系统出现&amp;quot;生产&amp;quot;和&amp;quot;消费&amp;quot;的速度和稳定性不一致时，就需要消息队列，正是这个中间层弥合双方的差异。使用消息队列主要三个好处（六字）：解耦、异步、削峰。
1.解耦 场景：A更新数据，通知B,C更新，D等待接入。
传统架构:
传统架构下，A更新数据后分别调用B,C系统API，将更新的数据传过去，这种结构有下面的问题：(1)耦合性太强 (2)B,C系统故障，无法正确接收更新数据 (3)如果有D再接入，A又需要配合修改代码
引入消息队列中间件架构:
引入消息队列中间件的架构后，如果A更新了数据，只需要将消息发布到消息队列，B,C只要从消息队列订阅这条消息，D接入也只需自己去订阅，完全无需A做任何改动。
消息的发送方和接收方并不需要彼此联系，也不需要受对方的影响。
2.异步 同步模式下，整个任务完成要耗时120s
消息队列异步模式下耗时35s，B,C异步运行。 异步处理主要目的是减少请求响应时间，实现非核心流程异步化，提高系统响应性能。
3.削峰 **场景1：**A系统有10000条数据更新，需要发送给B,C系统
传统架构下，A系统调用B,C系统的接口发消息过去，B,C系统处理能力A是无法预估的，可能B,C系统流量洪峰，最后导致系统崩溃。
消息队列架构下，系统BCD可以按照自己处理能力消费队列里的消息，在流量高峰期短暂积压是被允许的。
**场景2：**每天0:00到12:00,A系统风平浪静,每秒并发请求数量50个.结果每次一到12:00~13:00,每秒并发请求数量突然会暴增到5k+条,A系统是直连mysql，假设mysql最大并发处理能力每秒2k，很明显这个时候mysql会被打死，导致系统崩溃，停止服务。但一过高峰期每秒请求量可能就50个，对系统毫无压力。如果使用消息队列，高峰期5k+每秒的请求先写入到消息队列，A系统每秒最多处理2k个请求，不超过自己最大处理能力，这样高峰期不会崩溃，由于这时消息数入大于出，就形成了高峰期短暂积压（百万消息堆积），高峰期过后，每秒就50个请求，A系统还是按照每秒2k处理，多出来的能力可以快速处理高峰期积压。
三.使用消息队列带来的问题 考虑在项目引入一项新技术，除了知道这项技术的优点，更重要是对弊端的了解，如果都没考虑过，就把技术引入，就给项目带来了潜在风险。上面我们列了消息队列的有点，来一起看看它的缺点。
1.降低系统可用性 系统可用性在某种程度上降低,在加入MQ之前，不用考虑消息丢失或者说MQ挂掉等等的情况，但是，引入MQ之后就需要去考虑.
2.增加系统复杂度 原来两个系统简单直接调API相互通讯，加入MQ后，消息传递链路加长，延时会增加，要考虑消息传递的可靠性（消息丢失怎么处理？），消息不被重复消费，数据一致性等问题。
四.什么时候用消息队列 1. 数据驱动的任务依赖 什么是任务依赖？举个例子：电商公司需要跑拣货单，在这之前可能需要同步订单，更新库存等，这些任务之间就存在一定依赖关系。下面是一个任务依赖示范图：
(1) Task3需要Task2输出作为输入 (2) Task2需要Task1输出作为输入
Task1,Task2,Task3就是任务依赖关系，必须先按照顺序Task1-&amp;gt;Task2-&amp;gt;Task3执行。类似的需求很多时候我们都是用cron人工排时间实现（预估每个task执行时间，然后留合适的间隔时间buffer）： (1) Task1 00：00执行，执行50分钟,Task1的buffer时间10分钟 (2) Task2 01：00执行，执行40分钟，Task2的buffer时间20分钟 (3) Task3 02：00执行，执行时间30分钟，依次类推
这种方式可能遇到的问题：
(1) 如果一个Task执行超出预期时间（例如随着样本数据增加，需要更长时间计算），后面的Task不清楚前面是否成功，此时需要手动重跑或调整时间安排。 (2) 需要预留很多buffer，总任务执行时间很长，后置任务不能再前置任务完成立即执行 (3) 如果一个任务被多个任务依赖，定时任务提现不出来，被改动后，依赖的任务容易出错 (4) 一个任务的时间调整，将有多个任务执行时间调整</description>
			<content type="html"><![CDATA[<p>“消息队列”是在消息的传输过程中保存消息的容器。消息队列管理器在将消息从它的源中继到它的目标时充当中间人。队列的主要目的是提供路由并保证消息的传递；如果发送消息时接收者不可用，消息队列会保留消息，直到可以成功地传递它。</p>
<h2 id="一消息队列是什么">一.消息队列是什么</h2>
<p>维基百科的解释：</p>
<pre tabindex="0"><code>消息队列（英语：Message queue）是一种进程间通信或同一进程的不同线程间的通信方式，软件的贮列用来处理一系列的输入，通常是来自用户。消息队列提供了异步的通信协议，每一个贮列中的纪录包含详细说明的数据，包含发生的时间，输入设备的种类，以及特定的输入参数，也就是说：消息的发送者和接收者不需要同时与消息队列互交。消息会保存在队列中，直到接收者取回它。 ——维基百科
</code></pre><p>解释比较官方，来看一个最简单的架构模型：</p>
<p><img src="https://raw.githubusercontent.com/heyuan110/static-source/master/media/mq/15631737310204.jpg" alt=""></p>
<ul>
<li>Producer：消息生产者，负责产生和发送消息到Broker；</li>
<li>Broker：消息处理中心，负责消息存储、确认、重试等，一般其中会包含多个queue；</li>
<li>Consumer：消息消费者，负责从 Broker 中获取消息，并进行相应处理；</li>
</ul>
<p>消息队列是分布式系统中重要组件，使用消息队列主要是通过异步处理提高系统性能和削峰、降低系统耦合性。</p>
<p>下面用一个故事来理解消息队列：</p>
<p>小Y是攻城狮，有一天产品经理告诉他需要实现这样一个需求：&ldquo;用户下单成功，给用户发送一封确认邮件&rdquo;.小Y快速确认了需求，很简单嘛，加几行代码就搞定！如是在下单后调用发送邮件代码，经过本地和alpha测试，功能顺利上线。</p>
<p>正常运行了几天，产品经理找到小Y说观察监控数据，发现下单处理时间过长影响了转化率，小Y思考了一下，原来发邮件代码是放在下单完成代码后单线程同步阻塞的方式执行，确实有问题，于是新起了一个线程发邮件，测试通过后立即上线，下单感觉确实更顺畅了。</p>
<p>可是没过多久客服收到很多用户反馈没收到邮件，产品经理和小Y一起熬夜分析想办法，最后找到负责开发邮件模块的同事，负责邮件的同事说：&ldquo;不用搞那么复杂，我给你提供一个类似邮局信箱的东西，你往这信箱里写上你要发送的消息，以及我们约定的地址。之后你就不用再操心了，我们自然能从约定的地址中取得消息，进行邮件的相应操作&rdquo;。小Y快速按照邮件同事的建议修改了代码，并测试重新上线。</p>
<p>小Y后来才知道这个就是消息队列，你只需要将你想发送的消息发送到队列里，不用知道具体服务在哪，怎么执行，对应的服务自然能监听到你的发送的消息并获取过来执行。</p>
<p>后来其他业务也把邮件发送更换成这种方式，随着消息量增多，大量消息堆积，需要增加更多消费者来处理队列里的消息，于是便有了<strong>分布式消息处理</strong></p>
<h2 id="二为什么要用消息队列">二.为什么要用消息队列</h2>
<p>当系统出现&quot;生产&quot;和&quot;消费&quot;的速度和稳定性不一致时，就需要消息队列，正是这个中间层弥合双方的差异。使用消息队列主要三个好处（六字）：解耦、异步、削峰。</p>
<h3 id="1解耦">1.解耦</h3>
<p>场景：A更新数据，通知B,C更新，D等待接入。</p>
<p><strong>传统架构:</strong></p>
<p><img src="https://raw.githubusercontent.com/heyuan110/static-source/master/media/mq/15635134432700.jpg" alt=""></p>
<p>传统架构下，A更新数据后分别调用B,C系统API，将更新的数据传过去，这种结构有下面的问题：(1)耦合性太强 (2)B,C系统故障，无法正确接收更新数据 (3)如果有D再接入，A又需要配合修改代码</p>
<p><strong>引入消息队列中间件架构:</strong></p>
<p><img src="https://raw.githubusercontent.com/heyuan110/static-source/master/media/mq/15635155317762.jpg" alt=""></p>
<p>引入消息队列中间件的架构后，如果A更新了数据，只需要将消息发布到消息队列，B,C只要从消息队列订阅这条消息，D接入也只需自己去订阅，完全无需A做任何改动。</p>
<p>消息的发送方和接收方并不需要彼此联系，也不需要受对方的影响。</p>
<h3 id="2异步">2.异步</h3>
<p><img src="https://raw.githubusercontent.com/heyuan110/static-source/master/media/mq/15635203510234.jpg" alt=""></p>
<p>同步模式下，整个任务完成要耗时120s</p>
<p><img src="https://raw.githubusercontent.com/heyuan110/static-source/master/media/mq/15635204998462.jpg" alt=""></p>
<p>消息队列异步模式下耗时35s，B,C异步运行。
异步处理主要目的是减少请求响应时间，实现非核心流程异步化，提高系统响应性能。</p>
<h3 id="3削峰">3.削峰</h3>
<p>**场景1：**A系统有10000条数据更新，需要发送给B,C系统</p>
<p><img src="https://raw.githubusercontent.com/heyuan110/static-source/master/media/mq/15635258383869.jpg" alt=""></p>
<p>传统架构下，A系统调用B,C系统的接口发消息过去，B,C系统处理能力A是无法预估的，可能B,C系统流量洪峰，最后导致系统崩溃。</p>
<p><img src="https://raw.githubusercontent.com/heyuan110/static-source/master/media/mq/15635285626855.jpg" alt=""></p>
<p>消息队列架构下，系统BCD可以按照自己处理能力消费队列里的消息，在流量高峰期短暂积压是被允许的。</p>
<p>**场景2：**每天0:00到12:00,A系统风平浪静,每秒并发请求数量50个.结果每次一到12:00~13:00,每秒并发请求数量突然会暴增到5k+条,A系统是直连mysql，假设mysql最大并发处理能力每秒2k，很明显这个时候mysql会被打死，导致系统崩溃，停止服务。但一过高峰期每秒请求量可能就50个，对系统毫无压力。如果使用消息队列，高峰期5k+每秒的请求先写入到消息队列，A系统每秒最多处理2k个请求，不超过自己最大处理能力，这样高峰期不会崩溃，由于这时消息数入大于出，就形成了高峰期短暂积压（百万消息堆积），高峰期过后，每秒就50个请求，A系统还是按照每秒2k处理，多出来的能力可以快速处理高峰期积压。</p>
<h2 id="三使用消息队列带来的问题">三.使用消息队列带来的问题</h2>
<p>考虑在项目引入一项新技术，除了知道这项技术的优点，更重要是对弊端的了解，如果都没考虑过，就把技术引入，就给项目带来了潜在风险。上面我们列了消息队列的有点，来一起看看它的缺点。</p>
<h3 id="1降低系统可用性">1.降低系统可用性</h3>
<p>系统可用性在某种程度上降低,在加入MQ之前，不用考虑消息丢失或者说MQ挂掉等等的情况，但是，引入MQ之后就需要去考虑.</p>
<h3 id="2增加系统复杂度">2.增加系统复杂度</h3>
<p>原来两个系统简单直接调API相互通讯，加入MQ后，消息传递链路加长，延时会增加，要考虑消息传递的可靠性（消息丢失怎么处理？），消息不被重复消费，数据一致性等问题。</p>
<h2 id="四什么时候用消息队列">四.什么时候用消息队列</h2>
<h3 id="1-数据驱动的任务依赖">1. 数据驱动的任务依赖</h3>
<p>什么是任务依赖？举个例子：电商公司需要跑拣货单，在这之前可能需要同步订单，更新库存等，这些任务之间就存在一定依赖关系。下面是一个任务依赖示范图：</p>
<p><img src="https://raw.githubusercontent.com/heyuan110/static-source/master/media/mq/15645537675518.jpg" alt=""></p>
<p>(1) Task3需要Task2输出作为输入
(2) Task2需要Task1输出作为输入</p>
<p>Task1,Task2,Task3就是任务依赖关系，必须先按照顺序Task1-&gt;Task2-&gt;Task3执行。类似的需求很多时候我们都是用cron人工排时间实现（预估每个task执行时间，然后留合适的间隔时间buffer）：
(1) Task1 00：00执行，执行50分钟,Task1的buffer时间10分钟
(2) Task2 01：00执行，执行40分钟，Task2的buffer时间20分钟
(3) Task3 02：00执行，执行时间30分钟，依次类推</p>
<p>这种方式可能遇到的问题：</p>
<p>(1) 如果一个Task执行超出预期时间（例如随着样本数据增加，需要更长时间计算），后面的Task不清楚前面是否成功，此时需要手动重跑或调整时间安排。
(2) 需要预留很多buffer，总任务执行时间很长，后置任务不能再前置任务完成立即执行
(3) 如果一个任务被多个任务依赖，定时任务提现不出来，被改动后，依赖的任务容易出错
(4) 一个任务的时间调整，将有多个任务执行时间调整</p>
<p>加入MQ优化后：</p>
<p><img src="https://raw.githubusercontent.com/heyuan110/static-source/master/media/mq/15645550907175.jpg" alt=""></p>
<p>(1)task1执行完成，发送消息X1到MQ,不需要预留buffer时间，上游执行完，立即发起通知
(2)task2订阅消息X1，收到消息后第一时间启动执行，执行完成发送消息X2,多个任务依赖只需要订阅相关消息即可，不关心依赖任务执行时间。
(3)task3以此类推。</p>
<p>注意MQ只用来传递上下游执行完成的消息，不传递真正的输入输出数据。</p>
<h3 id="2-上游不关心下游执行结果">2. 上游不关心下游执行结果</h3>
<p>上游任务完成不关心下游执行结果，例如下完订单给用户发送邮件，下单和发送邮件是两个任务，下完单后发消息到MQ，发送邮件任务收到消息开始发送邮件，至于发送成功还是失败，下单这个任务已经不关心。</p>
<h3 id="3-异步返回执行时间长">3. 异步返回执行时间长</h3>
<p>任务A执行时间长，完成后发消息给MQ,消息订阅方收到结果。例如微信付款流程，用户发起付款调用微信付款服务，是否是立即付款不确定，但发起付款方很在乎支付结果，这时可以让微信服务回调接口将支付结果发到MQ，发起方订阅MQ消息，这样微信付款完成发起方立即就收到结果通知。</p>
<h2 id="五如何选择消息队列">五.如何选择消息队列</h2>
<p>上面从优缺点，使用场景方面介绍了消息队列，我们可以看到消息队列是一个复杂的架构，引入它有很多好处，但也得针对它带来的问题做各种额外技术方案和架构来规避。市面上消息队列款式比较多，那么怎么选择呢？我找了目前使用较多的几个消息队列做对比。</p>
<p><img src="https://raw.githubusercontent.com/heyuan110/static-source/master/media/mq/15645670624965.jpg" alt=""></p>
<p>任何脱离业务实际的技术选型就是耍流氓，可根据团队技术栈，业务规模做出合适选择。对于中小型互联网公司，RabbitMQ是不错的选择，管理简单，社区活跃，文档多，兼容语言多。kafaka更多是给大数据领域准备。</p>
<p>相关文章：
<a href="http://www.heyuan110.com/2019-08-02-%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97-RabbitMQ.html">消息队列-RabbitMQ</a></p>
]]></content>
		</item>
		
		<item>
			<title>Nexus3构建Docker私服</title>
			<link>http://www.heyuan110.com/posts/docker/2019-06-12-next3-dockerhub/</link>
			<pubDate>Wed, 12 Jun 2019 20:50:36 +0000</pubDate>
			
			<guid>http://www.heyuan110.com/posts/docker/2019-06-12-next3-dockerhub/</guid>
			<description>Nexus是有名的Maven仓库管理器。如果你使用Maven，你可以从Maven中央仓库下载所需要的构件（artifact），但这通常不是一个好的做法，你应该在本地架设一个Maven仓库服务器，在代理远程仓库的同时维护本地仓库，以节省带宽和时间，Nexus就可以满足这样的需要。此外，他还提供了强大的仓库管理功能，构件搜索功能，它基于REST，友好的UI是一个extjs的REST客户端，它占用较少的内存，基于简单文件系统而非数据库。这些优点使其日趋成为最流行的Maven仓库管理器。除此之外，最新Nexus3还可以管理多种格式的镜像，如下：
1.环境 系统：ubuntu16.04 docker：18.02.0-ce
2.获取nexus3镜像 docker pull sonatype/nexus3
3.启动镜像 docker run -id --privileged=true --name=nexus3 --restart=always -p 9500:8081 -p 9501:9501 -p 9502:9502 -p 9503:9503 -v /usr/local/programs/nexus3/nexus-data:/nexus-data sonatype/nexus3:latest 端口(注意映射了多个端口)：
9500: nexus3网页端 9501：docker(hosted)私有仓库，可以pull和push 9502：docker(proxy)代理远程仓，只能pull 9503：docker(group)私有仓库和代理的组，只能pull 运维人员维护镜像试用9501端口，项目pull镜像使用9503端口，全部可匿名pull。
数据：在宿主机创建目录/usr/local/programs/nexus3/nexus-data，/nexus-data为docker容器数据存储目录。所以-v设置映射关系后数据将会存到宿主机/usr/local/programs/nexus3/nexus-data
4.配置私有仓库 访问http://localhost:9500默认账号admin/admin123
几种repository的类型
hosted，本地仓库，自己创建的镜像上传到这一类型的仓库。 proxy，代理仓库，它们被用来代理远程的公共仓库，如dockerhub官方仓库。 group，仓库组，用来合并多个hosted/proxy仓库，当你的项目希望在多个repository使用资源时就不需要多次引用了，只需要引用一个group即可。 创建仓库前先创建对应的blob stores，在创建仓库时选择对应的blob，创建group组时调整好优先级，一般是host高于proxy。
注意：创建仓库时如果勾选匿名可pull项，需找到security-&amp;gt;realms页面(http://localhost:9500/#admin/security/realms)，将docker bearer token realm项添加到右边激活，否则匿名docker pull会报错无权限.
5. 用户侧docker添加私有仓 mac和win 打开docker的设置，选择daemon，在insecure registries里添加
http://localhost:9503 如果是运维人员，要push镜像，再添加一条 http://localhost:9501
重启docker。
ubuntu 命令vi /etc/docker/daemon.json，插入下面内容:
{ &amp;#34;insecure-registries&amp;#34;: [ &amp;#34;http://localhost:9501&amp;#34;, &amp;#34;http://localhost:9503&amp;#34; ] } 执行sudo service docker restart重启docker。</description>
			<content type="html"><![CDATA[<p><a href="https://www.sonatype.com/nexus-repository-oss">Nexus</a>是有名的Maven仓库管理器。如果你使用Maven，你可以从Maven中央仓库下载所需要的构件（artifact），但这通常不是一个好的做法，你应该在本地架设一个Maven仓库服务器，在代理远程仓库的同时维护本地仓库，以节省带宽和时间，Nexus就可以满足这样的需要。此外，他还提供了强大的仓库管理功能，构件搜索功能，它基于REST，友好的UI是一个extjs的REST客户端，它占用较少的内存，基于简单文件系统而非数据库。这些优点使其日趋成为最流行的Maven仓库管理器。除此之外，最新Nexus3还可以管理多种格式的镜像<!-- raw HTML omitted -->，如下：</p>
<p><img src="https://raw.githubusercontent.com/heyuan110/static-source/master/media/15604059653679/15604059653679.jpg" alt=""></p>
<h2 id="1环境">1.环境</h2>
<p>系统：ubuntu16.04
docker：18.02.0-ce</p>
<h2 id="2获取nexus3镜像">2.获取nexus3镜像</h2>
<p><code>docker pull sonatype/nexus3</code></p>
<h2 id="3启动镜像">3.启动镜像</h2>
<pre tabindex="0"><code>docker run -id --privileged=true --name=nexus3 --restart=always -p 9500:8081 -p 9501:9501 -p 9502:9502 -p 9503:9503 -v /usr/local/programs/nexus3/nexus-data:/nexus-data sonatype/nexus3:latest
</code></pre><p>端口(注意映射了多个端口)：</p>
<ul>
<li>9500: nexus3网页端</li>
<li>9501：docker(hosted)私有仓库，可以pull和push</li>
<li>9502：docker(proxy)代理远程仓，只能pull</li>
<li>9503：docker(group)私有仓库和代理的组，只能pull</li>
</ul>
<p>运维人员维护镜像试用9501端口，项目pull镜像使用9503端口，全部可匿名pull。</p>
<p>数据：在宿主机创建目录/usr/local/programs/nexus3/nexus-data，/nexus-data为docker容器数据存储目录。所以-v设置映射关系后数据将会存到宿主机/usr/local/programs/nexus3/nexus-data</p>
<h2 id="4配置私有仓库">4.配置私有仓库</h2>
<p>访问<a href="http://localhost:9500">http://localhost:9500</a>默认账号admin/admin123</p>
<p>几种repository的类型</p>
<ul>
<li>hosted，本地仓库，自己创建的镜像上传到这一类型的仓库。</li>
<li>proxy，代理仓库，它们被用来代理远程的公共仓库，如dockerhub官方仓库。</li>
<li>group，仓库组，用来合并多个hosted/proxy仓库，当你的项目希望在多个repository使用资源时就不需要多次引用了，只需要引用一个group即可。</li>
</ul>
<p>创建仓库前先创建对应的blob stores，在创建仓库时选择对应的blob，创建group组时调整好优先级，一般是host高于proxy。</p>
<p><strong>注意</strong>：创建仓库时如果勾选匿名可pull项，需找到security-&gt;realms页面(<a href="http://localhost:9500/#admin/security/realms">http://localhost:9500/#admin/security/realms</a>)，将docker bearer token realm项添加到右边激活，否则匿名docker pull会报错无权限.</p>
<h2 id="5-用户侧docker添加私有仓">5. 用户侧docker添加私有仓</h2>
<h3 id="mac和win">mac和win</h3>
<p>打开docker的设置，选择daemon，在insecure registries里添加</p>
<pre tabindex="0"><code>http://localhost:9503
</code></pre><p>如果是运维人员，要push镜像，再添加一条 <code>http://localhost:9501</code></p>
<p>重启docker。</p>
<h3 id="ubuntu">ubuntu</h3>
<p>命令<code>vi /etc/docker/daemon.json</code>，插入下面内容:</p>
<pre tabindex="0"><code>{
    &#34;insecure-registries&#34;: [
        &#34;http://localhost:9501&#34;,
        &#34;http://localhost:9503&#34;
    ]
}
</code></pre><p>执行<code>sudo service docker restart</code>重启docker。</p>
<h2 id="6管理镜像">6.管理镜像</h2>
<h3 id="添加镜像">添加镜像</h3>
<p>先登录到localhost:9501私有仓，执行<code>docker login localhost:9501</code>登录，看到login success表示登录成功。</p>
<p>例如本地有一个php:7.0镜像,需推送到私有仓,步骤如下：</p>
<ol>
<li>
<p>用docker tag命令打一个新tag，<code>docker tag php:7.0 localhost:9501/php:7.0</code></p>
</li>
<li>
<p>推送：<code>docker push localhost:9501/php:7.0</code></p>
</li>
</ol>
<p>可以打开<a href="http://localhost:9500/#browse/browse">http://localhost:9500/#browse/browse</a>查看上传镜像。</p>
<h3 id="拉取镜像">拉取镜像</h3>
<p>从docker group端口9503拉取，例如：<code>docker pull localhost:9503/php:7.0</code></p>
<h3 id="搜索镜像">搜索镜像</h3>
<p>从docker group端口9503搜索，例如：<code>docker search localhost:9503/php:7.0</code>，会从docker group包含的仓库按照设置的优先级搜索。</p>
]]></content>
		</item>
		
		<item>
			<title>Docker学习笔记</title>
			<link>http://www.heyuan110.com/posts/docker/2019-05-13-learn-docker/</link>
			<pubDate>Mon, 13 May 2019 20:33:33 +0000</pubDate>
			
			<guid>http://www.heyuan110.com/posts/docker/2019-05-13-learn-docker/</guid>
			<description>Docker 是一个开源的应用容器引擎，基于 Go 语言 并遵从Apache2.0协议开源。Docker 可以让开发者打包他们的应用以及依赖包到一个轻量级、可移植的容器中，然后发布到任何流行的 Linux 机器上，也可以实现虚拟化。
1.Docker 包括三个基本概念 镜像(Image)
容器(Container)
仓库(Repository)
2.镜像(Image) Docker 镜像是一个特殊的文件系统，除了提供容器运行时所需的程序、库、资 源、配置等文件外，还包含了一些为运行时准备的一些配置参数(如匿名卷、环境 变量、用户等)。镜像不包含任何动态数据，其内容在构建之后也不会被改变。
镜像并非是像一个 ISO 那样的打包文件，镜像只是一个虚拟的概念，其 实际体现并非由一个文件组成，而是由一组文件系统组成，或者说，由多层文件系 统联合组成。
镜像构建时，会一层层构建，前一层是后一层的基础。每一层构建完就不会再发生改变，后一层上的任何改变只发生在自己这一层。在构建镜像的时候，需要额外小心，每一层尽量只包含该层需要添加的东西，任何额外的东西应该在该层构建结束前清理掉。
3.Docker 容器 镜像(Image)和容器(Container)的关系，就像是面向对象程序设计中的类和实例一样，镜像是静态的定义，容器是镜像运行时的实体。容器可以被 创建、启动、停止、删除、暂停等。
容器也是分层存储。每一个容器运行时，是以镜像为基础层，在其上创建一个当前容器的存储层，我们可以称这个为容器运行时读写而准备的存储层为容器存储层。
容器存储层的生存周期和容器一样，容器消亡时，容器存储层也随之消亡。因此，任何保存于容器存储层的信息都会随容器删除而丢失。容器不应该向其存储层内写入任何数据，容器存储 层要保持无状态化。所有的文件写入操作，都应该使用 数据卷(Volume)、或者 绑定宿主目录，在这些位置的读写会跳过容器存储层，直接对宿主(或网络存储)发 生读写，其性能和稳定性更高。
4.Docker Registry 镜像构建完成后，可以很容易的在当前宿主上运行，但是，如果需要在其它服务器 上使用这个镜像，我们就需要一个集中的存储、分发镜像的服务，Docker Registry 就是这样的服务。 一个 Docker Registry 中可以包含多个仓库(Repository);每个仓库可以包含多 个标签(Tag);每个标签对应一个镜像。
5. Docker commit docker commit 的语法格式为:
docker commit [选项] &amp;lt;容器ID或容器名&amp;gt; [&amp;lt;仓库名&amp;gt;[:&amp;lt;标签&amp;gt;]] 例如：
$ docker commit \ --author &amp;#34;Tao Wang &amp;lt;twang2218@gmail.com&amp;gt;&amp;#34; \ --message &amp;#34;修改了默认网页&amp;#34; \ webserver \ nginx:v2 sha256:07e33465974800ce65751acc279adc6ed2dc5ed4e0838f8b86f0c87aa 1795214 docker commit会让制作的image越来越臃肿，不方便追溯，所以一般不用来制作镜像。commit命令除了学习之外，还有一些特殊的应用场合，比如被入侵后保 存现场等。但是，不要使用 docker commit 定制镜像，定制行为应该使用Dockerfile 来完成</description>
			<content type="html"><![CDATA[<p>Docker 是一个开源的应用容器引擎，基于 Go 语言 并遵从Apache2.0协议开源。Docker 可以让开发者打包他们的应用以及依赖包到一个轻量级、可移植的容器中，然后发布到任何流行的 Linux 机器上，也可以实现虚拟化。</p>
<h2 id="1docker-包括三个基本概念">1.Docker 包括三个基本概念</h2>
<ul>
<li>
<p>镜像(Image)</p>
</li>
<li>
<p>容器(Container)</p>
</li>
<li>
<p>仓库(Repository)</p>
</li>
</ul>
<h2 id="2镜像image">2.镜像(Image)</h2>
<p>Docker 镜像是一个特殊的文件系统，除了提供容器运行时所需的程序、库、资 源、配置等文件外，还包含了一些为运行时准备的一些配置参数(如匿名卷、环境 变量、用户等)。镜像不包含任何动态数据，其内容在构建之后也不会被改变。</p>
<p>镜像并非是像一个 ISO 那样的打包文件，镜像只是一个虚拟的概念，其 实际体现并非由一个文件组成，而是由一组文件系统组成，或者说，由多层文件系 统联合组成。</p>
<p>镜像构建时，会一层层构建，前一层是后一层的基础。每一层构建完就不会再发生改变，后一层上的任何改变只发生在自己这一层。在构建镜像的时候，需要额外小心，每一层尽量只包含该层需要添加的东西，任何额外的东西应该在该层构建结束前清理掉。</p>
<h2 id="3docker-容器">3.Docker 容器</h2>
<p>镜像(Image)和容器(Container)的关系，就像是面向对象程序设计中的类和实例一样，镜像是静态的定义，容器是镜像运行时的实体。容器可以被 创建、启动、停止、删除、暂停等。</p>
<p>容器也是分层存储。每一个容器运行时，是以镜像为基础层，在其上创建一个当前容器的存储层，我们可以称这个为容器运行时读写而准备的存储层为容器存储层。</p>
<p>容器存储层的生存周期和容器一样，容器消亡时，容器存储层也随之消亡。因此，任何保存于容器存储层的信息都会随容器删除而丢失。容器不应该向其存储层内写入任何数据，容器存储 层要保持<strong>无状态化</strong>。所有的文件写入操作，都应该使用 数据卷(Volume)、或者 绑定宿主目录，在这些位置的读写会跳过容器存储层，直接对宿主(或网络存储)发 生读写，其性能和稳定性更高。</p>
<h2 id="4docker-registry">4.Docker Registry</h2>
<p>镜像构建完成后，可以很容易的在当前宿主上运行，但是，如果需要在其它服务器 上使用这个镜像，我们就需要一个集中的存储、分发镜像的服务，Docker Registry 就是这样的服务。
一个 Docker Registry 中可以包含多个仓库(Repository);每个仓库可以包含多 个标签(Tag);每个标签对应一个镜像。</p>
<h2 id="5-docker-commit">5. Docker commit</h2>
<p>docker commit 的语法格式为:</p>
<pre><code>docker commit [选项] &lt;容器ID或容器名&gt; [&lt;仓库名&gt;[:&lt;标签&gt;]]
</code></pre>
<p>例如：</p>
<pre tabindex="0"><code>$ docker commit \
--author &#34;Tao Wang &lt;twang2218@gmail.com&gt;&#34; \ --message &#34;修改了默认网页&#34; \
webserver \
nginx:v2
sha256:07e33465974800ce65751acc279adc6ed2dc5ed4e0838f8b86f0c87aa
1795214
</code></pre><p>docker commit会让制作的image越来越臃肿，不方便追溯，所以一般不用来制作镜像。commit命令除了学习之外，还有一些特殊的应用场合，比如被入侵后保 存现场等。但是，不要使用 docker commit 定制镜像，定制行为应该使用Dockerfile 来完成</p>
<h2 id="6-dockerfile">6. Dockerfile</h2>
<p>Dockerfile 是一个文本文件，其内包含了一条条的指令(Instruction)，每一条指令 构建一层(修改、安装、构建、操作)，因此每一条指令的内容，就是描述该层应当如何构建。</p>
<ul>
<li>FROM 指定基础镜像</li>
</ul>
<p>FROM就是指定基础镜像，因此一个 Dockerfile 中 FROM 是必备的指令，并 且必须是第一条指令。</p>
<p>FROM scratch 表示一个空白的镜像</p>
<ul>
<li>RUN 执行命令</li>
</ul>
<p>RUN 指令是用来执行命令行命令的。由于命令行的强大能力， RUN 指令在定制
镜像时是最常用的指令之一。其格式有两种:</p>
<p>shell 格式: <code>RUN &lt;命令&gt;</code>,就像直接在命令行中输入的命令一样, 例如</p>
<pre tabindex="0"><code>RUN echo &#39;&lt;h1&gt;Hello, Docker!&lt;/h1&gt;&#39; &gt; /usr/share/nginx/html/index
.html
</code></pre><p>exec 格式: <code>RUN [&quot;可执行文件&quot;, &quot;参数1&quot;, &quot;参数2&quot;] </code>,这更像是函数调用中 的格式。</p>
<p><strong>每个RUN都会产生一个新的层。撰写 Dockerfile 的时候，要经常提醒自 己，这并不是在写 Shell 脚本，而是在定义每一层该如何构建。</strong></p>
<p>为了格式化还进行了换行。Dockerfile 支持 Shell 类的行尾添加 \ 的 命令换行方式，以及行首 # 进行注释的格式。良好的格式，比如换行、缩进、注 释等，会让维护、排障更为容易</p>
<ul>
<li>构建镜像</li>
</ul>
<p>docker build 命令进行镜像构建。其格式为:</p>
<pre><code>docker build [选项] &lt;上下文路径/URL/-&gt;
</code></pre>
<p>例如进到Dockerfile文件所在目录执行: <code>docker build -t nginx:v3 .</code></p>
<ul>
<li>镜像构建上下文(Context)</li>
</ul>
<p>docker build 的工作原理：Docker 在运行时分为 Docker 引擎 (也就是服务端守护进程)和客户端工具。Docker 的引擎提供了一组 REST API， 被称为 Docker Remote API，而如 docker 命令这样的客户端工具，则是通过这组 API 与 Docker 引擎交互，从而完成各种功能。因此，虽然表面上我们好像是在 本机执行各种 docker 功能，但实际上，一切都是使用的远程调用形式在服务端 (Docker 引擎)完成。</p>
<p>当构建的时候，用户会指定构建镜像上下文的路径， docker build 命令得知这个路径后，会将路径下的所有内容打包，然后上 传给 Docker 引擎。这样 Docker 引擎收到这个上下文包后，展开就会获得构建镜 像所需的一切文件。</p>
<p>如果在 Dockerfile 中这么写:</p>
<pre><code>COPY ./package.json /app/
</code></pre>
<p>这并不是要复制执行<code>docker build</code>命令所在的目录下的 package.json ，不是复制Dockerfile所在目录下的package.json ，而是复制 上下文(context)目录下的package.json。</p>
<p><img src="https://raw.githubusercontent.com/heyuan110/static-source/master/media/15575697047773/15576404978427.jpg" alt=""></p>
<p>docker build还支持从git库，tar压缩包，标准输入等方式构建镜像。</p>
<ul>
<li>COPY 复制文件</li>
</ul>
<p>格式：<code>COPY &lt;源路径&gt;... &lt;目标路径&gt;</code> 和 <code> COPY [&quot;&lt;源路径1&gt;&quot;,... &quot;&lt;目标路径&gt;&quot;]</code></p>
<p>两种格式，一种类似于命令行，一种类似于函数调用。</p>
<p>COPY指令&lt;&gt;将从<strong>构建上下文目录</strong>中 &lt;源路径&gt; 的文件/目录复制到新的一层的镜像内的&lt;目标路径&gt;位置。比如:</p>
<pre><code> COPY package.json /usr/src/app/
</code></pre>
<p>&lt;源路径&gt;可以是单个也可以是多个，也可以是通配符，例如</p>
<pre tabindex="0"><code>COPY hom* /mydir/
COPY hom?.txt /mydir/
</code></pre><p>&lt;目标路径&gt; 可以是容器内的绝对路径，也可以是相对于工作目录的相对路径(工 作目录可以用 WORKDIR 指令来指定)。目标路径不需要事先创建，如果目录不存 在会在复制文件前先行创建缺失目录。</p>
<p>COPY 指令，源文件的各种元数据都会保留。比如 读、写、执行权限、文件变更时间等。</p>
<ul>
<li>ADD 更高级的复制文件</li>
</ul>
<p>ADD 指令和 COPY 的格式和性质基本一致。但是在 COPY 基础上增加了一些
功能。</p>
<ol>
<li>&lt;源路径&gt; 可以是一个 URL, Docker引擎会自动下载放到目标路径，权限600，如果要解压或修改权限需再用RUN增加一层处理</li>
<li>&lt;源路径&gt; 是tar/gzip/bzip2等压缩文件，ADD指令会自动解压文件到目标路径。如果真的希望是把压缩文件拷贝到目标路径，而不被自动解压，这时不能使用ADD</li>
</ol>
<p>ADD包含更复杂的功能。ADD指令会导致镜像构建缓存时效导致构建缓慢。
尽可能使用COPY，语义明确，就是复制。除非需要自动解压缩的场景才用ADD.</p>
<ul>
<li>CMD 容器启动命令</li>
</ul>
<p>Docker不是虚拟机，容器就是进程。既然是进程，那么在启动容器的时候，需要指定所运行的程序及参数。 CMD 指令就是用于指定默认的容器主进程的启动命令的。</p>
<p>Docker 不是虚拟机，容器中的应用都应该以前台执行，而不是像虚拟机、物理机 里面那样，用 upstart/systemd 去启动后台服务，容器内没有后台服务的概念。</p>
<p>CMD 指令的格式
<img src="https://raw.githubusercontent.com/heyuan110/static-source/master/media/15575697047773/15577263039629.jpg" alt=""></p>
<p>如果使用 shell 格式的话，实际的命令会被包装为 sh -c 的参数的形式进行 执行。</p>
<p>例如使用<code>CMD service nginx start</code>启动nginx服务会发现执行完成，容器立即就退出。是因为使用service nginx start命令，则是希望以后台守护进程形式启动nginx服务，而刚才说的<code>CMD service nginx start</code>会被理解为
会被理解为 CMD [&ldquo;sh&rdquo;, &ldquo;-c&rdquo;, &ldquo;service nginx start&rdquo;], 因此主进程实际上是sh。那么当命令结束后，sh也就结束了， sh作为主进程退出了，自然就会令容器退出。所以正确的做法应该是直接执行 nginx 可执行文件，并且要求以前台形式运行:<code>CMD [&quot;nginx&quot;, &quot;-g&quot;, &quot;daemon off;&quot;]</code></p>
<ul>
<li>ENTRYPOINT 入口点</li>
</ul>
<p>ENTRYPOINT和CMD一样都是在指定容器启动程序及参数，不过比CMD繁琐一点，需要通过docker run的参数<code>--entrypoint</code>来指定</p>
<p>当指定ENTRYPOINT后，CMD 的含义就发生了改变，不再是直接的运行其命令，而是将CMD做为内容传给ENTRYPOINT指令，实际执行时将变为：
<code>&lt;ENTRYPOINT&gt; &quot;&lt;CMD&gt;&quot;</code></p>
<p>既生亮何生瑜，为什么有了CMD又有ENTRYPOINT呢？</p>
<ol>
<li>ENTRYPOINT可以让镜像变成像命令一样使用
<img src="https://raw.githubusercontent.com/heyuan110/static-source/master/media/15575697047773/15577305262576.jpg" alt=""></li>
</ol>
<p>假如我们使用 docker build -t myip . 来构建镜像的话，如果我们需要查询当 前公网 IP，只需要执行:<code>docker run myip</code>
那如果要在后面加-I参数呢，用<code>docker run myip -I</code>会报错，因为跟在镜像后面的是command，运行时会替换默认command，显然单独一个-I无法运行。</p>
<p>那如果把CMD换成ENTRYPOINT会怎样呢</p>
<p><img src="https://raw.githubusercontent.com/heyuan110/static-source/master/media/15575697047773/15577306857517.jpg" alt=""></p>
<p>再执行<code>docker run myip -I</code>不会报错，因为当ENTRYPOINT存在后，CMD 的内容将会作为参数传给ENTRYPOINT ，而这里-I就是新的CMD.</p>
<ol start="2">
<li>ENTRYPOINT可以让应用运行前的准备工作</li>
</ol>
<p>启动容器就是启动主进程，但有些时候，启动主进程前，需要一些准备工作。</p>
<ul>
<li>ENV 设置环境变量</li>
</ul>
<p><img src="https://raw.githubusercontent.com/heyuan110/static-source/master/media/15575697047773/15577308032517.jpg" alt=""></p>
<p>设置环境变量而已，无论是后面的其它指令，如 RUN ，还 是运行时的应用，都可以直接使用这里定义的环境变量。</p>
<p>例如node镜像的dockerfile:</p>
<p><img src="https://raw.githubusercontent.com/heyuan110/static-source/master/media/15575697047773/15577391077696.jpg" alt=""></p>
<p>在这里先定义了环境变量 NODE_VERSION ，其后的 RUN 这层里，多次使用$NODE_VERSION 来进行操作定制。可以看到，将来升级镜像构建版本的时候，只
需要更新$NODE_VERSION即可，Dockerfile 构建维护变得更轻松了。</p>
<p><img src="https://raw.githubusercontent.com/heyuan110/static-source/master/media/15575697047773/15577398706795.jpg" alt=""></p>
<ul>
<li>ARG 构建参数</li>
</ul>
<p>格式： ARG &lt;参数名&gt;[=&lt;默认值&gt;]</p>
<p>构建参数和 ENV 的效果一样，都是设置环境变量。所不同的是， ARG 所设置的 构建环境的环境变量，在将来容器运行时是会存在这些环境变量的. 不要用来存密码，docker history可以查看到这些变量。</p>
<p>The ARG instruction defines a variable that users can pass at build-time to the builder with the docker build command using the &ndash;build-arg <!-- raw HTML omitted -->=<!-- raw HTML omitted --> flag.
ARG指令定义了用户可以在编译时或者运行时传递的变量，如使用如下命令：&ndash;build-arg <!-- raw HTML omitted -->=<!-- raw HTML omitted --></p>
<p>The ENV instruction sets the environment variable <!-- raw HTML omitted --> to the value <!-- raw HTML omitted -->. The environment variables set using ENV will persist when a container is run from the resulting image.
ENV指令是在dockerfile里面设置环境变量，不能在编译时或运行时传递。</p>
<ul>
<li>VOLUME 定义匿名卷</li>
</ul>
<p>格式为: <code> VOLUME [&quot;&lt;路径1&gt;&quot;, &quot;&lt;路径2&gt;&quot;...]</code> 或 <code> VOLUME &lt;路径&gt;</code></p>
<p>容器运行时应该尽量保持容器存储层不发生写操作，对于数据库类 需要保存动态数据的应用，其数据库文件应该保存于卷(volume)中。</p>
<p><code>VOLUME /data</code> 这里的 /data 目录就会在运行时自动挂载为匿名卷，任何向 /data 中写入的 信息都不会记录进容器存储层，从而保证了容器存储层的无状态化。</p>
<p>运行时 可以覆盖这个挂载设置。比如: <code> docker run -d -v mydata:/data xxxx</code>, 在这行命令中，就使用了 mydata 这个命名卷挂载到了 /data 这个位置，替代 了 Dockerfile 中定义的匿名卷的挂载配置。</p>
<ul>
<li>EXPOSE 声明端口</li>
</ul>
<p>格式为 EXPOSE &lt;端口1&gt; [&lt;端口2&gt;&hellip;]</p>
<p>EXPOSE 指令是声明运行时容器提供服务端口，这只是一个声明，在运行时并不 会因为这个声明应用就会开启这个端口的服务</p>
<p>要将 EXPOSE 和在运行时使用 -p &lt;宿主端口&gt;:&lt;容器端口&gt; 区分开来。 -p是映射宿主端口和容器端口，换句话说，就是将容器的对应端口服务公开给外界访问，而 EXPOSE 仅仅是声明容器打算使用什么端口而已，并不会自动在宿主进行 端口映射。</p>
<ul>
<li>WORKDIR 指定工作目录</li>
</ul>
<p>格式为 WORKDIR &lt;工作目录路径&gt; 。</p>
<p>使用 WORKDIR 指令可以来指定工作目录(或者称为当前目录)，以后各层的当前 目录就被改为指定的目录，如该目录不存在， WORKDIR 会帮你建立目录。</p>
<p>初学者常犯的错误是把 Dockerfile 等同于 Shell 脚本来书写，例如下面的错误：</p>
<pre tabindex="0"><code>RUN cd /app
RUN echo &#34;hello&#34; &gt; world.txt
</code></pre><p>如果将这个 Dockerfile 进行构建镜像运行后，会发现找不到 /app/world.txt 文 件，或者其内容不是 hello。原因其实很简单，在 Shell 中，连续两行是同一个 进程执行环境，因此前一个命令修改的内存状态，会直接影响后一个命令;而在 Dockerfile 中，这两行 RUN 命令的执行环境根本不同，是两个完全不同的容器（两个RUN在两个层）。</p>
<p>每一个RUN 都是启动一个容器、执行命令、然后提交存储层文件变更。
第一层 的执行仅仅是当前进程的工作目录变更，一个内存上的变 化而已，其结果不会造成任何文件变更。而到第二层的时候，启动的是一个全新的 容器，跟第一层的容器更完全没关系，自然不可能继承前一层构建过程中的内存变 化。</p>
<p>因此如果需要改变以后各层的工作目录的位置，那么应该使用 WORKDIR 指令。</p>
<ul>
<li>USER 指定当前用户</li>
</ul>
<p><img src="https://raw.githubusercontent.com/heyuan110/static-source/master/media/15575697047773/15577429025013.jpg" alt=""></p>
<ul>
<li>HEALTHCHECK 健康检查</li>
</ul>
<p><img src="https://raw.githubusercontent.com/heyuan110/static-source/master/media/15575697047773/15577489951500.jpg" alt=""></p>
<p>HEALTHCHECK指令告诉 Docker 应该如何进行判断容器的状态是否正常</p>
<p><img src="https://raw.githubusercontent.com/heyuan110/static-source/master/media/15575697047773/15577490221766.jpg" alt=""></p>
<p><img src="https://raw.githubusercontent.com/heyuan110/static-source/master/media/15575697047773/15577490365000.jpg" alt=""></p>
<p>命令的返回值决定了该次健康检查的成功与否，0成功，1失败，2保留。</p>
<ul>
<li>ONBUILD 为他人做嫁衣裳</li>
</ul>
<p>格式: ONBUILD &lt;其它指令&gt;</p>
<p>ONBUILD 是一个特殊的指令，它后面跟的是其它指令，比如 RUN , COPY 等， 而这些指令，在当前镜像构建时并不会被执行。只有当以当前镜像为基础镜像，去 构建下一级镜像的时候才会被执行。</p>
<h2 id="7-迁移镜像">7. 迁移镜像</h2>
<p>Docker 还提供了 docker load 和 docker save 命令，用以将镜像保存为一 个 tar 文件，然后传输到另一个位置上，再加载进来。</p>
<p>这个是在没有docker registry时的做法，现在已经不推荐（可用docker hub或私网registry），但在有些场景还是可以用。</p>
<ul>
<li>docker save导出镜像</li>
</ul>
<p>例如：<code> $ docker save alpine | gzip &gt; alpine-latest.tar.gz</code></p>
<p>把alpine镜像导出成 alpine-latest.tar.gz</p>
<ul>
<li>docker load导入镜像</li>
</ul>
<p>用命令<code>docker load -i alpine-latest.tar.gz</code>导入镜像</p>
<p>导出和导入结合ssh可以很好的做一些镜像迁移。</p>
<h2 id="8-删除镜像">8. 删除镜像</h2>
<p><code>docker rmi [选项] &lt;镜像1&gt; [&lt;镜像2&gt; ...]</code></p>
<p>注意 docker rm 命令是删除容器，不要混淆。</p>
<p>镜像删除行为分为两类，一 类是 Untagged ，另一类是 Deleted
镜像的唯一标识是其 ID 和摘要，而一个镜像可以有多个标签。</p>
<p>因此当我们使用上面命令删除镜像的时候，实际上是在要求删除某个标签的镜像。
所以首先需要做的是将满足我们要求的所有镜像标签都取消，这就是我们看到的
Untagged 的信息。因为一个镜像可以对应多个标签，因此当我们删除了所指定 的标签后，可能还有别的标签指向了这个镜像，如果是这种情况，那么 Delete 行为就不会发生。所以并非所有的 docker rmi 都会产生删除镜像的行为，有可 能仅仅是取消了某个标签而已。</p>
<p>当该镜像所有的标签都被取消了，该镜像很可能会失去了存在的意义，因此会触发 删除行为。镜像是多层存储结构，因此在删除的时候也是从上层向基础层方向依次 进行判断删除。镜像的多层结构让镜像复用变动非常容易，因此很有可能某个其它 镜像正依赖于当前镜像的某一层。这种情况，依旧不会触发删除该层的行为。直到 没有任何层依赖当前层时，才会真实的删除当前层。</p>
<p>除了镜像依赖以外，还需要注意的是容器对镜像的依赖。如果有用这个镜像启动的容器存在(即使容器没有运行)，那么同样不可以删除这个镜像。之前讲过，容器是以镜像为基础，再加一层容器存储层，组成这样的多层存储结构去运行的。因此该镜像如果被这个容器所依赖的，那么删除必然会导致故障。如果这些容器是不需
要的，应该先将它们删除，然后再来删除镜像。</p>
<ul>
<li>批量删除镜像</li>
</ul>
<p>可以使用 docker images -q 来配合使用 docker rmi ，这样可以成批的删除希望删除的镜像。</p>
<p>例子：</p>
<pre tabindex="0"><code>//删除悬空镜像
docker rmi $(docker images -q -f dangling=true)

//删除所有仓库名为 redis 的镜像
docker rmi $(docker images -q redis)

//删除所有在 mongo:3.2 之前的镜像
docker rmi $(docker images -q -f before=mongo:3.2)
</code></pre><h2 id="9-操作docker容器">9. 操作docker容器</h2>
<ul>
<li>docker run启动容器</li>
</ul>
<p>当利用 docker run 来创建容器时，Docker 在后台运行的标准操作包括:</p>
<p>a. 检查本地是否存在指定的镜像，不存在就从公有仓库下载
b. 利用镜像创建并启动一个容器
c. 分配一个文件系统，并在只读的镜像层外面挂载一层可读写层
d. 从宿主主机配置的网桥接口中桥接一个虚拟接口到容器中去
e. 从地址池配置一个 ip 地址给容器
f. 执行用户指定的应用程序
g. 执行完毕后容器被终止</p>
<p>例如：<code> sudo docker run -t -i ubuntu:14.04 /bin/bash</code></p>
<p>其中， -t 选项让Docker分配一个伪终端(pseudo-tty)并绑定到容器的标准输入 上，   -i 则让容器的标准输入保持打开。</p>
<p>加一个-d参数后台运行,例如; <code>sudo docker run -d ubuntu:14.04 </code></p>
<ul>
<li>docker logs查看容器日志</li>
</ul>
<p>格式：<code>docker logs [container ID or NAMES]</code></p>
<ul>
<li>docker start</li>
</ul>
<p>启动已经停止的容器</p>
<ul>
<li>docker stop</li>
</ul>
<p>停止容器</p>
<ul>
<li>docker restart</li>
</ul>
<p>重启容器</p>
<ul>
<li>导出容器</li>
</ul>
<p><img src="https://raw.githubusercontent.com/heyuan110/static-source/master/media/15575697047773/15579916274906.jpg" alt=""></p>
<ul>
<li>导入容器快照</li>
</ul>
<p>可以使用 docker import 从容器快照文件中再导入为镜像，例如</p>
<pre tabindex="0"><code>$ cat ubuntu.tar | sudo docker import - test/ubuntu:v1.0
$ sudo docker images
REPOSITORY          TAG                 IMAGE ID            CREA
TED              VIRTUAL SIZE
test/ubuntu         v1.0                9d37a6082e97        Abou
t a minute ago   171.3 MB
</code></pre><p>注:用户既可以使用 docker load 来导入镜像存储文件到本地镜像库，也可以 使用 docker import来导入一个容器快照到本地镜像库。这两者的区别在于容 器快照文件将丢弃所有的历史记录和元数据信息(即仅保存容器当时的快照状 态)，而镜像存储文件将保存完整记录，体积也要大。此外，从容器快照文件导入 时可以重新指定标签等元数据信息。</p>
<ul>
<li>删除容器</li>
</ul>
<p>docker rm</p>
<ul>
<li>清理所有处于终止状态的容器</li>
</ul>
<p><code>docker rm $(docker ps -a -q)</code></p>
<h2 id="10-仓库">10. 仓库</h2>
<ul>
<li>官方仓库<a href="https://hub.docker.com/">docker hub</a></li>
</ul>
<p>docker search xx
docker pull xx</p>
<ul>
<li>私有仓库</li>
</ul>
<p>创建私有仓库<code>docker run --name=myregistry -d -p 8085:5000 -v /usr/local/programs/docker/myregistry:/var/lib registry</code></p>
<p>标记镜像<code>docker tag</code>，然后推送到私有仓库,例如：</p>
<pre tabindex="0"><code>//打tag，xxxxxx是镜像id或名称
docker tag xxxxxx 172.16.166.130:8085/test_nginx

//推送到私有仓库
docker push 172.16.166.130:8085/test_nginx
</code></pre><p>查看私有仓库镜像: <code>curl http://172.16.166.130:8085/v2/_catalog</code></p>
<p>到一台新机器pull私有仓库镜像：<code>docker pull 172.16.166.130:8085/test_nginx</code>，
注意在pull前请将http://172.16.166.130:8085地址添加到docker配置文件里。ubuntu配置(/etc/docker/daemon.json)格式：</p>
<pre tabindex="0"><code>{
    &#34;insecure-registries&#34;: [
        &#34;172.16.166.130:8085&#34;
    ]
}
</code></pre><h2 id="11-数据卷">11. 数据卷</h2>
<p>数据卷是一个可供一个或多个容器使用的特殊目录，它绕过 UFS，可以提供很多有 用的特性:</p>
<pre><code>- 数据卷可以在容器之间共享和重用
- 对数据卷的修改会立马生效
- 对数据卷的更新，不会影响镜像
- 数据卷默认会一直存在，即使容器被删除
</code></pre>
<ul>
<li>创建数据卷</li>
</ul>
<p>在用 docker run 命令的时候，使用 -v 标记来创建一个数据卷并挂载到容器 里。在一次 run 中多次使用可以挂载多个数据卷。例如 <code>docker run -d -P --name web -v /webapp training/webapp</code></p>
<p>也可以在 Dockerfile 中使用 VOLUME 来添加一个或者多个新的卷到由该镜 像创建的任意容器。</p>
<ul>
<li>挂载一个主机目录作为数据卷</li>
</ul>
<p>使用 -v 标记也可以指定挂载一个本地主机的目录到容器中去, 例如：</p>
<p><code>docker run -d -P --name web -v /src/webapp:/opt/webapp training/webapp python app.py</code></p>
<p>上面的命令加载主机的 /src/webapp 目录到容器的 /opt/webapp 目录,
主机本地目录的路径必须是绝对路径，如果目录不存在 Docker 会自动为你创建它。
注意:Dockerfile 中不支持这种用法，这是因为 Dockerfile 是为了移植和分享用 的。然而，不同操作系统的路径格式不一样，所以目前还不能支持。</p>
<p>Docker 挂载数据卷的默认权限是读写，用户也可以通过 :ro 指定为只读。</p>
<p><code>docker run -d -P --name web -v /src/webapp:/opt/webapp:ro training/webapp python app.py</code></p>
<p>加了 :ro 之后，就挂载为只读了。</p>
<ul>
<li>查看数据卷的具体信息</li>
</ul>
<p><code>docker inspect web</code></p>
<ul>
<li>挂载一个本地主机文件作为数据卷</li>
</ul>
<p>-v 标记也可以从主机挂载单个文件到容器中,例如：</p>
<p><code>docker run --rm -it -v ~/.bash_history:/.bash_history ubuntu /bin/bash</code></p>
<p>这样就可以记录在容器输入过的命令了。注意:如果直接挂载一个文件，很多文件编辑工具，包括 vi 或者 sed &ndash;in- place ，可能会造成文件 inode 的改变，从 Docker 1.1 .0起，这会导致报错误信 息。所以最简单的办法就直接挂载文件的父目录。</p>
<h2 id="12-数据卷容器">12. 数据卷容器</h2>
<p>如果你有一些持续更新的数据需要在容器之间共享，最好创建数据卷容器。 数据卷容器，其实就是一个正常的容器，专门用来提供数据卷供其它容器挂载的。</p>
<p>使用<code>--volumes-from</code>挂载容器中的数据卷，例如：</p>
<p>先创建一个数据卷容器：</p>
<p><code>docker run -d -v /dbdata --name dbdata training/postgres</code></p>
<p>然后把dbdata容器挂载到另外一个容器:</p>
<p><code>docker run -d --volumes-from dbdata --name db1 training/p ostgres</code></p>
<p>如果删除了挂载的容器(包括 dbdata、db1 和 db2)，数据卷并不会被自动删除。 如果要删除一个数据卷，必须在删除最后一个还挂载着它的容器时使用 docker rm -v 命令来指定同时删除关联的容器。</p>
<ul>
<li>备份</li>
</ul>
<p>首先使用 &ndash;volumes-from 标记来创建一个加载 dbdata 容器卷的容器，并从主 机挂载当前目录到容器的 /backup 目录。命令如下:</p>
<p><code>docker run --volumes-from dbdata -v $(pwd):/backup ubuntu tar cvf /backup/backup.tar /dbdata</code></p>
<p>容器启动后，使用了 tar 命令来将 dbdata 卷备份为容器中 /backup/backup.tar 文件，也就是主机当前目录下的名为 backup.tar 的文件。</p>
<ul>
<li>恢复</li>
</ul>
<p>如果要恢复数据到一个容器，首先创建一个带有空数据卷的容器 dbdata2。</p>
<p><code>docker run --volumes-from dbdata2 busybox /bin/ls /dbdata</code></p>
<h2 id="13-网络">13. 网络</h2>
<h3 id="131-映射端口">13.1 映射端口</h3>
<p>容器中可以运行一些网络应用，要让外部也可以访问这些应用，可以通过 -P 或
-p 参数来指定端口映射。</p>
<p>当使用 -P 标记时，Docker 会随机映射一个 49000~49900 的端口到内部容器开
放的网络端口。</p>
<p>例如: <code>docker run -d -P nginx</code></p>
<p>当使用-p标记时，要指定主机端口和容器端口</p>
<p>例如: <code>docker run -d -p 8081:80 nginx</code></p>
<p>将容器的80端口映射到主机的8081端口</p>
<p>使用<code>docker logs -f 容器名</code>可以查看容器日志.</p>
<ul>
<li>映射到指定地址的指定端口</li>
</ul>
<p>格式：<code>ip:hostPort:containerPort</code>，例如:<code>docker run -d -p 127.0.0.1:5000:5000 training/webapp python app.py</code></p>
<ul>
<li>映射到指定地址的任意端口</li>
</ul>
<p>格式：ip::containerPort，例如绑定 localhost 的任意端口到容器的 5000 端口，本地 主机会自动分配一个端口。</p>
<p><code>run -d -p 127.0.0.1::5000 training/webapp python app.py</code></p>
<p>还可以使用 udp 标记来指定 udp 端口：<code>docker run -d -p 127.0.0.1:5000:5000/udp training/webapp python app.py</code></p>
<ul>
<li>查看映射端口配置</li>
</ul>
<p><code>docker port 容器名</code></p>
<p>注意:
a. 容器有自己的内部网络和 ip 地址(使用 docker inspect 可以获取所有的 变量，Docker 还可以有一个可变的网络配置。)
b. -p 标记可以多次使用来绑定多个端口</p>
<p>例如：<code>docker run -d -p 5000:5000  -p 3000:80 training/webapp py thon app.py</code></p>
<ul>
<li>容器互联</li>
</ul>
<p>容器的连接(linking)系统是除了端口映射外，另一种跟容器中应用交互的方式。
该系统会在源和接收容器之间创建一个隧道，接收容器可以看到源容器指定的信
息。</p>
<p>是用&ndash;name参数命名容器，例如: <code>docker run -d -P --name web training/webapp</code></p>
<p>可以用<code>docker ps -l</code>或<code>docker inspect</code>查看容器名称</p>
<p>注意:容器的名称是唯一的。如果已经命名了一个叫 web 的容器，当你要再次使用 web 这个名称的时候，需要先用 docker rm 来删除之前创建的同名容器。</p>
<p>在执行 的时候如果添加 &ndash;rm 标记，则容器在终止后会立刻删 除。注意,&ndash;rm和-d参数不能同时使用。</p>
<p>使用 &ndash;link 参数可以让容器之间安全的进行交互。&ndash;link参数的格式为 &ndash;link name:alias ，其中 name 是要链接的容器的 名称，alias是这个连接的别名。例如：</p>
<p>首先创建一个数据库容器: <code>docker run -d --name db training/postgres</code>
再创建一个web容器：<code>docker run -d -P --name web --link db:db training/webapp python app.py</code></p>
<p>这样web和db两个容器就关联了。</p>
<p>Docker 在两个互联的容器之间创建了一个安全隧道，而且不用映射它们的端口到 宿主主机上。在启动 db 容器的时候并没有使用 -p 和 -P 标记，从而避免了暴 露数据库端口到外部网络上。</p>
<p>Docker 通过 2 种方式为容器公开连接信息: 环境变量和更新 /etc/hosts 文件 ，例如</p>
<p>查看一下web2关联db后的环境变量,执行<code>docker run --rm --name web2 --link db:db training/webapp env</code> 结果:</p>
<pre tabindex="0"><code>PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin
HOSTNAME=8aa5fc9a8c74
DB_PORT=tcp://172.17.0.9:5432
DB_PORT_5432_TCP=tcp://172.17.0.9:5432
DB_PORT_5432_TCP_ADDR=172.17.0.9
DB_PORT_5432_TCP_PORT=5432
DB_PORT_5432_TCP_PROTO=tcp
DB_NAME=/web2/db
DB_ENV_PG_VERSION=9.3
HOME=/root
</code></pre><p>其中 DB_ 开头的环境变量是供 web 容器连接 db 容器使用，前缀采用大写的连接 别名。</p>
<p>查看一下web2的/etc/hosts文件，执行<code>docker run -t -i --rm --link db:db training/webapp /bin/bash</code>，进入后执行<code>cat /etc/hosts</code>结果：</p>
<pre tabindex="0"><code>127.0.0.1	localhost
::1	localhost ip6-localhost ip6-loopback
fe00::0	ip6-localnet
ff00::0	ip6-mcastprefix
ff02::1	ip6-allnodes
ff02::2	ip6-allrouters
172.17.0.9	db 79e00cc81a64
172.17.0.11	9edb693775f6
</code></pre><p>域名db解析到了172.17.0.9，我们执行下ping命令：</p>
<pre tabindex="0"><code>root@9edb693775f6:/opt/webapp# ping db
PING db (172.17.0.9) 56(84) bytes of data.
64 bytes from db (172.17.0.9): icmp_seq=1 ttl=64 time=0.195 ms
64 bytes from db (172.17.0.9): icmp_seq=2 ttl=64 time=0.077 ms
64 bytes from db (172.17.0.9): icmp_seq=3 ttl=64 time=0.097 ms
64 bytes from db (172.17.0.9): icmp_seq=4 ttl=64 time=0.064 ms
64 bytes from db (172.17.0.9): icmp_seq=5 ttl=64 time=0.059 ms
64 bytes from db (172.17.0.9): icmp_seq=6 ttl=64 time=0.078 ms
64 bytes from db (172.17.0.9): icmp_seq=7 ttl=64 time=0.084 ms
64 bytes from db (172.17.0.9): icmp_seq=8 ttl=64 time=0.089 ms
64 bytes from db (172.17.0.9): icmp_seq=9 ttl=64 time=0.074 ms
64 bytes from db (172.17.0.9): icmp_seq=10 ttl=64 time=0.074 ms
64 bytes from db (172.17.0.9): icmp_seq=11 ttl=64 time=0.059 ms
64 bytes from db (172.17.0.9): icmp_seq=12 ttl=64 time=0.098 ms
64 bytes from db (172.17.0.9): icmp_seq=13 ttl=64 time=0.061 ms
64 bytes from db (172.17.0.9): icmp_seq=14 ttl=64 time=0.074 ms
</code></pre><p>用 ping 来测试db容器，它会解析成 172.17.0.5 。</p>
<p><em>注意:官方的 ubuntu 镜像 默认没有安装 ping，需要自行安装。</em></p>
<h3 id="132-高级网络配置">13.2 高级网络配置</h3>
<p>当 Docker 启动时，会自动在主机上创建一个 docker0 虚拟网桥，实际上是 Linux 的一个 bridge，可以理解为一个软件交换机。它会在挂载到它的网口之间进 行转发。</p>
<p><img src="https://raw.githubusercontent.com/heyuan110/static-source/master/media/15575697047773/15580787948502.jpg" alt=""></p>
<p><img src="https://raw.githubusercontent.com/heyuan110/static-source/master/media/15575697047773/15580788457994.jpg" alt=""></p>
<p>从网络架构的角度来看，所有的容器通过本地主机的网桥接口相互通信，就像物理机器通过物理交换机通信一样。</p>
<p>一些要熟悉的概念：</p>
<p><img src="https://raw.githubusercontent.com/heyuan110/static-source/master/media/15575697047773/15580795828187.jpg" alt=""></p>
<h2 id="14-docker基本架构">14. Docker基本架构</h2>
<p><img src="https://raw.githubusercontent.com/heyuan110/static-source/master/media/15575697047773/15580802323092.jpg" alt=""></p>
<p>Docker 采用了 C/S架构，包括客户端和服务端。 Docker daemon 作为服务端接受 来自客户的请求，并处理这些请求(创建、运行、分发容器)。 客户端和服务端既 可以运行在一个机器上，也可通过 socket 或者 RESTful API 来进行通信。</p>
]]></content>
		</item>
		
		<item>
			<title>Shell脚本中$符开头变量解释</title>
			<link>http://www.heyuan110.com/posts/linux/2019-05-13-linux-shell-vars/</link>
			<pubDate>Mon, 13 May 2019 20:16:54 +0000</pubDate>
			
			<guid>http://www.heyuan110.com/posts/linux/2019-05-13-linux-shell-vars/</guid>
			<description>shell脚本中经常会看到$开头的特殊变量，那怎么理解它们呢？
变量 $$ Shell本身的PID（ProcessID）
$! Shell最后运行的后台Process的PID
$? 最后运行的命令的结束代码（返回值）
$- 使用Set命令设定的Flag一览
$* 所有参数列表。如&amp;quot;$*&amp;ldquo;用「&amp;quot;」括起来的情况、以&amp;rdquo;$1 $2 … $n&amp;quot;的形式输出所有参数。
$@ 所有参数列表。如&amp;quot;$@&amp;ldquo;用「&amp;quot;」括起来的情况、以&amp;rdquo;$1&amp;quot; &amp;ldquo;$2&amp;rdquo; … &amp;ldquo;$n&amp;rdquo; 的形式输出所有参数。
$# 添加到Shell的参数个数
$0 Shell本身的文件名
$1～$n 添加到Shell的各参数值。$1是第1参数、$2是第2参数…。
示例 1 #!/bin/bash 2 # 3 printf &amp;#34;The complete list is %s\n&amp;#34; &amp;#34;$$&amp;#34; 4 printf &amp;#34;The complete list is %s\n&amp;#34; &amp;#34;$!&amp;#34; 5 printf &amp;#34;The complete list is %s\n&amp;#34; &amp;#34;$?&amp;#34; 6 printf &amp;#34;The complete list is %s\n&amp;#34; &amp;#34;$*&amp;#34; 7 printf &amp;#34;The complete list is %s\n&amp;#34; &amp;#34;$@&amp;#34; 8 printf &amp;#34;The complete list is %s\n&amp;#34; &amp;#34;$#&amp;#34; 9 printf &amp;#34;The complete list is %s\n&amp;#34; &amp;#34;$0&amp;#34; 10 printf &amp;#34;The complete list is %s\n&amp;#34; &amp;#34;$1&amp;#34; 11 printf &amp;#34;The complete list is %s\n&amp;#34; &amp;#34;$2 结果 [Aric@localhost ~]$ bash params.</description>
			<content type="html"><![CDATA[<p>shell脚本中经常会看到$开头的特殊变量，那怎么理解它们呢？</p>
<h2 id="变量">变量</h2>
<ul>
<li>$$</li>
</ul>
<p>Shell本身的PID（ProcessID）</p>
<ul>
<li>$!</li>
</ul>
<p>Shell最后运行的后台Process的PID</p>
<ul>
<li>$?</li>
</ul>
<p>最后运行的命令的结束代码（返回值）</p>
<ul>
<li>$-</li>
</ul>
<p>使用Set命令设定的Flag一览</p>
<ul>
<li>$*</li>
</ul>
<p>所有参数列表。如&quot;$*&ldquo;用「&quot;」括起来的情况、以&rdquo;$1 $2 … $n&quot;的形式输出所有参数。</p>
<ul>
<li>$@</li>
</ul>
<p>所有参数列表。如&quot;$@&ldquo;用「&quot;」括起来的情况、以&rdquo;$1&quot; &ldquo;$2&rdquo; … &ldquo;$n&rdquo; 的形式输出所有参数。</p>
<ul>
<li>$#</li>
</ul>
<p>添加到Shell的参数个数</p>
<ul>
<li>$0</li>
</ul>
<p>Shell本身的文件名</p>
<ul>
<li>$1～$n</li>
</ul>
<p>添加到Shell的各参数值。$1是第1参数、$2是第2参数…。</p>
<h2 id="示例">示例</h2>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-shell" data-lang="shell"><span class="line"><span class="cl"> <span class="m">1</span> <span class="c1">#!/bin/bash</span>
</span></span><span class="line"><span class="cl"> <span class="m">2</span> <span class="c1">#</span>
</span></span><span class="line"><span class="cl"> <span class="m">3</span> <span class="nb">printf</span> <span class="s2">&#34;The complete list is %s\n&#34;</span> <span class="s2">&#34;</span><span class="nv">$$</span><span class="s2">&#34;</span>
</span></span><span class="line"><span class="cl"> <span class="m">4</span> <span class="nb">printf</span> <span class="s2">&#34;The complete list is %s\n&#34;</span> <span class="s2">&#34;</span><span class="nv">$!</span><span class="s2">&#34;</span>
</span></span><span class="line"><span class="cl"> <span class="m">5</span> <span class="nb">printf</span> <span class="s2">&#34;The complete list is %s\n&#34;</span> <span class="s2">&#34;</span><span class="nv">$?</span><span class="s2">&#34;</span>
</span></span><span class="line"><span class="cl"> <span class="m">6</span> <span class="nb">printf</span> <span class="s2">&#34;The complete list is %s\n&#34;</span> <span class="s2">&#34;</span><span class="nv">$*</span><span class="s2">&#34;</span>
</span></span><span class="line"><span class="cl"> <span class="m">7</span> <span class="nb">printf</span> <span class="s2">&#34;The complete list is %s\n&#34;</span> <span class="s2">&#34;</span><span class="nv">$@</span><span class="s2">&#34;</span>
</span></span><span class="line"><span class="cl"> <span class="m">8</span> <span class="nb">printf</span> <span class="s2">&#34;The complete list is %s\n&#34;</span> <span class="s2">&#34;</span><span class="nv">$#</span><span class="s2">&#34;</span>
</span></span><span class="line"><span class="cl"> <span class="m">9</span> <span class="nb">printf</span> <span class="s2">&#34;The complete list is %s\n&#34;</span> <span class="s2">&#34;</span><span class="nv">$0</span><span class="s2">&#34;</span>
</span></span><span class="line"><span class="cl"><span class="m">10</span> <span class="nb">printf</span> <span class="s2">&#34;The complete list is %s\n&#34;</span> <span class="s2">&#34;</span><span class="nv">$1</span><span class="s2">&#34;</span>
</span></span><span class="line"><span class="cl"><span class="m">11</span> <span class="nb">printf</span> <span class="s2">&#34;The complete list is %s\n&#34;</span> <span class="s2">&#34;</span><span class="nv">$2</span><span class="s2">
</span></span></span></code></pre></div><h2 id="结果">结果</h2>
<pre tabindex="0"><code>[Aric@localhost ~]$ bash params.sh 123456 QQ
The complete list is 24249
The complete list is
The complete list is 0
The complete list is 123456 QQ
The complete list is 123456
The complete list is QQ
The complete list is 2
The complete list is params.sh
The complete list is 123456
The complete list is QQ
</code></pre>]]></content>
		</item>
		
		<item>
			<title>Ubuntu16.04环境Jira和Confluence搭建</title>
			<link>http://www.heyuan110.com/posts/linux/2019-04-15-jira-confluence-install/</link>
			<pubDate>Mon, 15 Apr 2019 13:53:32 +0000</pubDate>
			
			<guid>http://www.heyuan110.com/posts/linux/2019-04-15-jira-confluence-install/</guid>
			<description>&lt;p&gt;jira和confluence都是Atlassian公司产品。jira是项目与事务跟踪工具，可以完成项目执行管理、敏捷开发管理、体系流程管理、产品Bug跟踪、提案跟踪、需求管理、客户服务等工作。confluence是一个专业的企业知识管理与协同软件，可以用于构建企业wiki，通过它可以实现团队成员之间的协作和知识共享。&lt;/p&gt;</description>
			<content type="html"><![CDATA[<p>jira和confluence都是Atlassian公司产品。jira是项目与事务跟踪工具，可以完成项目执行管理、敏捷开发管理、体系流程管理、产品Bug跟踪、提案跟踪、需求管理、客户服务等工作。confluence是一个专业的企业知识管理与协同软件，可以用于构建企业wiki，通过它可以实现团队成员之间的协作和知识共享。</p>
<!-- raw HTML omitted -->
<h2 id="一环境">一、环境</h2>
<p>前一篇讲了<a href="http://www.heyuan110.com/2019-04-12-%E6%8C%96%E7%9F%BF%E7%97%85%E6%AF%92kerberods%E7%9A%84%E5%85%A5%E4%BE%B5%E5%92%8C%E5%A4%84%E7%90%86.html">挖矿病毒</a>的入侵，决定对那台服务器上相关服务拆分迁移。上面的jira和confluence共用jira账号体系，迁移时两者要注意安装顺序，最后确定的方案：</p>
<p><img src="https://raw.githubusercontent.com/heyuan110/static-source/master/media/15553944919153/15553972819985.jpg" alt=""></p>
<h3 id="1系统">1.系统</h3>
<p>系统：Ubuntu 16.04.5 LTS
CPU：4核
内存：16G</p>
<p>上面机器配置最多可支持2000人，如果有更多人数需求，需升级配置。</p>
<h3 id="2java环境">2.Java环境</h3>
<p>需安装jdk1.8以上版本</p>
<p>安装java</p>
<blockquote>
<p>sudo apt install default-jre</p>
</blockquote>
<p>查看java版本</p>
<pre tabindex="0"><code>ubuntu@ip-172-31-23-228:~$ java -version
openjdk version &#34;1.8.0_191&#34;
OpenJDK Runtime Environment (build 1.8.0_191-8u191-b12-2ubuntu0.16.04.1-b12)
OpenJDK 64-Bit Server VM (build 25.191-b12, mixed mode)
</code></pre><h3 id="3mysql">3.Mysql</h3>
<p>安装mysql5.7</p>
<blockquote>
<p>sudo apt-get install mysql-server</p>
</blockquote>
<p>根据提示一步步设置，完成后记住mysql默认账号root的密码。</p>
<h2 id="二jira">二、Jira</h2>
<h3 id="1下载文件">1.下载文件</h3>
<p>**a)**下载jira，选择和老机器上jira相同的版本</p>
<blockquote>
<p>wget <a href="https://downloads.atlassian.com/software/jira/downloads/atlassian-jira-software-7.3.8-x64.bin">https://downloads.atlassian.com/software/jira/downloads/atlassian-jira-software-7.3.8-x64.bin</a></p>
</blockquote>
<p>**b)**下载jira7.3.8破解文件</p>
<blockquote>
<p>wget <a href="https://raw.githubusercontent.com/heyuan110/static-source/master/media/15553944919153/jira-lib-7.3.8.zip">https://raw.githubusercontent.com/heyuan110/static-source/master/media/15553944919153/jira-lib-7.3.8.zip</a></p>
</blockquote>
<p>解压<code>jira-lib-7.3.8.zip</code>文件</p>
<pre tabindex="0"><code>ubuntu@ip-172-31-23-228:/usr/local/programs/src$ unzip jira7.3.8.zip
Archive:  jira7.3.8.zip
  inflating: jira7.3.8/atlassian-extras-3.2.jar
  inflating: jira7.3.8/mysql-connector-java-5.1.39-bin.jar
</code></pre><h3 id="2配置jira数据库">2.配置jira数据库</h3>
<p>登录mysql</p>
<blockquote>
<p>mysql -uroot -p</p>
</blockquote>
<p>执行下面的SQL</p>
<pre tabindex="0"><code>;创建数据库sql
CREATE DATABASE jira CHARACTER SET utf8 COLLATE utf8_bin;

;授权用户
GRANT ALL ON jira.* TO &#39;jira&#39;@&#39;localhost&#39; IDENTIFIED BY &#39;jirapassword&#39;;

;刷新
FLUSH PRIVILEGES;
</code></pre><p>{% alert info %}
注意创建数据库时COLLATE需使用utf8_bin
{% endalert %}</p>
<h3 id="3安装jira">3.安装jira</h3>
<p>给安装包添加可执行权限</p>
<blockquote>
<p>chmod +x atlassian-jira-software-7.3.8-x64.bin</p>
</blockquote>
<p>执行安装</p>
<blockquote>
<p>./atlassian-jira-software-7.3.8-x64.bin</p>
</blockquote>
<p><img src="https://raw.githubusercontent.com/heyuan110/static-source/master/media/15553944919153/15554007889877.jpg" alt=""></p>
<p>按照提示键入安装即可。
如果没有自定义目录，jira的程序和应用数据分表装到了两个目录：</p>
<p>应用：<code>/opt/atlassian/jira</code>
应用数据: <code>/var/atlassian/application-data/jira</code></p>
<p>如果要修改jira默认端口，修改配置文件<code>/opt/atlassian/jira/conf/server.xml</code></p>
<h3 id="4破解jira">4.破解jira</h3>
<p>先停掉jira服务</p>
<blockquote>
<p>sudo /etc/init.d/jira stop</p>
</blockquote>
<p>**a)**用破解文件atlassian-extras-3.2.jar替换<code>/opt/atlassian/jira/atlassian-jira/WEB-INF/lib/atlassian-extras-3.2.jar</code>文件</p>
<pre tabindex="0"><code>#先备份原文件
mv /opt/atlassian/jira/atlassian-jira/WEB-INF/lib/atlassian-extras-3.2.jar /tmp/atlassian-extras-3.2.jar

#替换文件
cp /破解文件目录/atlassian-extras-3.2.jar /opt/atlassian/jira/atlassian-jira/WEB-INF/lib/atlassian-extras-3.2.jar
</code></pre><p>**b)**确保jira可访问mysql，将mysql-connector-java-5.1.39-bin.jar拷贝<code>/opt/atlassian/jira/atlassian-jira/WEB-INF/lib/</code>路径下</p>
<pre tabindex="0"><code>cp /破解文件目录/mysql-connector-java-5.1.39-bin.jar /opt/atlassian/jira/atlassian-jira/WEB-INF/lib/mysql-connector-java-5.1.39-bin.jar
</code></pre><p>启动Jira服务, 默认端口8080</p>
<blockquote>
<p>sudo /etc/init.d/jira start</p>
</blockquote>
<p>按下图向导配置:
<img src="https://raw.githubusercontent.com/heyuan110/static-source/master/media/15553944919153/15554025003672.jpg" alt=""></p>
<p>配置数据库
<img src="https://raw.githubusercontent.com/heyuan110/static-source/master/media/15553944919153/15554025207183.jpg" alt=""></p>
<p>设置应用程序属性
<img src="https://raw.githubusercontent.com/heyuan110/static-source/master/media/15553944919153/15554025578020.jpg" alt=""></p>
<p>生成JIRA使用许可证
<img src="https://raw.githubusercontent.com/heyuan110/static-source/master/media/15553944919153/15554026788338.jpg" alt=""></p>
<p>打开Atlassian官网获取许可证
<img src="https://raw.githubusercontent.com/heyuan110/static-source/master/media/15553944919153/15554028462386.jpg" alt=""></p>
<p>继续下一步配置完邮件(也可先跳过)，选择语言，至此Jira的安装和破解完成。</p>
<h3 id="5老机器jira数据备份新机器jira数据恢复">5.老机器jira数据备份，新机器jira数据恢复</h3>
<p>**a)**管理员账号登录老机器jira</p>
<p>点击右上角的&quot;系统&quot;-&ldquo;导入导出&rdquo;-&ldquo;备份系统&rdquo;，Jira默认会打开自动备份的功能，备份路径为<code>/var/atlassian/application-data/jira/export</code>；入如果没有打开，也可以手动进行备份，如下，可以自定义备份的文件名。</p>
<p><img src="https://raw.githubusercontent.com/heyuan110/static-source/master/media/15553944919153/15554034483507.jpg" alt=""></p>
<p>{% alert info %}
注意:这里的备份数据不包括附件。
jira附件都保存到服务器的/var/atlassian/application-data/jira/data/attachments路径下，这里的附件数据需要手动写脚本进行备份。点击右上角的&quot;系统&quot;-&ldquo;高级&rdquo;-&ldquo;附件&quot;就可以看到jira附件的设置。
{% endalert %}</p>
<p><img src="https://raw.githubusercontent.com/heyuan110/static-source/master/media/15553944919153/15554036917962.jpg" alt=""></p>
<p>将jira的备份文件jira-backup.zip和attachments.zip文件拷贝到新机器。</p>
<p>**b)**管理员账号登录新机器jira</p>
<p>停止jira服务，将附件备份文件attachments.zip解压替换<code>/var/atlassian/application-data/jira/data/attachments</code>目录(可先备份)。</p>
<p>将备份文件jira-backup.zip拷贝到<code>/var/atlassian/application-data/jira/import</code>路径下。</p>
<p>启动jira服务，点击右上角的&quot;系统&rdquo;-&ldquo;导入导出&rdquo;-&ldquo;恢复系统&rdquo;，</p>
<p><img src="https://raw.githubusercontent.com/heyuan110/static-source/master/media/15553944919153/15554041476782.jpg" alt=""></p>
<p>点击 [复原]开始恢复。</p>
<h2 id="三confluence">三、Confluence</h2>
<p>老机器上是confluence6.3.1版本，这个版本的WebDAV和widgetconnector都存在漏洞，如果继续安装这个版本，恢复完数据估计很快又会沦为矿机。</p>
<p>针对上面两个漏洞官方在每个小版本里都发布了修复版，和6.3.1比较近的版本6.6.12就是一个修复了漏洞版本，所以决定下载并破解confluence6.6.12。</p>
<h3 id="1下载文件-1">1.下载文件</h3>
<p>**a)**下载confluence，选择和老机器上confluence相同的版本</p>
<blockquote>
<p>wget <a href="https://product-downloads.atlassian.com/software/confluence/downloads/atlassian-confluence-6.6.12-x64.bin">https://product-downloads.atlassian.com/software/confluence/downloads/atlassian-confluence-6.6.12-x64.bin</a></p>
</blockquote>
<p>**b)**下载mysql链接库和破解工具</p>
<blockquote>
<p>wget <a href="https://raw.githubusercontent.com/heyuan110/static-source/master/media/15553944919153/confluence-crack-tool.zip">https://raw.githubusercontent.com/heyuan110/static-source/master/media/15553944919153/confluence-crack-tool.zip</a></p>
</blockquote>
<p>解压<code>unzip confluence-crack-tool.zip</code>可以看到mysql链接库和破解工具confluence_keygen</p>
<h3 id="2配置confluence数据库">2.配置confluence数据库</h3>
<p>登录mysql</p>
<blockquote>
<p>mysql -uroot -p</p>
</blockquote>
<p>执行下面的SQL</p>
<pre tabindex="0"><code>;创建数据库sql
CREATE DATABASE confluence CHARACTER SET utf8 COLLATE utf8_bin;

;授权用户
GRANT ALL ON confluence.* TO &#39;confluence&#39;@&#39;localhost&#39; IDENTIFIED BY &#39;confluencepassword&#39;;

;刷新
FLUSH PRIVILEGES;
</code></pre><p>{% alert info %}
注意创建数据库时COLLATE需使用utf8_bin
{% endalert %}</p>
<h3 id="3安装confluence">3.安装confluence</h3>
<p>给安装包添加可执行权限</p>
<blockquote>
<p>chmod +x atlassian-confluence-6.6.12-x64.bin</p>
</blockquote>
<p>执行安装</p>
<blockquote>
<p>./atlassian-confluence-6.6.12-x64.bin</p>
</blockquote>
<p><img src="https://raw.githubusercontent.com/heyuan110/static-source/master/media/15553944919153/15554719813856.jpg" alt=""></p>
<p>（截图用的6.3.1版本，仅参考）按照提示键入安装即可。（注意第一次确认是否继续，第二次选择安装方式(选1express安装)，第三次是否启动服务）
如果没有自定义目录，jira的程序和应用数据分表装到了两个目录：</p>
<p>应用：<code>/opt/atlassian/confluence</code>
应用数据: <code>/var/atlassian/application-data/confluence</code></p>
<p>默认监听的端口是8090，如果要修改confluence默认端口，修改配置文件<code>/opt/atlassian/confluence/conf/server.xml</code></p>
<p>最后提示安装完成并启动了服务。</p>
<h3 id="4破解confluence">4.破解confluence</h3>
<p>打开http://ip:8090(未配置完成前强烈建议用ip+port访问，不要用域名，重装过几次每次用域名访问配置到数据库那一步一定会报超时错误！用ip就不会)，</p>
<p>先停掉confluence服务</p>
<blockquote>
<p>sudo /etc/init.d/confluence stop</p>
</blockquote>
<p>设置语言
<img src="https://raw.githubusercontent.com/heyuan110/static-source/master/media/15553944919153/15554744214183.jpg" alt=""></p>
<p>选择产品
<img src="https://raw.githubusercontent.com/heyuan110/static-source/master/media/15553944919153/15554744447563.jpg" alt=""></p>
<p>不要选择任何插件
<img src="https://raw.githubusercontent.com/heyuan110/static-source/master/media/15553944919153/15554744812861.jpg" alt=""></p>
<p><img src="https://raw.githubusercontent.com/heyuan110/static-source/master/media/15553944919153/15554745162747.jpg" alt=""></p>
<p>到这一步，<strong>记录服务器ID</strong>,不要关掉页面</p>
<p>停止confluence服务</p>
<blockquote>
<p>sudo /etc/init.d/confluence stop</p>
</blockquote>
<p>**a)**替换库文件</p>
<p>将confluence库文件<code>/opt/atlassian/confluence/confluence/WEB-INF/lib/atlassian-extras-decoder-v2-3.2.jar</code>通过scp拷贝到本地(可使用scp,rsync,ftp等)</p>
<p>下面在本地电脑操作：</p>
<ol>
<li>
<p>将拷贝到本地的atlassian-extras-decoder-v2-3.2.jar改名为atlassian-extras-2.4.jar（因为破解工具只认这个版本的名称）</p>
</li>
<li>
<p>运行confluence_keygen.jar(mac里有java环境直接双击打开，win和linux可用java命令打开)，填好ServerID，其他随便填。点击gen生成key并拷贝出来记录好。点击patch，选择刚重命名为atlassian-extras-2.4.jar的文件进行破解</p>
</li>
</ol>
<p><img src="https://raw.githubusercontent.com/heyuan110/static-source/master/media/15553944919153/15555684266000.jpg" alt=""></p>
<ol start="3">
<li>破解完成，将破解的文件atlassian-extras-2.4.jar回传到服务器</li>
</ol>
<p>下面在服务器操作：</p>
<p>在服务器上将回传的atlassian-extras-2.4.jar重命名为atlassian-extras-decoder-v2-3.2.jar</p>
<blockquote>
<p>mv atlassian-extras-2.4.jar atlassian-extras-decoder-v2-3.3.0.jar</p>
</blockquote>
<p>然后覆盖回原路径：</p>
<blockquote>
<p>cp -a  atlassian-extras-decoder-v2-3.3.0.jar /opt/atlassian/confluence/confluence/WEB-INF/lib/</p>
</blockquote>
<p>**b)**确保jira可访问mysql，将mysql-connector-java-5.1.39-bin.jar(放在破解工具目录)拷贝<code>/opt/atlassian/confluence/lib/</code>路径下</p>
<p>启动confluence服务</p>
<blockquote>
<p>sudo /etc/init.d/confluence start</p>
</blockquote>
<p>回到输入key的界面，输入上面记录的key，点击下一步</p>
<p><img src="https://raw.githubusercontent.com/heyuan110/static-source/master/media/15553944919153/15555689505079.jpg" alt=""></p>
<p>然后进行配置数据库：我选择的是我自己的数据库，这里需要对数据库进行一些配置。如果选择内置的话，就是使用嵌入式的数据库，不用配置什么东西，等一段（挺长的）时间，就好了。</p>
<p><img src="https://raw.githubusercontent.com/heyuan110/static-source/master/media/15553944919153/15555689819609.jpg" alt=""></p>
<p><img src="https://raw.githubusercontent.com/heyuan110/static-source/master/media/15553944919153/15555690078229.jpg" alt=""></p>
<p>在测试成功后，下一步比较慢，需要往数据库写好多表。</p>
<p>注意：这一步因为用域名访问每次都报错，都必须删除重新安装，强烈建议用ip+port访问</p>
<p>连接数据库的配置文件：/var/atlassian/application-data/confluence/confluence.cfg.xml。</p>
<p>推荐使用示范站点，先熟悉Confluence，然后再自行进行设置
<img src="https://raw.githubusercontent.com/heyuan110/static-source/master/media/15553944919153/15555691635256.jpg" alt=""></p>
<p>可以选择confluence中管理用户，也可选择jira链接，不过强烈建议选第一个，后面要链接再自己取加，
这个地方的坑一会在最后面记录。因为我们是基于jira用户，所以选择了第二个。
<img src="https://raw.githubusercontent.com/heyuan110/static-source/master/media/15553944919153/15555691997258.jpg" alt=""></p>
<p>填完信息开始同步jira用户
<img src="https://raw.githubusercontent.com/heyuan110/static-source/master/media/15553944919153/15554790883441.jpg" alt=""></p>
<p>（我之前在这一步也失败过,所以我才说建议先创建内部账号。。。）</p>
<p>如果同步完成没报错，继续下一步配置完邮件(也可先跳过)，选择语言，至此Jira的安装和破解完成。</p>
<p>可以打开http://ip:port/admin/license.action查看破解情况
<img src="https://raw.githubusercontent.com/heyuan110/static-source/master/media/15553944919153/15555696667314.jpg" alt=""></p>
<h3 id="5老机器confluence数据备份新机器confluence数据恢复">5.老机器confluence数据备份，新机器confluence数据恢复</h3>
<p>**a)**管理员账号登录老机器confluence</p>
<p>点击右上角的&quot;一般配置&quot;-&ldquo;每日备份管理&rdquo;，如下图（默认配置）：
<img src="https://raw.githubusercontent.com/heyuan110/static-source/master/media/15553944919153/15555697603764.jpg" alt=""></p>
<p>默认每天会自动备份一个zip打包的数据，存放在服务器的/var/atlassian/application-data/confluence/backups路径下。还可以点击&quot;编辑&quot;进行自定义。</p>
<p>默认每天2点左右都会整体备份一次！恢复或迁移的时候，可以直接用这里的zip打包数据进行恢复。除此之外，还可以点击&quot;一般配置&quot;-&ldquo;备份与还原&quot;里面的备份进行手动备份。</p>
<p><img src="https://raw.githubusercontent.com/heyuan110/static-source/master/media/15553944919153/15555698570656.jpg" alt=""></p>
<p>{% alert info %}
注意:最好将附件也从原机器备份过来。附件都保存在服务器的/var/atlassian/application-data/confluence/attachments路径下。
{% endalert %}</p>
<p>将confluence的备份文件confluence-backup.zip和attachments.zip文件拷贝到新机器。</p>
<p>**b)**管理员账号登录新机器confluence</p>
<p>停止confluence服务，将附件备份文件attachments.zip解压替换<code>/var/atlassian/application-data/confluence/attachments</code>目录(可先备份)。</p>
<p>将备份文件confluence-backup.zip拷贝到<code>/var/atlassian/application-data/confluence/restore</code>路径下。</p>
<p>启动confluence服务，点击&quot;一般配置&rdquo;-&ldquo;备份与还原&quot;里面的恢复进行数据恢复，</p>
<p><img src="https://raw.githubusercontent.com/heyuan110/static-source/master/media/15553944919153/15555701266334.jpg" alt=""></p>
<p>如果文件放到restore目录下了，会显示在图中列表里，选择文件，点击 [还原]开始恢复。</p>
<h2 id="四问题总结">四、问题总结</h2>
<h3 id="1-confluence致命漏洞和修复">1. confluence致命漏洞和修复</h3>
<p>最近各大安全平台爆出Confluence Server远程代码执行漏洞</p>
<pre tabindex="0"><code>Atlassian 公司的 Confluence Server 和 Data Center 产品中使用的 widgetconnecter 组件 (版本&lt;=3.1.3) 中存在服务器端模板注入 (SSTI) 漏洞。攻击者可以利用该漏洞实现对目标系统进行路径遍历攻击、服务端请求伪造 (SSRF)、远程代码执行 (RCE)。
</code></pre><p>攻击者可以通过构造恶意的 HTTP 请求参数，对目标系统实施（路径遍历、任意文件读取以及远程命令执行）攻击。该类攻击可导致目标系统中的敏感信息被泄露，以及执行攻击者构造的恶意代码。</p>
<p>尽快升级到confluence官方修复版，目前官方修复版本：</p>
<p>版本 6.6.12 及更高版本的 6.6.x.
版本 6.12.3 及更高版本的 6.12.x
版本 6.13.3 及更高版本的 6.13.x
版本 6.14.2 及更高版本</p>
<p><em>参考:</em>
<em>1.<a href="https://confluence.atlassian.com/doc/confluence-security-advisory-2019-03-20-966660264.html">https://confluence.atlassian.com/doc/confluence-security-advisory-2019-03-20-966660264.html</a></em>
<em>2.<a href="https://www.chainnews.com/articles/426052160451.htm">https://www.chainnews.com/articles/426052160451.htm</a></em>
<em>3.<a href="http://news.ssssafe.com/archives/834">http://news.ssssafe.com/archives/834</a></em>
<em>4.<a href="http://copyfuture.com/blogs-details/3a44938fcd7518cdda0f1390099382cd">http://copyfuture.com/blogs-details/3a44938fcd7518cdda0f1390099382cd</a></em></p>
<h3 id="2-confluence数据库字符乱码">2. confluence数据库字符乱码</h3>
<p>在恢复数据时到一半就报错<code>duplicate entry '???' for key xxx</code>,去数据库查看，发现很多记录是?，查看数据库编码为latin（拉丁文），修改mysql5.7配置</p>
<blockquote>
<p>vi /etc/mysql/mysql.conf.d/mysqld.cnf</p>
</blockquote>
<p>在mysqld下增加字符相关配置，修改log的size，配置如下</p>
<pre tabindex="0"><code>#set character
symbolic-links=0
collation_server=utf8_unicode_ci
character_set_server=utf8
skip-character-set-client-handshake
transaction-isolation=READ-COMMITTED

key_buffer_size         = 32M
max_allowed_packet      = 128M
thread_stack            = 192K
thread_cache_size       = 8
innodb_log_file_size    = 512M
</code></pre><p>重启mysql，再导入不会报错。</p>
<p><em>参考：<a href="https://confluence.atlassian.com/jirakb/health-check-database-collation-in-mysql-943951422.html">https://confluence.atlassian.com/jirakb/health-check-database-collation-in-mysql-943951422.html</a></em></p>
<h3 id="3-confluence账户体系">3. confluence账户体系</h3>
<p>confluence包含两套账户体系：confluence内部的用户、外部链接的用户(jira,ldap等)
confluence内部用户：创建、更新都只对confluence生效，目录属于Confluence Internal Directory。
外部链接的用户：和jira共用账户体系，通过应用程序链接授权和同步用户到confluence，在添加程序链接时可以设置单向同步还是双向同步。</p>
<p>强烈建议在confluence搭建时一定要先创建一个内部用户管理员账号，而且只有内部用户管理员才可以编辑非内部目录链接，编辑连接（http://host:port/plugins/servlet/embedded-crowd/directories/list）。</p>
<p>添加jira外部用户链接步骤：</p>
<ol>
<li>在jira里添加[JIRA用户服务器]，打开http://jira.xxxx.com/secure/admin/ConfigureCrowdServer.jspa，(修改url成你自己jira的域名)。添加一个新应用程序：
<ul>
<li>输入Confluence在访问Jira时将使用的应用程序名称和密码（可自己定义），</li>
<li>输入Confluence服务器的IP地址(如果和jira在同一台服务器，最好用内网ip)</li>
<li>保存。</li>
</ul>
</li>
<li>在confluence里添加用户目录, 打开http://host:port/plugins/servlet/embedded-crowd/directories/list，(修改url成你自己confluece的域名)。添加一个用户目录：
<ul>
<li>选择类型（jira）</li>
<li>填应用名称，填服务器的URL（Jira服务器地址，如果和confluence在同一台服务器，建议填内网），第1步中设置的应用程序名称，密码</li>
<li>其他项看情况自己选择，点测试设置，通过后保存</li>
</ul>
</li>
</ol>
<p><em>参考:</em>
<em>1.https://confluence.atlassian.com/doc/connecting-to-crowd-or-jira-for-user-management-229838465.html#ConnectingtoCrowdorJIRAforUserManagement-ConnectingConfluencetoJIRAforUserManagement</em>
<em>2.https://www.cnblogs.com/kevingrace/p/5569932.html</em></p>
<h3 id="4-confluence无法登录解决办法">4. confluence无法登录解决办法</h3>
<p>遇到一个很尴尬的问题，confluence全部安装完成运行，也设置好了confluence内部用户管理员账号，
可还原备份数据后，新的内部管理员账号被删除，外部链接设置也被还原成老的配置，导致用内部管理员账号无法登录，用老账号也无法登录！</p>
<p>第一次选择了重装，到还原这一步又是同样的问题，最后去官网找到了解决方案，大致思路：</p>
<ol>
<li>通过sql直接在数据库创建内部用户管理员账号</li>
<li>用内部管理员账号登录进去后修改jira外部用户链接配置</li>
</ol>
<p>相关SQL:</p>
<pre tabindex="0"><code>#1.创建用户confluence-admin，密码admin
insert into cwd_user(id, user_name, lower_user_name, active, created_date, updated_date, first_name, lower_first_name, last_name, lower_last_name, display_name, lower_display_name, email_address, lower_email_address, directory_id, credential) values (1212121, &#39;confluence-admin&#39;, &#39;confluence-admin&#39;, &#39;T&#39;, &#39;2009-11-26 17:42:08&#39;, &#39;2009-11-26 17:42:08&#39;, &#39;A. D.&#39;, &#39;a. d.&#39;, &#39;Ministrator&#39;, &#39;ministrator&#39;, &#39;A. D. Ministrator&#39;, &#39;a. d. ministrator&#39;, &#39;confluence-admin@xxxx.com&#39;, &#39;confluence-admin@xxxx.com&#39;, (select id from cwd_directory where directory_name=&#39;Confluence Internal Directory&#39;), &#39;x61Ey612Kl2gpFL56FT9weDnpSo4AV8j8+qx2AuTHdRyY036xxzTTrw10Wq3+4qQyB+XURPWx1ONxp3Y3pB37A==&#39;);

#2.添加映射关系
insert into user_mapping values (&#39;2c9681954172cf560000000000000001&#39;, &#39;confluence-admin&#39;, &#39;confluence-admin&#39;);

#3.非必须步骤:创建组，这一步可以自己去数据库先看看，可能已经创建过了
insert into cwd_group(id, group_name, lower_group_name, active, local, created_date, updated_date, description, group_type, directory_id)
values ( &#39;888888&#39;,&#39;confluence-administrators&#39;,&#39;confluence-administrators&#39;,&#39;T&#39;,&#39;F&#39;,&#39;2011-03-21 12:20:29&#39;,&#39;2011-03-21 12:20:29&#39;,NULL,&#39;GROUP&#39;,(select id from cwd_directory where directory_name=&#39;Confluence Internal Directory&#39;));
insert into cwd_group(id, group_name, lower_group_name, active, local, created_date, updated_date, description, group_type, directory_id)
values ( &#39;999999&#39;,&#39;confluence-users&#39;,&#39;confluence-users&#39;,&#39;T&#39;,&#39;F&#39;,&#39;2011-03-21 12:20:29&#39;,&#39;2011-03-21 12:20:29&#39;,NULL,&#39;GROUP&#39;,(select id from cwd_directory where directory_name=&#39;Confluence Internal Directory&#39;));

#4.将用户添加到组confluence-users和confluence-administrators
insert into cwd_membership (id, parent_id, child_user_id) values (163841, (select id from cwd_group where group_name=&#39;confluence-users&#39; and directory_id=(select id from cwd_directory where directory_name=&#39;Confluence Internal Directory&#39;)), 1212121);
insert into cwd_membership (id, parent_id, child_user_id) values (163842, (select id from cwd_group where group_name=&#39;confluence-administrators&#39; and directory_id=(select id from cwd_directory where directory_name=&#39;Confluence Internal Directory&#39;)), 1212121);

#5.验证一下是否添加成功
select u.id, u.user_name, u.active from cwd_user u
join cwd_membership m on u.id=m.child_user_id join cwd_group g on m.parent_id=g.id join cwd_directory d on d.id=g.directory_id
where g.group_name = &#39;confluence-administrators&#39; and d.directory_name=&#39;Confluence Internal Directory&#39;;

#查目录
select d.id, d.directory_name, m.list_index from cwd_directory d join cwd_app_dir_mapping m on d.id=m.directory_id;
select id, directory_name, active from cwd_directory where id = 98306;
</code></pre><p>详细步骤参考官网：</p>
<p><em><a href="https://confluence.atlassian.com/conf64/restore-passwords-to-recover-admin-user-rights-936511358.html">https://confluence.atlassian.com/conf64/restore-passwords-to-recover-admin-user-rights-936511358.html</a></em></p>
<h3 id="5相关参考">5.相关参考</h3>
<ol>
<li><a href="https://www.cnblogs.com/kevingrace/p/8862531.html">Jira/Confluence的备份、恢复和迁移</a></li>
<li><a href="https://blog.51cto.com/moerjinrong/2149177?utm_source=oschina-app">linux安装破解Confluence-6.8.5</a></li>
</ol>]]></content>
		</item>
		
		<item>
			<title>挖矿病毒kerberods的入侵和处理</title>
			<link>http://www.heyuan110.com/posts/linux/2019-04-12-linux-kerberods/</link>
			<pubDate>Fri, 12 Apr 2019 16:15:53 +0000</pubDate>
			
			<guid>http://www.heyuan110.com/posts/linux/2019-04-12-linux-kerberods/</guid>
			<description>最近经常听到挖矿病毒kerberods肆虐，大量linux主机沦陷，导致的结果显著特征CPU持续100%，正常的应用服务无法提供。不幸昨天我们有一台机器中招了，下面记录整个事件发生、处理过程。
事件发生 昨天下午5.30左右，几个同事反馈git代码无法提交，报502错误。
立即安排了一个运维童鞋排查，本来以为和上次一样gitlab并发数达到上限，改改配置重启下就行，结果从18点到20点一直顺着gitlab502错误这个方向搞了2小时，没有任何进展。由于代码无法提交，gitlab访问不了，发布系统也就不能正常做上线操作，赶紧我也投入了排查。
排查处理 这台机器上有三个服务gitlab，jira，confluence，除了gitlab，另外两个看着是正常的(其实里面部分页面已经异常，只是没仔细去检查)。
检查系统运行指标，先上服务器上执行top，如下： 粗略一看cpu和内存好像正常，按1切换看每个cpu情况问题来了，居然只有一个cpu0，这台ec2机器有16CPU，接着到aws console上看到这台机器cpu，如下：
5.30左右cpu突然直接100%了，其实这时脑袋闪了一下有想到是病毒，然后去看了机器的network out/in发现没有突然激增，所以没继续朝这想。随后执行ps -ef查看进程，发现居然没有php，java相关进程，开始想是不是aws系统故障（之前有前科）？
于是让同事赶紧给aws提了个加急support，同时联系专门对接我们的AWS SA让其帮忙跟进催促。这时我们还是没意识到是感染了病毒，如是边等待aws那边消息，边继续在google搜索gitlab502错误相关的资料。
gitlab论坛、google上能搜到资料都尝试了，基本都在说是因为端口被占用，超时时间设置等等，执行netstat -ntlp发现gitlab服务的8080端口压根没占用，不过抱着侥幸心理还是改了默认端口然后gitlab-ctl reconfigure和gitlab-ctl restart，最后用gitlab-ctl status查看发现显示所有的服务都起来了，翻遍了gitlab里相关服务所有的log，唯有有点线索的还是显示127.0.0.1:8080 refused，gitlab坛子里有人说要多尝试其次，又试了几遍，当然不会有结果啊，最后我基本确认不是gitlab问题，又去催aws sa帮我联系他们support。
中间已经开始做最坏打算，让另外一个同事开新机器把gitlab迁移过去，可是发现gitlab backup超级无敌慢，不过还是耐心的等待着。
还好大概在一个小时后美国那边的supprot打电话过来，以为有救了，nonono，接下来一度很无语，给他们描述完问题，才发现他们毛都干不了。aws规定他们售后工程师不能碰客户机器(说是基于客户安全考虑，不过应该有点扯，都托管到他们那了想干啥不行啊)，那你不能碰机器，又不能看到底层，凭超能力感知么？反正无厘头一顿指挥操作后，没啥结果。然后让做一个AMI，也是神坑速度超慢，点开始后就只能傻傻等，最后我提出来远程协助工具，居然没有，那我share屏幕，你看着然后一起分析总行吧，还好这个有，很快他发了一个screenshare的link，下载安装好bomgar，打开开始share屏幕，至此才可以说是support开始。。。。尼玛有sharescreen这种工具怎么不一上来就提出来用，唾沫星子能解决个毛线问题啊。
工欲善其事必先利其器，这里真心要吐槽下aws support的&amp;quot;维修工具箱&amp;quot;，有顾虑和安全意识不让碰客户机器可以理解，可是能不能搞一些方便沟通提高解决问题效率的工具，比如远程协助，分享屏幕，文字、图片截图聊天等等。
以上是吐槽，得结论：16CPU的top命令只能看到1CPU在跑，有点诡异，继续排查。
重启EC2 怀疑是EC2硬件故障，并且反复尝试了多次；发现上述现象依然存在，服务器始终无法显示所有的CPU资源，依旧显示一颗CPU在运行，查看系统启动日志/var/log/syslog，日志最后提示：didn’t collect load info for all cpus, balancing is broken
排查CPU 先对故障的机器做快照，准备快照完起新机器还原过去试试。同时开始排查CPU，大概过程如下：
$ cat /proc/cpuinfo 查看CPU信息，系统在启动过程中，CPU的信息在启动的过程中被装载到虚拟目录/proc下的cpuinfo文件中 $ cat /var/log/syslog | grep irqbalance 查看系统日志过滤CPU中断分布信息； 关于irqbalance的更多信息：http://blog.huatai.me/2014/11/05/linux-irqbalance-irq-and-cpu-affinity/ $ cat /proc/stat # 查看CPU的利用率 $ mpstat -P ALL 1 3 或 $ for i in `seq 3`; do cat /proc/stat &amp;gt;&amp;gt; /tmp/stat.</description>
			<content type="html"><![CDATA[<p>最近经常听到挖矿病毒kerberods肆虐，大量linux主机沦陷，导致的结果显著特征CPU持续100%，正常的应用服务无法提供。不幸昨天我们有一台机器中招了，下面记录整个事件发生、处理过程。</p>
<h2 id="事件发生">事件发生</h2>
<p>昨天下午5.30左右，几个同事反馈git代码无法提交，报502错误。</p>
<p><img src="https://raw.githubusercontent.com/heyuan110/static-source/master/media/kerberods/15550614255551.jpg" alt=""></p>
<p>立即安排了一个运维童鞋排查，本来以为和上次一样gitlab并发数达到上限，改改配置重启下就行，结果从18点到20点一直顺着gitlab502错误这个方向搞了2小时，没有任何进展。由于代码无法提交，gitlab访问不了，发布系统也就不能正常做上线操作，赶紧我也投入了排查。</p>
<h2 id="排查处理">排查处理</h2>
<p>这台机器上有三个服务gitlab，jira，confluence，除了gitlab，另外两个看着是正常的(其实里面部分页面已经异常，只是没仔细去检查)。</p>
<ol>
<li>检查系统运行指标，先上服务器上执行<code>top</code>，如下：</li>
</ol>
<p><img src="https://raw.githubusercontent.com/heyuan110/static-source/master/media/kerberods/981554911843_.pic_hd.jpg" alt="981554911843_.pic_hd"></p>
<p>粗略一看cpu和内存好像正常，按1切换看每个cpu情况问题来了，居然只有一个cpu0，这台ec2机器有16CPU，接着到aws console上看到这台机器cpu，如下：</p>
<p><img src="https://raw.githubusercontent.com/heyuan110/static-source/master/media/kerberods/881554911487_.pic_hd.jpg" alt="881554911487_.pic_hd"></p>
<p>5.30左右cpu突然直接100%了，其实这时脑袋闪了一下有想到是病毒，然后去看了机器的network out/in发现没有突然激增，所以没继续朝这想。随后执行<code>ps -ef</code>查看进程，发现居然没有php，java相关进程，开始想是不是aws系统故障（之前有前科）？</p>
<p>于是让同事赶紧给aws提了个加急support，同时联系专门对接我们的AWS SA让其帮忙跟进催促。这时我们还是没意识到是感染了病毒，如是边等待aws那边消息，边继续在google搜索gitlab502错误相关的资料。</p>
<p>gitlab论坛、google上能搜到资料都尝试了，基本都在说是因为端口被占用，超时时间设置等等，执行<code>netstat -ntlp</code>发现gitlab服务的8080端口压根没占用，不过抱着侥幸心理还是改了默认端口然后<code>gitlab-ctl reconfigure</code>和<code>gitlab-ctl restart</code>，最后用<code>gitlab-ctl status</code>查看发现显示所有的服务都起来了，翻遍了gitlab里相关服务所有的log，唯有有点线索的还是显示127.0.0.1:8080 refused，gitlab坛子里有人说要多尝试其次，又试了几遍，当然不会有结果啊，最后我基本确认不是gitlab问题，又去催aws sa帮我联系他们support。</p>
<p>中间已经开始做最坏打算，让另外一个同事开新机器把gitlab迁移过去，可是发现gitlab backup超级无敌慢，不过还是耐心的等待着。</p>
<p>还好大概在一个小时后美国那边的supprot打电话过来，以为有救了，nonono，接下来一度很无语，给他们描述完问题，才发现他们毛都干不了。aws规定他们售后工程师不能碰客户机器(说是基于客户安全考虑，不过应该有点扯，都托管到他们那了想干啥不行啊)，那你不能碰机器，又不能看到底层，凭超能力感知么？反正无厘头一顿指挥操作后，没啥结果。然后让做一个AMI，也是神坑速度超慢，点开始后就只能傻傻等，最后我提出来远程协助工具，居然没有，那我share屏幕，你看着然后一起分析总行吧，还好这个有，很快他发了一个screenshare的link，下载安装好bomgar，打开开始share屏幕，至此才可以说是support开始。。。。尼玛有sharescreen这种工具怎么不一上来就提出来用，唾沫星子能解决个毛线问题啊。</p>
<blockquote>
<p>工欲善其事必先利其器，这里真心要吐槽下aws support的&quot;维修工具箱&quot;，有顾虑和安全意识不让碰客户机器可以理解，可是能不能搞一些方便沟通提高解决问题效率的工具，比如远程协助，分享屏幕，文字、图片截图聊天等等。</p>
</blockquote>
<p>以上是吐槽，得结论：16CPU的top命令只能看到1CPU在跑，有点诡异，继续排查。</p>
<ol start="2">
<li>重启EC2</li>
</ol>
<p>怀疑是EC2硬件故障，并且反复尝试了多次；发现上述现象依然存在，服务器始终无法显示所有的CPU资源，依旧显示一颗CPU在运行，查看系统启动日志/var/log/syslog，日志最后提示：<code>didn’t collect load info for all cpus, balancing is broken</code></p>
<ol start="3">
<li>排查CPU</li>
</ol>
<p>先对故障的机器做快照，准备快照完起新机器还原过去试试。同时开始排查CPU，大概过程如下：</p>
<pre tabindex="0"><code>
$ cat /proc/cpuinfo

查看CPU信息，系统在启动过程中，CPU的信息在启动的过程中被装载到虚拟目录/proc下的cpuinfo文件中

$ cat /var/log/syslog | grep irqbalance

查看系统日志过滤CPU中断分布信息；

关于irqbalance的更多信息：http://blog.huatai.me/2014/11/05/linux-irqbalance-irq-and-cpu-affinity/

$ cat /proc/stat             # 查看CPU的利用率

$ mpstat -P ALL 1 3 或

$ for i in `seq 3`; do cat /proc/stat &gt;&gt; /tmp/stat.txt; sleep 1; done

# 采集所有的CPU核心的当前运行情况，每秒更新一次，采集3次

cpu  10445020 88 14726 50034 5432 0 457 11658 0 0

cpu0 653379 0 922 2011 805 0 13 535 0 0

cpu1 651988 0 1745 2566 872 0 26 782 0 0

cpu2 653171 37 925 2511 598 0 4 735 0 0

cpu3 653520 0 807 2460 455 0 0 741 0 0

cpu4 651566 0 1390 3614 486 0 197 729 0 0

cpu5 652563 0 1318 2713 447 0 196 752 0 0

cpu6 652903 0 734 3258 340 0 1 748 0 0

cpu7 653128 0 842 2762 502 0 2 733 0 0

cpu8 652979 0 692 3446 128 0 0 733 0 0

cpu9 652710 0 729 3701 100 0 5 731 0 0

cpu10 652843 51 760 3471 119 0 3 732 0 0

cpu11 652815 0 703 3610 120 0 0 736 0 0

cpu12 652166 0 856 4120 102 0 1 734 0 0

cpu13 652992 0 777 3347 121 0 1 736 0 0

cpu14 653266 0 647 3284 40 0 1 753 0 0

cpu15 653024 0 874 3154 189 0 2 742 0 0

intr 33000247 89 9 0 0 1495 0 3 0 2 0 0 0 144 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1742341 37454 89869 0 97 336 1786533 51288 92366 0 154 25 1729717 45438 85288 0 381 44 1709936 37017 91720 0 141 68 1896285 59966 56559 0 239 17 1890560 58187 89663 0 265 11 1703860 30700 92690 0 111 2 1706076 34320 77972 0 352 0 1735997 30031 92496 0 107 5 1707715 23861 89955 0 146 1 1700884 26785 92025 0 177 0 1697132 23744 92566 0 126 2 1788088 29854 74162 0 142 0 1781043 35672 92946 0 382 1 1707596 18470 91498 0 98 0 1698041 24493 92666 0 148 1 141 126617 481806 477683 20 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0

ctxt 9044786

btime 1554911733

processes 20719

procs_running 17

procs_blocked 0

softirq 35206004 0 26207552 1856 1006735 0 0 3292 1129827 0 6856742

cpu  10446621 88 14727 50040 5432 0 457 11658 0 0

cpu0 653480 0 922 2011 805 0 13 535 0 0

cpu1 652089 0 1745 2566 872 0 26 782 0 0

cpu2 653272 37 925 2511 598 0 4 735 0 0

cpu3 653620 0 807 2460 455 0 0 741 0 0

cpu4 651661 0 1390 3619 486 0 197 729 0 0

cpu5 652663 0 1318 2713 447 0 196 752 0 0

cpu6 653004 0 734 3258 340 0 1 748 0 0

cpu7 653228 0 842 2762 502 0 2 733 0 0

cpu8 653079 0 692 3446 128 0 0 733 0 0

cpu9 652811 0 729 3701 100 0 5 731 0 0

cpu10 652944 51 760 3471 119 0 3 732 0 0

cpu11 652915 0 703 3610 120 0 0 736 0 0

cpu12 652266 0 856 4120 102 0 1 734 0 0

cpu13 653092 0 777 3347 121 0 1 736 0 0

cpu14 653367 0 647 3284 40 0 1 753 0 0

cpu15 653124 0 874 3154 189 0 2 742 0 0

intr 33004598 89 9 0 0 1495 0 3 0 2 0 0 0 144 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1742594 37455 89869 0 97 336 1786791 51288 92366 0 154 25 1729977 45441 85288 0 381 44 1710194 37020 91720 0 141 68 1896595 59981 56559 0 239 17 1890835 58193 89663 0 265 11 1704118 30705 92690 0 111 2 1706348 34321 77972 0 352 0 1736251 30033 92496 0 107 5 1707971 23863 89955 0 146 1 1701145 26786 92025 0 177 0 1697391 23748 92566 0 126 2 1788355 29855 74162 0 142 0 1781306 35675 92946 0 382 1 1707855 18471 91498 0 98 0 1698298 24496 92666 0 148 1 141 126617 481820 477693 20 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0

......

查看CPU时钟频率

$ getconf CLK_TCK

100

Hertz(tick per second)就是CLK_TCK，可以根据getconf CLK_TCK获取

$ echo l &gt; /proc/sysrq-trigger

Send a SIGKILL to all processes, except for init

# 将所有的CPU正在执行进程打在了dmesg中

$ dmesg

文件：dmesg1.txt

关闭系统透明大页面

$ cat /sys/kernel/mm/transparent_hugepage/enabled

$ cat /sys/kernel/mm/transparent_hugepage/defrag

always [madvise] never

$ echo never &gt; /sys/kernel/mm/transparent_hugepage/enabled

$ echo never &gt; /sys/kernel/mm/transparent_hugepage/defrag

$ vi /etc/default/grub

$ GRUB_CMDLINE_LINUX=&#34;transparent_hugepage=never&#34;

$ source /etc/default/grub

$ update-grub

$ cat /sys/kernel/mm/transparent_hugepage/enabled

$ cat /sys/kernel/mm/transparent_hugepage/enabled

always madvise [never]

$ echo l &gt; /proc/sysrq-trigger

文件：dmesg2.txt

$ ps -ef | grep khugepaged

$ cd /proc

$ for f in `find . -name &#39;[1-9][0-9]*&#39; -maxdepth 1`; do echo $f; cat $f/comm; done

# 查看当前系统下所有正在执行的应用程序

find: warning: you have specified the -maxdepth option after a non-option argument -name, but options are not positional (-maxdepth affects tests specified before it as well as those specified after it).  Please specify options before other arguments.

./10

watchdog/0

./11

watchdog/1

./12

migration/1

./13

ksoftirqd/1

./15

kworker/1:0H

./16

watchdog/2

./17

migration/2

./18

ksoftirqd/2

./20

kworker/2:0H

./21

watchdog/3

./22

migration/3

./23

ksoftirqd/3

./25

kworker/3:0H

./26

watchdog/4

./27

migration/4

./28

ksoftirqd/4

./30

kworker/4:0H

./31

watchdog/5

./32

migration/5

./33

ksoftirqd/5

./35

kworker/5:0H

./36

watchdog/6

./37

migration/6

./38

ksoftirqd/6

./40

kworker/6:0H

./41

watchdog/7

./42

migration/7

./43

ksoftirqd/7

./45

kworker/7:0H

......

$ echo l &gt; /proc/sysrq-trigger

文件：dmesg3.txt

[  177.581904] Sending NMI to all CPUs:

[  177.583305] NMI backtrace for cpu 0

[  177.583307] CPU: 0 PID: 2495 Comm: khugepageds Not tainted 4.4.0-145-generic #171-Ubuntu

[  177.583309] Hardware name: Xen HVM domU, BIOS 4.2.amazon 08/24/2006

 ....

[  177.583334] NMI backtrace for cpu 1

[  177.583336] CPU: 1 PID: 2492 Comm: khugepageds Not tainted 4.4.0-145-generic #171-Ubuntu

[  177.583338] Hardware name: Xen HVM domU, BIOS 4.2.amazon 08/24/2006

 .....

[  177.583363] NMI backtrace for cpu 2

[  177.583365] CPU: 2 PID: 2487 Comm: khugepageds Not tainted 4.4.0-145-generic #171-Ubuntu

[  177.583367] Hardware name: Xen HVM domU, BIOS 4.2.amazon 08/24/2006

 ......

[  177.583392] NMI backtrace for cpu 3

[  177.583394] CPU: 3 PID: 2493 Comm: khugepageds Not tainted 4.4.0-145-generic #171-Ubuntu

[  177.583395] Hardware name: Xen HVM domU, BIOS 4.2.amazon 08/24/2006

......

[  177.583421] NMI backtrace for cpu 4

[  177.583422] CPU: 4 PID: 2411 Comm: bash Not tainted 4.4.0-145-generic #171-Ubuntu

[  177.583424] Hardware name: Xen HVM domU, BIOS 4.2.amazon 08/24/2006

......

[  177.583482] NMI backtrace for cpu 5

[  177.583484] CPU: 5 PID: 2497 Comm: khugepageds Not tainted 4.4.0-145-generic #171-Ubuntu

[  177.583486] Hardware name: Xen HVM domU, BIOS 4.2.amazon 08/24/2006

......

[  177.583511] NMI backtrace for cpu 6

[  177.583513] CPU: 6 PID: 2496 Comm: khugepageds Not tainted 4.4.0-145-generic #171-Ubuntu

[  177.583514] Hardware name: Xen HVM domU, BIOS 4.2.amazon 08/24/2006

......

[  177.583540] NMI backtrace for cpu 7

[  177.583541] CPU: 7 PID: 2494 Comm: khugepageds Not tainted 4.4.0-145-generic #171-Ubuntu

[  177.583543] Hardware name: Xen HVM domU, BIOS 4.2.amazon 08/24/2006

......

[  177.583568] NMI backtrace for cpu 8

[  177.583570] CPU: 8 PID: 2501 Comm: khugepageds Not tainted 4.4.0-145-generic #171-Ubuntu

[  177.583572] Hardware name: Xen HVM domU, BIOS 4.2.amazon 08/24/2006

......

[  177.583597] NMI backtrace for cpu 9

[  177.583599] CPU: 9 PID: 2488 Comm: khugepageds Not tainted 4.4.0-145-generic #171-Ubuntu

[  177.583601] Hardware name: Xen HVM domU, BIOS 4.2.amazon 08/24/2006

......

[  177.583626] NMI backtrace for cpu 10

[  177.583628] CPU: 10 PID: 2490 Comm: khugepageds Not tainted 4.4.0-145-generic #171-Ubuntu

[  177.583629] Hardware name: Xen HVM domU, BIOS 4.2.amazon 08/24/2006

......

[  177.583655] NMI backtrace for cpu 11

[  177.583656] CPU: 11 PID: 2491 Comm: khugepageds Not tainted 4.4.0-145-generic #171-Ubuntu

[  177.583658] Hardware name: Xen HVM domU, BIOS 4.2.amazon 08/24/2006

......

[  177.583684] NMI backtrace for cpu 12

[  177.583685] CPU: 12 PID: 2486 Comm: khugepageds Not tainted 4.4.0-145-generic #171-Ubuntu

[  177.583687] Hardware name: Xen HVM domU, BIOS 4.2.amazon 08/24/2006

......

[  177.583712] NMI backtrace for cpu 13

[  177.583714] CPU: 13 PID: 2500 Comm: khugepageds Not tainted 4.4.0-145-generic #171-Ubuntu

[  177.583716] Hardware name: Xen HVM domU, BIOS 4.2.amazon 08/24/2006

......

[  177.583741] NMI backtrace for cpu 14

[  177.583743] CPU: 14 PID: 2499 Comm: khugepageds Not tainted 4.4.0-145-generic #171-Ubuntu

[  177.583744] Hardware name: Xen HVM domU, BIOS 4.2.amazon 08/24/2006

......

[  177.583770] NMI backtrace for cpu 15

[  177.583772] CPU: 15 PID: 2489 Comm: khugepageds Not tainted 4.4.0-145-generic #171-Ubuntu

[  177.583773] Hardware name: Xen HVM domU, BIOS 4.2.amazon 08/24/2006

......

从上述日志可以看出 khugepageds 分别在0、1、2、3、5、6、7、8、9、10、11、12、13、14、15上执行，唯独没有在CPU 的第4个core上存在，与top命令显示只有一个CPU在运行吻合

从上面的日志中，根据cpu13中的PID找出对应的应用程序

$ ls /proc | grep 2500

khugepageds

[ 1035.043542] NMI backtrace for cpu 6

[ 1035.043544] CPU: 6 PID: 2493 Comm: khugepageds Not tainted 4.4.0-145-generic #171-Ubuntu

[ 1035.043545] Hardware name: Xen HVM domU, BIOS 4.2.amazon 08/24/2006

。。。。。。
</code></pre><p>根据&quot;khugepageds&quot;关键字google搜索出相关资料,发现居然是和一个挖矿病毒有关，此病毒相关资料：</p>
<p><a href="https://stackoverflow.com/questions/55318938/jenkins-high-cpu-usage-khugepageds">https://stackoverflow.com/questions/55318938/jenkins-high-cpu-usage-khugepageds</a></p>
<p><a href="https://laucyun.com/17e194c26e4554cab975aae760bad553.html">https://laucyun.com/17e194c26e4554cab975aae760bad553.html</a></p>
<p>最后查出是confluence漏洞导致</p>
<p><a href="https://community.atlassian.com/t5/Confluence-discussions/khugepageds-eating-all-of-the-CPU/td-p/1055337">https://community.atlassian.com/t5/Confluence-discussions/khugepageds-eating-all-of-the-CPU/td-p/1055337</a></p>
<p><a href="https://confluence.atlassian.com/doc/confluence-security-advisory-2019-03-20-966660264.html?_ga=2.65341993.660720501.1556073417-575823134.1554929090">https://confluence.atlassian.com/doc/confluence-security-advisory-2019-03-20-966660264.html?_ga=2.65341993.660720501.1556073417-575823134.1554929090</a></p>
<p>从上面的URL得知因为confluence漏洞导致感染挖矿病毒，知道是什么病毒就好解决了，继续google找到清理这个病毒的资料：</p>
<p><a href="https://git.laucyun.com/security/lsd_malware_clean_tool/blob/master/README.md">https://git.laucyun.com/security/lsd_malware_clean_tool/blob/master/README.md</a></p>
<p><a href="https://git.laucyun.com/security/lsd_malware_clean_tool/blob/master/clear_kerberods.sh">https://git.laucyun.com/security/lsd_malware_clean_tool/blob/master/clear_kerberods.sh</a></p>
<p>至此，按上面文档清理病毒，打上confluence漏洞补丁，搞定问题。</p>
<h2 id="总结">总结</h2>
<p>开源的一些软件漏洞都比较多（wordpress。。。），注意关注官方重大提醒。
最后强调，备份，备份，备份！</p>
]]></content>
		</item>
		
		<item>
			<title>Go语言学习</title>
			<link>http://www.heyuan110.com/posts/go/talk/2019-01-25-learn-go/</link>
			<pubDate>Fri, 25 Jan 2019 21:13:19 +0000</pubDate>
			
			<guid>http://www.heyuan110.com/posts/go/talk/2019-01-25-learn-go/</guid>
			<description>前言 Go语言(或Golang)是Google在2007年开发的一种开源编程语言,于2009年11月10日向全球公布,2012年早些时候发布了Go 1稳定版本。现在Go的开发已经是完全开放的，并且拥有一个活跃的社区。
GO部署简单、并发性好、语言设计良好、执行性能好
一、GO语言结构 Go语言的基础组成有一下几个部分：
包声明 引入包 函数 变量 语句和表达式 注释 例子：
//定义包名 package main //引入fmt包 import &amp;#34;fmt&amp;#34; //定义函数, main为入口函数 func main() { /* 这是我的第一个简单的程序，我是注释 */ fmt.Println(&amp;#34;Hello, World!&amp;#34;) } 二、Go基础语法 行分隔符：一行代表一个语句结束，无需；号结尾 注释：单行//，多行/**/ 标识符关键字：标识符用来命名变量、类型等程序实体，第一个字符必须是字母或下划线而不能是数字 关键字： 25 个关键字或保留字 36 个预定义标识符 空格：声明必须使用空格隔开，变量与运算符间加入空格，程序看起来更加美观 1.数据类型 数据类型用于声明函数和变量。 数据类型的出现是为了把数据分成所需内存大小不同的数据，编程的时候需要用大数据的时候才需要申请大内存，就可以充分利用内存。
Go按类别划分有以下集中数据类型:
布尔型(BOOL) 布尔型的值只可以是常量 true 或者 false。一个简单的例子：var b bool = true。
数字类型 整型 int 和浮点型 float32、float64. 整型包含： 浮点型： 其他数字类型 字符串类型 字符串就是一串固定长度的字符连接起来的字符序列。 Go 的字符串是由单个字节连接起来的，字节使用 UTF-8 编码标识 Unicode 文本。</description>
			<content type="html"><![CDATA[<p><img src="/images/learn-golang/go.jpg" alt="image"></p>
<h2 id="前言">前言</h2>
<p>Go语言(或Golang)是Google在2007年开发的一种开源编程语言,于2009年11月10日向全球公布,2012年早些时候发布了Go 1稳定版本。现在Go的开发已经是完全开放的，并且拥有一个活跃的社区。</p>
<p><code>GO部署简单、并发性好、语言设计良好、执行性能好</code></p>
<h2 id="一go语言结构">一、GO语言结构</h2>
<p>Go语言的基础组成有一下几个部分：</p>
<ul>
<li>包声明</li>
<li>引入包</li>
<li>函数</li>
<li>变量</li>
<li>语句和表达式</li>
<li>注释</li>
</ul>
<p>例子：</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-go" data-lang="go"><span class="line"><span class="cl"><span class="c1">//定义包名
</span></span></span><span class="line"><span class="cl"><span class="c1"></span><span class="kn">package</span> <span class="nx">main</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1">//引入fmt包
</span></span></span><span class="line"><span class="cl"><span class="c1"></span><span class="kn">import</span> <span class="s">&#34;fmt&#34;</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1">//定义函数, main为入口函数
</span></span></span><span class="line"><span class="cl"><span class="c1"></span><span class="kd">func</span> <span class="nf">main</span><span class="p">()</span> <span class="p">{</span>
</span></span><span class="line"><span class="cl">   <span class="cm">/* 这是我的第一个简单的程序，我是注释 */</span>
</span></span><span class="line"><span class="cl">   <span class="nx">fmt</span><span class="p">.</span><span class="nf">Println</span><span class="p">(</span><span class="s">&#34;Hello, World!&#34;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="p">}</span>
</span></span></code></pre></div><h2 id="二go基础语法">二、Go基础语法</h2>
<ul>
<li>行分隔符：一行代表一个语句结束，无需；号结尾</li>
<li>注释：单行//，多行/**/</li>
<li>标识符关键字：标识符用来命名变量、类型等程序实体，第一个字符必须是字母或下划线而不能是数字</li>
<li>关键字： 25 个关键字或保留字
<img src="/images/learn-golang/15483971756507.jpg" alt="">
36 个预定义标识符
<img src="/images/learn-golang/15483972014339.jpg" alt=""></li>
<li>空格：声明必须使用空格隔开，变量与运算符间加入空格，程序看起来更加美观</li>
</ul>
<h3 id="1数据类型">1.数据类型</h3>
<p>数据类型用于声明函数和变量。
数据类型的出现是为了<strong>把数据分成所需内存大小不同的数据</strong>，编程的时候需要用大数据的时候才需要申请大内存，就可以充分利用内存。</p>
<p>Go按类别划分有以下集中数据类型:</p>
<ul>
<li>布尔型(BOOL)</li>
</ul>
<p>布尔型的值只可以是常量 true 或者 false。一个简单的例子：var b bool = true。</p>
<ul>
<li>数字类型</li>
</ul>
<p>整型 int 和浮点型 float32、float64.
整型包含：
<img src="/images/learn-golang/15483985088545.jpg" alt="">
浮点型：
<img src="/images/learn-golang/15483985320227.jpg" alt=""></p>
<p>其他数字类型
<img src="/images/learn-golang/15483985582507.jpg" alt=""></p>
<ul>
<li>字符串类型</li>
</ul>
<p>字符串就是一串固定长度的字符连接起来的字符序列。
Go 的字符串是由单个字节连接起来的，字节使用 UTF-8 编码标识 Unicode 文本。</p>
<ul>
<li>派生类型
<ul>
<li>指针类型(Pointer)</li>
<li>数组类型</li>
<li>结构化类型(struct)</li>
<li>Channel类型</li>
<li>函数类型</li>
<li>切片类型</li>
<li>接口类型(interface)</li>
<li>Map类型</li>
</ul>
</li>
</ul>
<h3 id="2变量">2.变量</h3>
<p>变量名由字母、数字、下划线组成，其中首个字符不能为数字</p>
<p>申明变量的三种格式:</p>
<ul>
<li>指定变量类型，声明后若不赋值，使用默认值</li>
</ul>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-go" data-lang="go"><span class="line"><span class="cl"><span class="kd">var</span> <span class="nx">v_name</span> <span class="nx">v_type</span>
</span></span><span class="line"><span class="cl"><span class="nx">v_name</span> <span class="p">=</span> <span class="nx">value</span>
</span></span></code></pre></div><ul>
<li>根据值自行判定变量类型： var v_name = value</li>
<li>省略var, 注意 :=左侧的变量不应该是已经声明过的，否则会导致编译错误</li>
</ul>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-go" data-lang="go"><span class="line"><span class="cl"><span class="nx">v_name</span> <span class="o">:=</span> <span class="nx">value</span>
</span></span><span class="line"><span class="cl"><span class="err">例如</span>
</span></span><span class="line"><span class="cl"><span class="nx">x</span> <span class="o">:=</span> <span class="mi">10</span>
</span></span></code></pre></div><p>多变量声明</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-go" data-lang="go"><span class="line"><span class="cl"><span class="kd">var</span> <span class="nx">vname1</span><span class="p">,</span> <span class="nx">vname2</span><span class="p">,</span> <span class="nx">vname3</span> <span class="kd">type</span>
</span></span><span class="line"><span class="cl"><span class="nx">vname1</span><span class="p">,</span> <span class="nx">vname2</span><span class="p">,</span> <span class="nx">vname3</span> <span class="p">=</span> <span class="nx">v1</span><span class="p">,</span> <span class="nx">v2</span><span class="p">,</span> <span class="nx">v3</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1">//和python很像,不需要显示声明类型，自动推断
</span></span></span><span class="line"><span class="cl"><span class="c1"></span><span class="kd">var</span> <span class="nx">vname1</span><span class="p">,</span> <span class="nx">vname2</span><span class="p">,</span> <span class="nx">vname3</span> <span class="p">=</span> <span class="nx">v1</span><span class="p">,</span> <span class="nx">v2</span><span class="p">,</span> <span class="nx">v3</span> 
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1">//出现在:=左侧的变量不应该是已经被声明过的，否则会导致编译错误
</span></span></span><span class="line"><span class="cl"><span class="c1"></span><span class="nx">vname1</span><span class="p">,</span> <span class="nx">vname2</span><span class="p">,</span> <span class="nx">vname3</span> <span class="o">:=</span> <span class="nx">v1</span><span class="p">,</span> <span class="nx">v2</span><span class="p">,</span> <span class="nx">v3</span> 
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1">// 这种因式分解关键字的写法一般用于声明全局变量
</span></span></span><span class="line"><span class="cl"><span class="c1"></span><span class="kd">var</span> <span class="p">(</span>
</span></span><span class="line"><span class="cl">    <span class="nx">vname1</span> <span class="nx">v_type1</span>
</span></span><span class="line"><span class="cl">    <span class="nx">vname2</span> <span class="nx">v_type2</span>
</span></span><span class="line"><span class="cl"><span class="p">)</span>
</span></span></code></pre></div><p>局部变量声明后如果没有使用编译时会报错。</p>
<h3 id="3常量">3.常量</h3>
<p>常量是一个简单值的标识符，在程序运行时，不会被修改的量。
常量中的数据类型只可以是布尔型、数字型（整数型、浮点型和复数）和字符串型。</p>
<ul>
<li>定义常量的格式：<code>const identifier [type] = value</code></li>
</ul>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-go" data-lang="go"><span class="line"><span class="cl"><span class="o">-</span> <span class="err">显式类型定义：</span> <span class="kd">const</span> <span class="nx">b</span> <span class="kt">string</span> <span class="p">=</span> <span class="s">&#34;abc&#34;</span>
</span></span><span class="line"><span class="cl"><span class="o">-</span> <span class="err">隐式类型定义：</span> <span class="kd">const</span> <span class="nx">b</span> <span class="p">=</span> <span class="s">&#34;abc&#34;</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="err">例如</span>
</span></span><span class="line"><span class="cl"><span class="kd">const</span> <span class="nx">LENGTH</span> <span class="kt">int</span> <span class="p">=</span> <span class="mi">10</span> 
</span></span><span class="line"><span class="cl"><span class="kd">const</span> <span class="nx">WIDTH</span> <span class="p">=</span> <span class="mi">10</span> 
</span></span></code></pre></div><ul>
<li>常量可以用作枚举，例如：</li>
</ul>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-go" data-lang="go"><span class="line"><span class="cl"><span class="kd">const</span> <span class="p">(</span>
</span></span><span class="line"><span class="cl">    <span class="nx">Unknown</span> <span class="p">=</span> <span class="mi">0</span>
</span></span><span class="line"><span class="cl">    <span class="nx">Female</span> <span class="p">=</span> <span class="mi">1</span>
</span></span><span class="line"><span class="cl">    <span class="nx">Male</span> <span class="p">=</span> <span class="mi">2</span>
</span></span><span class="line"><span class="cl"><span class="p">)</span>
</span></span></code></pre></div><ul>
<li>常量可以用函数（必须是内置函数）计算表达式的值，例如len(), cap(), unsafe.Sizeof()等函数。</li>
</ul>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-go" data-lang="go"><span class="line"><span class="cl"><span class="kn">package</span> <span class="nx">main</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="kn">import</span> <span class="s">&#34;unsafe&#34;</span>
</span></span><span class="line"><span class="cl"><span class="kd">const</span> <span class="p">(</span>
</span></span><span class="line"><span class="cl">    <span class="nx">a</span> <span class="p">=</span> <span class="s">&#34;abc&#34;</span>
</span></span><span class="line"><span class="cl">    <span class="nx">b</span> <span class="p">=</span> <span class="nb">len</span><span class="p">(</span><span class="nx">a</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="nx">c</span> <span class="p">=</span> <span class="nx">unsafe</span><span class="p">.</span><span class="nf">Sizeof</span><span class="p">(</span><span class="nx">a</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="kd">func</span> <span class="nf">main</span><span class="p">(){</span>
</span></span><span class="line"><span class="cl">    <span class="nb">println</span><span class="p">(</span><span class="nx">a</span><span class="p">,</span> <span class="nx">b</span><span class="p">,</span> <span class="nx">c</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="p">}</span>
</span></span></code></pre></div><ul>
<li>iota常量
特殊常量，可以认为是一个可以被编译器修改的常量
iota在const关键字出现时将被重置为0(const内部的第一行之前)，const中每新增一行常量声明将使iota计数一次(iota可理解为const语句块中的<strong>行索引</strong>)</li>
</ul>
<p>用作枚举值：</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-go" data-lang="go"><span class="line"><span class="cl"><span class="kd">const</span> <span class="p">(</span>
</span></span><span class="line"><span class="cl">    <span class="nx">a</span> <span class="p">=</span> <span class="kc">iota</span> <span class="c1">//0
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>    <span class="nx">b</span> <span class="p">=</span> <span class="kc">iota</span> <span class="c1">//1
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>    <span class="nx">c</span> <span class="p">=</span> <span class="kc">iota</span> <span class="c1">//2
</span></span></span><span class="line"><span class="cl"><span class="c1"></span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="err">可简写</span>
</span></span><span class="line"><span class="cl"><span class="kd">const</span> <span class="p">(</span>
</span></span><span class="line"><span class="cl">    <span class="nx">a</span> <span class="p">=</span> <span class="kc">iota</span>
</span></span><span class="line"><span class="cl">    <span class="nx">b</span>
</span></span><span class="line"><span class="cl">    <span class="nx">c</span>
</span></span><span class="line"><span class="cl"><span class="p">)</span>
</span></span></code></pre></div><h3 id="4运算符">4.运算符</h3>
<ul>
<li>
<p>算术运算符
假定 A 值为 10，B 值为 20
<img src="/images/learn-golang/15484031841274.jpg" alt=""></p>
</li>
<li>
<p>关系运算符
假定 A 值为 10，B 值为 20。
<img src="/images/learn-golang/15484032595654.jpg" alt=""></p>
</li>
<li>
<p>逻辑运算符
假定 A 值为 True，B 值为 False
<img src="/images/learn-golang/15484033088693.jpg" alt=""></p>
</li>
<li>
<p>位运算符</p>
</li>
</ul>
<p>位运算符对整数在内存中的二进制位进行操作,假定 A 为60，B 为13
<img src="/images/learn-golang/15484034266782.jpg" alt=""></p>
<p>注意右移n位时除以2的n次方对负数无效。</p>
<p>下表列出了位运算符 &amp;, |, 和 ^ 的计算：
<img src="/images/learn-golang/15484035756694.jpg" alt=""></p>
<p>假定 A = 60; B = 13; 其二进制数转换为：
<img src="/images/learn-golang/15484036026004.jpg" alt=""></p>
<ul>
<li>
<p>赋值运算符
<img src="/images/learn-golang/15484039516433.jpg" alt=""></p>
</li>
<li>
<p>其他运算符
<img src="/images/learn-golang/15484039839342.jpg" alt=""></p>
<pre tabindex="0"><code>package main

import &#34;fmt&#34;

func main() {
   var a int = 4
   var b int32
   var c float32
   var ptr *int

   /* 运算符实例 */
   fmt.Printf(&#34;第 1 行 - a 变量类型为 = %T\n&#34;, a );
   fmt.Printf(&#34;第 2 行 - b 变量类型为 = %T\n&#34;, b );
   fmt.Printf(&#34;第 3 行 - c 变量类型为 = %T\n&#34;, c );

   /*  &amp; 和 * 运算符实例 */
   ptr = &amp;a    /* &#39;ptr&#39; 包含了 &#39;a&#39; 变量的地址 */
   fmt.Printf(&#34;a 的值为  %d\n&#34;, a);
   fmt.Printf(&#34;*ptr 为 %d\n&#34;, *ptr);
}
</code></pre></li>
<li>
<p>优先级</p>
</li>
</ul>
<p>有些运算符拥有较高的优先级，二元运算符的运算方向均是从左至右.下表列出了所有运算符以及它们的优先级，由上至下代表优先级由高到低</p>
<p><img src="/images/learn-golang/15484105551893.jpg" alt=""></p>
<p>可以通过使用括号来临时提升某个表达式的整体运算优先级</p>
<h3 id="5条件语句">5.条件语句</h3>
<p>条件语句的结构：
<img src="/images/learn-golang/15484106537473.jpg" alt=""></p>
<p>GO提供以下条件判断语句
<img src="/images/learn-golang/15484106379972.jpg" alt=""></p>
<p>if&hellip;else， switch例句</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-go" data-lang="go"><span class="line"><span class="cl">   <span class="k">if</span> <span class="nx">a</span> <span class="p">&lt;</span> <span class="mi">20</span> <span class="p">{</span>
</span></span><span class="line"><span class="cl">       <span class="cm">/* 如果条件为 true 则执行以下语句 */</span>
</span></span><span class="line"><span class="cl">       <span class="nx">fmt</span><span class="p">.</span><span class="nf">Printf</span><span class="p">(</span><span class="s">&#34;a 小于 20\n&#34;</span> <span class="p">);</span>
</span></span><span class="line"><span class="cl">   <span class="p">}</span> <span class="k">else</span> <span class="p">{</span>
</span></span><span class="line"><span class="cl">       <span class="cm">/* 如果条件为 false 则执行以下语句 */</span>
</span></span><span class="line"><span class="cl">       <span class="nx">fmt</span><span class="p">.</span><span class="nf">Printf</span><span class="p">(</span><span class="s">&#34;a 不小于 20\n&#34;</span> <span class="p">);</span>
</span></span><span class="line"><span class="cl">   <span class="p">}</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">   <span class="k">switch</span> <span class="p">{</span>
</span></span><span class="line"><span class="cl">      <span class="k">case</span> <span class="nx">grade</span> <span class="o">==</span> <span class="s">&#34;A&#34;</span> <span class="p">:</span>
</span></span><span class="line"><span class="cl">         <span class="nx">fmt</span><span class="p">.</span><span class="nf">Printf</span><span class="p">(</span><span class="s">&#34;优秀!\n&#34;</span> <span class="p">)</span>     
</span></span><span class="line"><span class="cl">      <span class="k">case</span> <span class="nx">grade</span> <span class="o">==</span> <span class="s">&#34;B&#34;</span><span class="p">,</span> <span class="nx">grade</span> <span class="o">==</span> <span class="s">&#34;C&#34;</span> <span class="p">:</span>
</span></span><span class="line"><span class="cl">         <span class="nx">fmt</span><span class="p">.</span><span class="nf">Printf</span><span class="p">(</span><span class="s">&#34;良好\n&#34;</span> <span class="p">)</span>      
</span></span><span class="line"><span class="cl">      <span class="k">case</span> <span class="nx">grade</span> <span class="o">==</span> <span class="s">&#34;D&#34;</span> <span class="p">:</span>
</span></span><span class="line"><span class="cl">         <span class="nx">fmt</span><span class="p">.</span><span class="nf">Printf</span><span class="p">(</span><span class="s">&#34;及格\n&#34;</span> <span class="p">)</span>      
</span></span><span class="line"><span class="cl">      <span class="k">case</span> <span class="nx">grade</span> <span class="o">==</span> <span class="s">&#34;F&#34;</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">         <span class="nx">fmt</span><span class="p">.</span><span class="nf">Printf</span><span class="p">(</span><span class="s">&#34;不及格\n&#34;</span> <span class="p">)</span>
</span></span><span class="line"><span class="cl">      <span class="k">default</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">         <span class="nx">fmt</span><span class="p">.</span><span class="nf">Printf</span><span class="p">(</span><span class="s">&#34;差\n&#34;</span> <span class="p">);</span>
</span></span><span class="line"><span class="cl">   <span class="p">}</span>
</span></span><span class="line"><span class="cl">   
</span></span></code></pre></div><p>select是Go中的一个控制结构，类似于用于通信的switch语句。每个case必须是一个通信操作，要么是发送要么是接收。
select随机执行一个可运行的case。如果没有case可运行，它将阻塞，直到有case可运行。一个默认的子句应该总是可运行的。</p>
<h3 id="6循环语句">6.循环语句</h3>
<p>循环程序的流程图
<img src="/images/learn-golang/15484112508588.jpg" alt=""></p>
<p>for在go语言中3种形式</p>
<ul>
<li>for init; condition; post { }</li>
<li>for condition { }</li>
<li>for { }</li>
</ul>
<p>init： 一般为赋值表达式，给控制变量赋初值；
condition： 关系表达式或逻辑表达式，循环控制条件；
post： 一般为赋值表达式，给控制变量增量或减量。</p>
<p>for 循环的 range 格式可以对 slice、map、数组、字符串等进行迭代循环。格式如下：</p>
<pre tabindex="0"><code>for key, value := range oldMap {
    newMap[key] = value
}
</code></pre><p>for使用实例:</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-go" data-lang="go"><span class="line"><span class="cl"><span class="kn">package</span> <span class="nx">main</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="kn">import</span> <span class="s">&#34;fmt&#34;</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="kd">func</span> <span class="nf">main</span><span class="p">()</span> <span class="p">{</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">   <span class="kd">var</span> <span class="nx">b</span> <span class="kt">int</span> <span class="p">=</span> <span class="mi">15</span>
</span></span><span class="line"><span class="cl">   <span class="kd">var</span> <span class="nx">a</span> <span class="kt">int</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">   <span class="nx">numbers</span> <span class="o">:=</span> <span class="p">[</span><span class="mi">6</span><span class="p">]</span><span class="kt">int</span><span class="p">{</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">5</span><span class="p">}</span> 
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">   <span class="cm">/* for 循环 */</span>
</span></span><span class="line"><span class="cl">   <span class="k">for</span> <span class="nx">a</span> <span class="o">:=</span> <span class="mi">0</span><span class="p">;</span> <span class="nx">a</span> <span class="p">&lt;</span> <span class="mi">10</span><span class="p">;</span> <span class="nx">a</span><span class="o">++</span> <span class="p">{</span>
</span></span><span class="line"><span class="cl">      <span class="nx">fmt</span><span class="p">.</span><span class="nf">Printf</span><span class="p">(</span><span class="s">&#34;a 的值为: %d\n&#34;</span><span class="p">,</span> <span class="nx">a</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">   <span class="p">}</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">   <span class="k">for</span> <span class="nx">a</span> <span class="p">&lt;</span> <span class="nx">b</span> <span class="p">{</span>
</span></span><span class="line"><span class="cl">      <span class="nx">a</span><span class="o">++</span>
</span></span><span class="line"><span class="cl">      <span class="nx">fmt</span><span class="p">.</span><span class="nf">Printf</span><span class="p">(</span><span class="s">&#34;a 的值为: %d\n&#34;</span><span class="p">,</span> <span class="nx">a</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">   <span class="p">}</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">   <span class="k">for</span> <span class="nx">i</span><span class="p">,</span><span class="nx">x</span><span class="o">:=</span> <span class="k">range</span> <span class="nx">numbers</span> <span class="p">{</span>
</span></span><span class="line"><span class="cl">      <span class="nx">fmt</span><span class="p">.</span><span class="nf">Printf</span><span class="p">(</span><span class="s">&#34;第 %d 位 x 的值 = %d\n&#34;</span><span class="p">,</span> <span class="nx">i</span><span class="p">,</span><span class="nx">x</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">   <span class="p">}</span>   
</span></span><span class="line"><span class="cl"><span class="p">}</span>
</span></span></code></pre></div><h3 id="7函数">7.函数</h3>
<p>函数是基本的代码块，用于执行一个任务，go程序最少有一个main()函数</p>
<ul>
<li>函数定义:</li>
</ul>
<pre tabindex="0"><code>func function_name( [parameter list] ) [return_types] {
   函数体
}

func：函数由 func 开始声明
function_name：函数名称，函数名和参数列表一起构成了函数签名。
parameter list：参数列表，参数就像一个占位符，当函数被调用时，你可以将值传递给参数，这个值被称为实际参数。参数列表指定的是参数类型、顺序、及参数个数。参数是可选的，也就是说函数也可以不包含参数。
return_types：返回类型，函数返回一列值。return_types 是该列值的数据类型。有些功能不需要返回值，这种情况下 return_types 不是必须的。
函数体：函数定义的代码集合。
</code></pre><p>实例:</p>
<pre tabindex="0"><code>/* 函数返回两个数的最大值 */
func max(num1, num2 int) int {
   /* 声明局部变量 */
   var result int

   if (num1 &gt; num2) {
      result = num1
   } else {
      result = num2
   }
   return result 
}
</code></pre><ul>
<li>函数调用、返回多值</li>
</ul>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-go" data-lang="go"><span class="line"><span class="cl"><span class="kn">package</span> <span class="nx">main</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="kn">import</span> <span class="s">&#34;fmt&#34;</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="kd">func</span> <span class="nf">swap</span><span class="p">(</span><span class="nx">x</span><span class="p">,</span> <span class="nx">y</span> <span class="kt">string</span><span class="p">)</span> <span class="p">(</span><span class="kt">string</span><span class="p">,</span> <span class="kt">string</span><span class="p">)</span> <span class="p">{</span>
</span></span><span class="line"><span class="cl">   <span class="k">return</span> <span class="nx">y</span><span class="p">,</span> <span class="nx">x</span>
</span></span><span class="line"><span class="cl"><span class="p">}</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="kd">func</span> <span class="nf">main</span><span class="p">()</span> <span class="p">{</span>
</span></span><span class="line"><span class="cl">   <span class="nx">a</span><span class="p">,</span> <span class="nx">b</span> <span class="o">:=</span> <span class="nf">swap</span><span class="p">(</span><span class="s">&#34;Mahesh&#34;</span><span class="p">,</span> <span class="s">&#34;Kumar&#34;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">   <span class="nx">fmt</span><span class="p">.</span><span class="nf">Println</span><span class="p">(</span><span class="nx">a</span><span class="p">,</span> <span class="nx">b</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="p">}</span>
</span></span></code></pre></div><ul>
<li>函数参数</li>
</ul>
<p>函数如果使用参数，该变量可称为函数的形参。
两种方式传参:
(a) 值传递</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-go" data-lang="go"><span class="line"><span class="cl"><span class="cm">/* 定义相互交换值的函数 */</span>
</span></span><span class="line"><span class="cl"><span class="kd">func</span> <span class="nf">swap</span><span class="p">(</span><span class="nx">x</span><span class="p">,</span> <span class="nx">y</span> <span class="kt">int</span><span class="p">)</span> <span class="kt">int</span> <span class="p">{</span>
</span></span><span class="line"><span class="cl">   <span class="kd">var</span> <span class="nx">temp</span> <span class="kt">int</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">   <span class="nx">temp</span> <span class="p">=</span> <span class="nx">x</span> <span class="cm">/* 保存 x 的值 */</span>
</span></span><span class="line"><span class="cl">   <span class="nx">x</span> <span class="p">=</span> <span class="nx">y</span>    <span class="cm">/* 将 y 值赋给 x */</span>
</span></span><span class="line"><span class="cl">   <span class="nx">y</span> <span class="p">=</span> <span class="nx">temp</span> <span class="cm">/* 将 temp 值赋给 y*/</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">   <span class="k">return</span> <span class="nx">temp</span><span class="p">;</span>
</span></span><span class="line"><span class="cl"><span class="p">}</span>
</span></span></code></pre></div><p>(b) 引用传递</p>
<pre tabindex="0"><code>/* 定义交换值函数*/
func swap(x *int, y *int) {
   var temp int
   temp = *x    /* 保持 x 地址上的值 */
   *x = *y      /* 将 y 值赋给 x */
   *y = temp    /* 将 temp 值赋给 y */
}
</code></pre><ul>
<li>函数用法</li>
</ul>
<p>(a)函数作为值: 函数定义后可作为值来使用</p>
<pre tabindex="0"><code>package main

import (
   &#34;fmt&#34;
   &#34;math&#34;
)

func main(){
   /* 声明函数变量 */
   getSquareRoot := func(x float64) float64 {
      return math.Sqrt(x)
   }

   /* 使用函数 */
   fmt.Println(getSquareRoot(9)
}
</code></pre><p>(b)闭包:闭包是匿名函数，可在动态编程中使用</p>
<pre tabindex="0"><code>package main

import &#34;fmt&#34;

func getSequence() func() int {
   i:=0
   return func() int {
      i+=1
     return i  
   }
}

func main(){
   /* nextNumber 为一个函数，函数 i 为 0 */
   nextNumber := getSequence()  

   /* 调用 nextNumber 函数，i 变量自增 1 并返回 */
   fmt.Println(nextNumber())
   fmt.Println(nextNumber())
   fmt.Println(nextNumber())
   
   /* 创建新的函数 nextNumber1，并查看结果 */
   nextNumber1 := getSequence()  
   fmt.Println(nextNumber1())
   fmt.Println(nextNumber1())
}
</code></pre><p>(c)方法:方法就是一个包含了接受者的函数</p>
<p>定类型的方法属于该类型的方法集,语法格式:</p>
<pre tabindex="0"><code>func (variable_name variable_data_type) function_name() [return_type]{
   /* 函数体*/
}
</code></pre><p>实例:</p>
<pre tabindex="0"><code>package main

import (
   &#34;fmt&#34;  
)

/* 定义结构体 */
type Circle struct {
  radius float64
}

func main() {
  var c1 Circle
  c1.radius = 10.00
  fmt.Println(&#34;圆的面积 = &#34;, c1.getArea())
}

//该 method 属于 Circle 类型对象中的方法
func (c Circle) getArea() float64 {
  //c.radius 即为 Circle 类型对象中的属性
  return 3.14 * c.radius * c.radius
}
</code></pre><h3 id="8变量作用域">8.变量作用域</h3>
<ul>
<li>局部变量</li>
<li>全局变量</li>
<li>形式参数</li>
</ul>
<h3 id="9数组">9.数组</h3>
<p>数组是具有相同唯一类型的一组已编号且长度固定的数据项序列
数组元素可以通过索引（位置）来读取（或者修改），索引从0开始，第一个元素索引为 0，第二个索引为 1，以此类推。
<img src="/images/learn-golang/15487334966945.jpg" alt=""></p>
<ul>
<li>声明</li>
</ul>
<p>数组声明需要指定元素类型及元素个数，语法格式：<code>var variable_name [SIZE] variable_type</code></p>
<p>例如定义一个数组 balance 长度为 10 类型为 float32：<code>var balance [10] float32</code></p>
<ul>
<li>初始化</li>
</ul>
<p>初始化数组中 {} 中的元素个数不能大于 [] 中的数字。</p>
<p><code>var balance = [5]float32{1000.0, 2.0, 3.4, 7.0, 50.0}</code></p>
<p>可省略[]里的数字</p>
<p><code> var balance = [...]float32{1000.0, 2.0, 3.4, 7.0, 50.0}</code></p>
<ul>
<li>读取和赋值数组元素</li>
</ul>
<p>数组元素通过索引读取，实例：</p>
<pre tabindex="0"><code>package main

import &#34;fmt&#34;

func main() {
   var n [10]int /* n 是一个长度为 10 的数组 */
   var i,j int

   /* 为数组 n 初始化元素 */         
   for i = 0; i &lt; 10; i++ {
      n[i] = i + 100 /* 设置元素为 i + 100 */
   }

   /* 输出每个数组元素的值 */
   for j = 0; j &lt; 10; j++ {
      fmt.Printf(&#34;Element[%d] = %d\n&#34;, j, n[j] )
   }
}
</code></pre><ul>
<li>多维数组</li>
</ul>
<p>常用的多维数组声明方式：<code>var variable_name [SIZE1][SIZE2]...[SIZEN] variable_type </code>，例如：<code>var threedim [5][10][4]int</code></p>
<p>初始化多维数组:</p>
<pre tabindex="0"><code>a = [3][4]int{  
 {0, 1, 2, 3} ,   /*  第一行索引为 0 */
 {4, 5, 6, 7} ,   /*  第二行索引为 1 */
 {8, 9, 10, 11},   /* 第三行索引为 2 */
}
</code></pre><p>多维数组实例:</p>
<pre tabindex="0"><code>package main

import &#34;fmt&#34;

func main() {
   /* 数组 - 5 行 2 列*/
   var a = [5][2]int{ {0,0}, {1,2}, {2,4}, {3,6},{4,8}}
   var i, j int

   /* 输出数组元素 */
   for  i = 0; i &lt; 5; i++ {
      for j = 0; j &lt; 2; j++ {
         fmt.Printf(&#34;a[%d][%d] = %d\n&#34;, i,j, a[i][j] )
      }
   }
}
</code></pre><h3 id="10指针">10.指针</h3>
<ul>
<li>定义</li>
</ul>
<p>一个指针变量指向了一个值的内存地址，在使用指针前你需要声明指针</p>
<p>格式：<code>var var_name *var-type</code></p>
<p>var-type 为指针类型，var_name 为指针变量名，* 号用于指定变量是作为一个指针。以下是有效的指针声明：</p>
<pre tabindex="0"><code>var ip *int        /* 指向整型*/
var fp *float32    /* 指向浮点型 */
</code></pre><pre tabindex="0"><code>package main

import &#34;fmt&#34;

func main() {
   var a int= 20   /* 声明实际变量 */
   var ip *int        /* 声明指针变量 */

   ip = &amp;a  /* 指针变量的存储地址 */

   fmt.Printf(&#34;a 变量的地址是: %x\n&#34;, &amp;a  )

   /* 指针变量的存储地址 */
   fmt.Printf(&#34;ip 变量储存的指针地址: %x\n&#34;, ip )

   /* 使用指针访问值 */
   fmt.Printf(&#34;*ip 变量的值: %d\n&#34;, *ip )
}
</code></pre><ul>
<li>空指针</li>
</ul>
<p>当一个指针被定义后没有分配到任何变量时，它的值为 nil，nil指针也称为空指针, 一个指针变量通常缩写为ptr。</p>
<p>实例：</p>
<pre tabindex="0"><code>package main

import &#34;fmt&#34;

func main() {
   var  ptr *int

   fmt.Printf(&#34;ptr 的值为 : %x\n&#34;, ptr  )
}
</code></pre><p>判断空指针</p>
<pre tabindex="0"><code>if(ptr != nil)     /* ptr 不是空指针 */
if(ptr == nil)    /* ptr 是空指针 */
</code></pre><ul>
<li>指针数组</li>
</ul>
<pre tabindex="0"><code>ackage main

import &#34;fmt&#34;

const MAX int = 3

func main() {
   a := []int{10,100,200}
   var i int
   var ptr [MAX]*int;

   for  i = 0; i &lt; MAX; i++ {
      ptr[i] = &amp;a[i] /* 整数地址赋值给指针数组 */
   }

   for  i = 0; i &lt; MAX; i++ {
      fmt.Printf(&#34;a[%d] = %d\n&#34;, i,*ptr[i] )
   }
}
</code></pre><ul>
<li>指向指针的指针</li>
</ul>
<p>如果一个指针变量存放的又是另一个指针变量的地址，则称这个指针变量为指向指针的指针变量。</p>
<p>当定义一个指向指针的指针变量时，第一个指针存放第二个指针的地址，第二个指针存放变量的地址：
<img src="/images/learn-golang/15487422095707.jpg" alt=""></p>
<p>指向指针的指针变量格式：<code>var ptr **int;</code></p>
<p>访问指向指针的指针变量值需要使用两个 * 号，如下所示：</p>
<pre tabindex="0"><code>package main

import &#34;fmt&#34;

func main() {

   var a int
   var ptr *int
   var pptr **int

   a = 3000

   /* 指针 ptr 地址 */
   ptr = &amp;a

   /* 指向指针 ptr 地址 */
   pptr = &amp;ptr

   /* 获取 pptr 的值 */
   fmt.Printf(&#34;变量 a = %d\n&#34;, a )
   fmt.Printf(&#34;指针变量 *ptr = %d\n&#34;, *ptr )
   fmt.Printf(&#34;指向指针的指针变量 **pptr = %d\n&#34;, **pptr)
}
</code></pre><ul>
<li>指针作为函数参数</li>
</ul>
<p>向函数传递指针，只需要在函数定义的参数上设置为指针类型即可。</p>
<p>以下实例演示了如何向函数传递指针，并在函数调用后修改函数内的值:</p>
<pre tabindex="0"><code>package main

import &#34;fmt&#34;

func main() {
   /* 定义局部变量 */
   var a int = 100
   var b int= 200

   fmt.Printf(&#34;交换前 a 的值 : %d\n&#34;, a )
   fmt.Printf(&#34;交换前 b 的值 : %d\n&#34;, b )

   /* 调用函数用于交换值
   * &amp;a 指向 a 变量的地址
   * &amp;b 指向 b 变量的地址
   */
   swap(&amp;a, &amp;b);

   fmt.Printf(&#34;交换后 a 的值 : %d\n&#34;, a )
   fmt.Printf(&#34;交换后 b 的值 : %d\n&#34;, b )
}

func swap(x *int, y *int) {
   var temp int
   temp = *x    /* 保存 x 地址的值 */
   *x = *y      /* 将 y 赋值给 x */
   *y = temp    /* 将 temp 赋值给 y */
}
</code></pre><h3 id="11结构体">11.结构体</h3>
<p>结构体是由一系列具有相同类型或不同类型的数据构成的数据集合。</p>
<p>数组可以存储同一类型的数据，但在结构体中可以为不同项定义不同的数据类型。</p>
<ul>
<li>定义结构体</li>
</ul>
<p>结构体定义需要使用 type 和 struct 语句：</p>
<pre tabindex="0"><code>type struct_variable_type struct {
   member definition;
   member definition;
   ...
   member definition;
}
</code></pre><p>struct 语句定义一个新的数据类型，结构体有中有一个或多个成员
type 语句设定了结构体的名称</p>
<ul>
<li>使用结构体</li>
</ul>
<p>语法格式:</p>
<p><code>variable_name := structure_variable_type {value1, value2...valuen}</code></p>
<p>或</p>
<p><code>variable_name := structure_variable_type { key1: value1, key2: value2..., keyn: valuen}</code></p>
<p>实例如下：</p>
<pre tabindex="0"><code>package main

import &#34;fmt&#34;

type Books struct {
   title string
   author string
   subject string
   book_id int
}

func main() {

    // 创建一个新的结构体
    fmt.Println(Books{&#34;Go 语言&#34;, &#34;www.runoob.com&#34;, &#34;Go 语言教程&#34;, 6495407})

    // 也可以使用 key =&gt; value 格式
    fmt.Println(Books{title: &#34;Go 语言&#34;, author: &#34;www.runoob.com&#34;, subject: &#34;Go 语言教程&#34;, book_id: 6495407})

    // 忽略的字段为 0 或 空
   fmt.Println(Books{title: &#34;Go 语言&#34;, author: &#34;www.runoob.com&#34;})
}
</code></pre><ul>
<li>访问结构体成员</li>
</ul>
<p>使用 <strong>.</strong> 操作符,格式为：<code>结构体.成员名</code></p>
<p>实例如下:</p>
<pre tabindex="0"><code>package main

import &#34;fmt&#34;

type Books struct {
   title string
   author string
   subject string
   book_id int
}

func main() {
   var Book1 Books        /* 声明 Book1 为 Books 类型 */
   var Book2 Books        /* 声明 Book2 为 Books 类型 */

   /* book 1 描述 */
   Book1.title = &#34;Go 语言&#34;
   Book1.author = &#34;www.runoob.com&#34;
   Book1.subject = &#34;Go 语言教程&#34;
   Book1.book_id = 6495407

   /* book 2 描述 */
   Book2.title = &#34;Python 教程&#34;
   Book2.author = &#34;www.runoob.com&#34;
   Book2.subject = &#34;Python 语言教程&#34;
   Book2.book_id = 6495700

   /* 打印 Book1 信息 */
   fmt.Printf( &#34;Book 1 title : %s\n&#34;, Book1.title)
   fmt.Printf( &#34;Book 1 author : %s\n&#34;, Book1.author)
   fmt.Printf( &#34;Book 1 subject : %s\n&#34;, Book1.subject)
   fmt.Printf( &#34;Book 1 book_id : %d\n&#34;, Book1.book_id)

   /* 打印 Book2 信息 */
   fmt.Printf( &#34;Book 2 title : %s\n&#34;, Book2.title)
   fmt.Printf( &#34;Book 2 author : %s\n&#34;, Book2.author)
   fmt.Printf( &#34;Book 2 subject : %s\n&#34;, Book2.subject)
   fmt.Printf( &#34;Book 2 book_id : %d\n&#34;, Book2.book_id)
}
</code></pre><ul>
<li>作为函数参数</li>
</ul>
<pre tabindex="0"><code>package main

import &#34;fmt&#34;

type Books struct {
   title string
   author string
   subject string
   book_id int
}

func main() {
   var Book1 Books        /* 声明 Book1 为 Books 类型 */
   var Book2 Books        /* 声明 Book2 为 Books 类型 */

   /* book 1 描述 */
   Book1.title = &#34;Go 语言&#34;
   Book1.author = &#34;www.runoob.com&#34;
   Book1.subject = &#34;Go 语言教程&#34;
   Book1.book_id = 6495407

   /* book 2 描述 */
   Book2.title = &#34;Python 教程&#34;
   Book2.author = &#34;www.runoob.com&#34;
   Book2.subject = &#34;Python 语言教程&#34;
   Book2.book_id = 6495700

   /* 打印 Book1 信息 */
   printBook(Book1)

   /* 打印 Book2 信息 */
   printBook(Book2)
}

func printBook( book Books ) {
   fmt.Printf( &#34;Book title : %s\n&#34;, book.title);
   fmt.Printf( &#34;Book author : %s\n&#34;, book.author);
   fmt.Printf( &#34;Book subject : %s\n&#34;, book.subject);
   fmt.Printf( &#34;Book book_id : %d\n&#34;, book.book_id);
}
</code></pre><ul>
<li>结构体指针</li>
</ul>
<p>指向结构体的指针类似于其他指针变量，格式如下：<code>var struct_pointer *Books</code></p>
<p>以上定义的指针变量可以存储结构体变量的地址。查看结构体变量地址，可以将 &amp; 符号放置于结构体变量前：<code>struct_pointer = &amp;Book1;</code></p>
<p>使用结构体指针访问结构体成员，使用 &ldquo;.&rdquo; 操作符：<code>struct_pointer.title;</code></p>
<p>实例如下:</p>
<pre tabindex="0"><code>package main

import &#34;fmt&#34;

type Books struct {
   title string
   author string
   subject string
   book_id int
}

func main() {
   var Book1 Books        /* Declare Book1 of type Book */
   var Book2 Books        /* Declare Book2 of type Book */

   /* book 1 描述 */
   Book1.title = &#34;Go 语言&#34;
   Book1.author = &#34;www.runoob.com&#34;
   Book1.subject = &#34;Go 语言教程&#34;
   Book1.book_id = 6495407

   /* book 2 描述 */
   Book2.title = &#34;Python 教程&#34;
   Book2.author = &#34;www.runoob.com&#34;
   Book2.subject = &#34;Python 语言教程&#34;
   Book2.book_id = 6495700

   /* 打印 Book1 信息 */
   printBook(&amp;Book1)

   /* 打印 Book2 信息 */
   printBook(&amp;Book2)
}
func printBook( book *Books ) {
   fmt.Printf( &#34;Book title : %s\n&#34;, book.title);
   fmt.Printf( &#34;Book author : %s\n&#34;, book.author);
   fmt.Printf( &#34;Book subject : %s\n&#34;, book.subject);
   fmt.Printf( &#34;Book book_id : %d\n&#34;, book.book_id);
}
</code></pre><h3 id="12切片">12.切片</h3>
<p>切片(slice)是对数组的抽象,长度不固定，可追加元素，可理解为动态数组</p>
<ul>
<li>定义切片</li>
</ul>
<p>可以声明一个未指定大小的数组来定义切片：<code>var identifier []type</code></p>
<p>切片不需要说明长度。</p>
<p>或使用make()函数来创建切片:</p>
<pre tabindex="0"><code>var slice1 []type = make([]type, len)

也可以简写为

slice1 := make([]type, len)
</code></pre><p>也可以指定容量，其中capacity为可选参数。</p>
<p><code>make([]T, length, capacity)</code></p>
<ul>
<li>
<p>初始化切片</p>
<p><strong>a</strong>. 直接初始化</p>
<p><code>s :=[] int {1,2,3 }</code>, 直接初始化切片，[]表示是切片类型，{1,2,3}初始化值依次是1,2,3.其cap=len=3</p>
<p><strong>b</strong>. 从数组初始化</p>
<p><code>s := arr[:]</code>, 初始化切片s,是数组arr的引用</p>
<pre tabindex="0"><code>s := arr[startIndex:endIndex] 
将arr中从下标startIndex到endIndex-1 下的元素创建为一个新的切片

s := arr[startIndex:] 
缺省endIndex时将表示一直到arr的最后一个元素

s := arr[:endIndex] 
缺省startIndex时将表示从arr的第一个元素开始
</code></pre><p><strong>c</strong>. 从切片s初始化切片s1</p>
<p><code>s1 := s[startIndex:endIndex] </code></p>
<p><strong>d</strong>. 通过内置函数make()初始化切片s</p>
<p><code>s :=make([]int,len,cap)</code>, []int 标识为其元素类型为int的切片</p>
</li>
<li>
<p>切片函数</p>
</li>
</ul>
<p>切片可索引，可由**len()<strong>获取长度，可计算容量，用</strong>cap()**测量切片最长可达到多少。</p>
<p>一个切片在未初始化之前默认为 nil，长度为 0</p>
<p>实例:</p>
<pre tabindex="0"><code>package main
import &#34;fmt&#34;

func main() {
   var numbers = make([]int,3,5)
   printSlice(numbers)
   
   var numbers2 []int
   printSlice(numbers2)
   if(numbers2 == nil){
      fmt.Printf(&#34;切片是空的&#34;)
   }
}

func printSlice(x []int){
   fmt.Printf(&#34;len=%d cap=%d slice=%v\n&#34;,len(x),cap(x),x)
}
</code></pre><p>如果想增加切片的容量，我们必须创建一个新的更大的切片并把原分片的内容都拷贝过来。
下面的代码描述了从拷贝切片的 <strong>copy()</strong> 方法和向切片追加新元素的 <strong>append()</strong> 方法</p>
<pre tabindex="0"><code>package main

import &#34;fmt&#34;

func main() {
   var numbers []int
   printSlice(numbers)

   /* 允许追加空切片 */
   numbers = append(numbers, 0)
   printSlice(numbers)

   /* 向切片添加一个元素 */
   numbers = append(numbers, 1)
   printSlice(numbers)

   /* 同时添加多个元素 */
   numbers = append(numbers, 2,3,4)
   printSlice(numbers)

   /* 创建切片 numbers1 是之前切片的两倍容量*/
   numbers1 := make([]int, len(numbers), (cap(numbers))*2)

   /* 拷贝 numbers 的内容到 numbers1 */
   copy(numbers1,numbers)
   printSlice(numbers1)   
}

func printSlice(x []int){
   fmt.Printf(&#34;len=%d cap=%d slice=%v\n&#34;,len(x),cap(x),x)
}
</code></pre><p>可以通过设置下限及上限来设置截取切片 [lower-bound:upper-bound]，实例如下：</p>
<pre tabindex="0"><code>package main

import &#34;fmt&#34;

func main() {
   /* 创建切片 */
   numbers := []int{0,1,2,3,4,5,6,7,8}   
   printSlice(numbers)

   /* 打印原始切片 */
   fmt.Println(&#34;numbers ==&#34;, numbers)

   /* 打印子切片从索引1(包含) 到索引4(不包含)*/
   fmt.Println(&#34;numbers[1:4] ==&#34;, numbers[1:4])

   /* 默认下限为 0*/
   fmt.Println(&#34;numbers[:3] ==&#34;, numbers[:3])

   /* 默认上限为 len(s)*/
   fmt.Println(&#34;numbers[4:] ==&#34;, numbers[4:])

   numbers1 := make([]int,0,5)
   printSlice(numbers1)

   /* 打印子切片从索引  0(包含) 到索引 2(不包含) */
   number2 := numbers[:2]
   printSlice(number2)

   /* 打印子切片从索引 2(包含) 到索引 5(不包含) */
   number3 := numbers[2:5]
   printSlice(number3)

}

func printSlice(x []int){
   fmt.Printf(&#34;len=%d cap=%d slice=%v\n&#34;,len(x),cap(x),x)
}
</code></pre><h3 id="13范围range">13.范围（range）</h3>
<p>range 关键字用于 for 循环中迭代数组(array)、切片(slice)、通道(channel)或集合(map)的元素。</p>
<p>数组和切片中它返回元素的索引和索引对应的值，在集合中返回key-value对的 key值。</p>
<p>实例如下：</p>
<pre tabindex="0"><code>package main
import &#34;fmt&#34;
func main() {
   //这是我们使用range去求一个slice的和。使用数组跟这个很类似
   nums := []int{2, 3, 4}
   sum := 0
   for _, num := range nums {
       sum += num
   }
   fmt.Println(&#34;sum:&#34;, sum)
   //在数组上使用range将传入index和值两个变量。上面那个例子我们不需要使用该元素的序号，所以我们使用空白符&#34;_&#34;省略了。有时侯我们确实需要知道它的索引。
   for i, num := range nums {
       if num == 3 {
           fmt.Println(&#34;index:&#34;, i)
       }
   }
   //range也可以用在map的键值对上。
   kvs := map[string]string{&#34;a&#34;: &#34;apple&#34;, &#34;b&#34;: &#34;banana&#34;}
   for k, v := range kvs {
       fmt.Printf(&#34;%s -&gt; %s\n&#34;, k, v)
   }
   //range也可以用来枚举Unicode字符串。第一个参数是字符的索引，第二个是字符（Unicode的值）本身。
   for i, c := range &#34;go&#34; {
       fmt.Println(i, c)
   }
}
</code></pre><h3 id="14集合map">14.集合（map）</h3>
<p>map是一种无序的键值对的集合，通过key来快速检索数据。</p>
<ul>
<li>定义map</li>
</ul>
<p>可以使用内建函数 make 也可以使用 map 关键字来定义 Map:</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-go" data-lang="go"><span class="line"><span class="cl"><span class="c1">//声明变量，默认 map 是 nil 
</span></span></span><span class="line"><span class="cl"><span class="c1"></span><span class="kd">var</span> <span class="nx">map_variable</span> <span class="kd">map</span><span class="p">[</span><span class="nx">key_data_type</span><span class="p">]</span><span class="nx">value_data_type</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1">//使用 make 函数
</span></span></span><span class="line"><span class="cl"><span class="c1"></span><span class="nx">map_variable</span> <span class="o">:=</span> <span class="nb">make</span><span class="p">(</span><span class="kd">map</span><span class="p">[</span><span class="nx">key_data_type</span><span class="p">]</span><span class="nx">value_data_type</span><span class="p">)</span>
</span></span></code></pre></div><p>不初始化，定义的map为nil map，不能用来存放键值对.</p>
<p>实例如下:</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-go" data-lang="go"><span class="line"><span class="cl"><span class="kn">package</span> <span class="nx">main</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="kn">import</span> <span class="s">&#34;fmt&#34;</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="kd">func</span> <span class="nf">main</span><span class="p">()</span> <span class="p">{</span>
</span></span><span class="line"><span class="cl">    <span class="kd">var</span> <span class="nx">countryCapitalMap</span> <span class="kd">map</span><span class="p">[</span><span class="kt">string</span><span class="p">]</span><span class="kt">string</span> <span class="cm">/*创建集合 */</span>
</span></span><span class="line"><span class="cl">    <span class="nx">countryCapitalMap</span> <span class="p">=</span> <span class="nb">make</span><span class="p">(</span><span class="kd">map</span><span class="p">[</span><span class="kt">string</span><span class="p">]</span><span class="kt">string</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="cm">/* map插入key - value对,各个国家对应的首都 */</span>
</span></span><span class="line"><span class="cl">    <span class="nx">countryCapitalMap</span> <span class="p">[</span> <span class="s">&#34;France&#34;</span> <span class="p">]</span> <span class="p">=</span> <span class="s">&#34;Paris&#34;</span>
</span></span><span class="line"><span class="cl">    <span class="nx">countryCapitalMap</span> <span class="p">[</span> <span class="s">&#34;Italy&#34;</span> <span class="p">]</span> <span class="p">=</span> <span class="s">&#34;罗马&#34;</span>
</span></span><span class="line"><span class="cl">    <span class="nx">countryCapitalMap</span> <span class="p">[</span> <span class="s">&#34;Japan&#34;</span> <span class="p">]</span> <span class="p">=</span> <span class="s">&#34;东京&#34;</span>
</span></span><span class="line"><span class="cl">    <span class="nx">countryCapitalMap</span> <span class="p">[</span> <span class="s">&#34;India &#34;</span> <span class="p">]</span> <span class="p">=</span> <span class="s">&#34;新德里&#34;</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="cm">/*使用键输出地图值 */</span> <span class="k">for</span> <span class="nx">country</span> <span class="o">:=</span> <span class="k">range</span> <span class="nx">countryCapitalMap</span> <span class="p">{</span>
</span></span><span class="line"><span class="cl">        <span class="nx">fmt</span><span class="p">.</span><span class="nf">Println</span><span class="p">(</span><span class="nx">country</span><span class="p">,</span> <span class="s">&#34;首都是&#34;</span><span class="p">,</span> <span class="nx">countryCapitalMap</span> <span class="p">[</span><span class="nx">country</span><span class="p">])</span>
</span></span><span class="line"><span class="cl">    <span class="p">}</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="cm">/*查看元素在集合中是否存在 */</span>
</span></span><span class="line"><span class="cl">    <span class="nx">captial</span><span class="p">,</span> <span class="nx">ok</span> <span class="o">:=</span> <span class="nx">countryCapitalMap</span> <span class="p">[</span> <span class="s">&#34;美国&#34;</span> <span class="p">]</span> <span class="cm">/*如果确定是真实的,则存在,否则不存在 */</span>
</span></span><span class="line"><span class="cl">    <span class="cm">/*fmt.Println(captial) */</span>
</span></span><span class="line"><span class="cl">    <span class="cm">/*fmt.Println(ok) */</span>
</span></span><span class="line"><span class="cl">    <span class="k">if</span> <span class="p">(</span><span class="nx">ok</span><span class="p">)</span> <span class="p">{</span>
</span></span><span class="line"><span class="cl">        <span class="nx">fmt</span><span class="p">.</span><span class="nf">Println</span><span class="p">(</span><span class="s">&#34;美国的首都是&#34;</span><span class="p">,</span> <span class="nx">captial</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="p">}</span> <span class="k">else</span> <span class="p">{</span>
</span></span><span class="line"><span class="cl">        <span class="nx">fmt</span><span class="p">.</span><span class="nf">Println</span><span class="p">(</span><span class="s">&#34;美国的首都不存在&#34;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="p">}</span>
</span></span><span class="line"><span class="cl"><span class="p">}</span>
</span></span></code></pre></div><ul>
<li>delete() 函数</li>
</ul>
<p>delete() 函数用于删除集合的元素, 参数为 map 和其对应的 key。实例如下：</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-go" data-lang="go"><span class="line"><span class="cl"><span class="kn">package</span> <span class="nx">main</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="kn">import</span> <span class="s">&#34;fmt&#34;</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="kd">func</span> <span class="nf">main</span><span class="p">()</span> <span class="p">{</span>
</span></span><span class="line"><span class="cl">    <span class="cm">/* 创建map */</span>
</span></span><span class="line"><span class="cl">    <span class="nx">countryCapitalMap</span> <span class="o">:=</span> <span class="kd">map</span><span class="p">[</span><span class="kt">string</span><span class="p">]</span><span class="kt">string</span><span class="p">{</span><span class="s">&#34;France&#34;</span><span class="p">:</span> <span class="s">&#34;Paris&#34;</span><span class="p">,</span> <span class="s">&#34;Italy&#34;</span><span class="p">:</span> <span class="s">&#34;Rome&#34;</span><span class="p">,</span> <span class="s">&#34;Japan&#34;</span><span class="p">:</span> <span class="s">&#34;Tokyo&#34;</span><span class="p">,</span> <span class="s">&#34;India&#34;</span><span class="p">:</span> <span class="s">&#34;New delhi&#34;</span><span class="p">}</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="nx">fmt</span><span class="p">.</span><span class="nf">Println</span><span class="p">(</span><span class="s">&#34;原始地图&#34;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="cm">/* 打印地图 */</span>
</span></span><span class="line"><span class="cl">    <span class="k">for</span> <span class="nx">country</span> <span class="o">:=</span> <span class="k">range</span> <span class="nx">countryCapitalMap</span> <span class="p">{</span>
</span></span><span class="line"><span class="cl">        <span class="nx">fmt</span><span class="p">.</span><span class="nf">Println</span><span class="p">(</span><span class="nx">country</span><span class="p">,</span> <span class="s">&#34;首都是&#34;</span><span class="p">,</span> <span class="nx">countryCapitalMap</span> <span class="p">[</span> <span class="nx">country</span> <span class="p">])</span>
</span></span><span class="line"><span class="cl">    <span class="p">}</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="cm">/*删除元素*/</span> <span class="nb">delete</span><span class="p">(</span><span class="nx">countryCapitalMap</span><span class="p">,</span> <span class="s">&#34;France&#34;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="nx">fmt</span><span class="p">.</span><span class="nf">Println</span><span class="p">(</span><span class="s">&#34;法国条目被删除&#34;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="nx">fmt</span><span class="p">.</span><span class="nf">Println</span><span class="p">(</span><span class="s">&#34;删除元素后地图&#34;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="cm">/*打印地图*/</span>
</span></span><span class="line"><span class="cl">    <span class="k">for</span> <span class="nx">country</span> <span class="o">:=</span> <span class="k">range</span> <span class="nx">countryCapitalMap</span> <span class="p">{</span>
</span></span><span class="line"><span class="cl">        <span class="nx">fmt</span><span class="p">.</span><span class="nf">Println</span><span class="p">(</span><span class="nx">country</span><span class="p">,</span> <span class="s">&#34;首都是&#34;</span><span class="p">,</span> <span class="nx">countryCapitalMap</span> <span class="p">[</span> <span class="nx">country</span> <span class="p">])</span>
</span></span><span class="line"><span class="cl">    <span class="p">}</span>
</span></span><span class="line"><span class="cl"><span class="p">}</span>
</span></span></code></pre></div><h3 id="15接口">15.接口</h3>
<p>接口把所有的具有共性的方法定义在一起，任何其他类型只要实现了这些方法就是实现了这个接口。</p>
<ul>
<li>定义接口</li>
</ul>
<pre tabindex="0"><code>/* 定义接口 */
type interface_name interface {
   method_name1 [return_type]
   method_name2 [return_type]
   method_name3 [return_type]
   ...
   method_namen [return_type]
}

/* 定义结构体 */
type struct_name struct {
   /* variables */
}

/* 实现接口方法 */
func (struct_name_variable struct_name) method_name1() [return_type] {
   /* 方法实现 */
}
...
func (struct_name_variable struct_name) method_namen() [return_type] {
   /* 方法实现*/
}
</code></pre><p>实例:</p>
<pre tabindex="0"><code>package main

import (
    &#34;fmt&#34;
)

type Phone interface {
    call()
}

type NokiaPhone struct {
}

func (nokiaPhone NokiaPhone) call() {
    fmt.Println(&#34;I am Nokia, I can call you!&#34;)
}

type IPhone struct {
}

func (iPhone IPhone) call() {
    fmt.Println(&#34;I am iPhone, I can call you!&#34;)
}

func main() {
    var phone Phone

    phone = new(NokiaPhone)
    phone.call()

    phone = new(IPhone)
    phone.call()

}
</code></pre><h3 id="16异常处理">16.异常处理</h3>
<p>go通过内置的错误接口提供了非常简单的错误处理机制。
error类型是一个接口类型，这是它的定义：</p>
<pre tabindex="0"><code>type error interface {
    Error() string
}
</code></pre><p>函数通常在最后的返回值中返回错误信息。使用errors.New 可返回一个错误信息：</p>
<pre tabindex="0"><code>func Sqrt(f float64) (float64, error) {
    if f &lt; 0 {
        return 0, errors.New(&#34;math: square root of negative number&#34;)
    }
    // 实现
}
</code></pre><p>实例:</p>
<pre tabindex="0"><code>package main

import (
    &#34;fmt&#34;
)

// 定义一个 DivideError 结构
type DivideError struct {
    dividee int
    divider int
}

// 实现 `error` 接口
func (de *DivideError) Error() string {
    strFormat := `
    Cannot proceed, the divider is zero.
    dividee: %d
    divider: 0
`
    return fmt.Sprintf(strFormat, de.dividee)
}

// 定义 `int` 类型除法运算的函数
func Divide(varDividee int, varDivider int) (result int, errorMsg string) {
    if varDivider == 0 {
        dData := DivideError{
            dividee: varDividee,
            divider: varDivider,
        }
        errorMsg = dData.Error()
        return
    } else {
        return varDividee / varDivider, &#34;&#34;
    }

}

func main() {

    // 正常情况
    if result, errorMsg := Divide(100, 10); errorMsg == &#34;&#34; {
        fmt.Println(&#34;100/10 = &#34;, result)
    }
    // 当被除数为零的时候会返回错误信息
    if _, errorMsg := Divide(100, 0); errorMsg != &#34;&#34; {
        fmt.Println(&#34;errorMsg is: &#34;, errorMsg)
    }

}
</code></pre><h3 id="17并发">17.并发</h3>
<p>Go支持并发，我们只需要通过go关键字来开启goroutine即可。</p>
<p>goroutine是轻量级线程，goroutine的调度是由golang运行时进行管理的。</p>
<p>goroutine 语法格式：<code>go 函数名( 参数列表 )</code> , 例如: <code>go f(x, y, z)</code></p>
<p>go允许使用go语句开启一个新的运行期线程， 即 goroutine，以一个不同的、新创建的 goroutine 来执行一个函数。 同一个程序中的所有 goroutine 共享同一个地址空间。</p>
<p>实例</p>
<pre tabindex="0"><code>package main

import (
        &#34;fmt&#34;
        &#34;time&#34;
)

func say(s string) {
        for i := 0; i &lt; 5; i++ {
                time.Sleep(100 * time.Millisecond)
                fmt.Println(s)
        }
}

func main() {
        go say(&#34;world&#34;)
        say(&#34;hello&#34;)
}
</code></pre><h3 id="18通道channel">18.通道(channel)</h3>
<p>通道（channel）是用来传递数据的一个数据结构。</p>
<p>通道可用于两个 goroutine 之间通过传递一个指定类型的值来同步运行和通讯。操作符 &lt;- 用于指定通道的方向，发送或接收。如果未指定方向，则为双向通道。
<img src="/images/learn-golang/15487532812467.jpg" alt=""></p>
<p>声明一个通道很简单，使用chan关键字即可，通道在使用前必须先创建：
<img src="/images/learn-golang/15487533241343.jpg" alt=""></p>
<p>默认情况下，通道是不带缓冲区的。发送端发送数据，同时接收端必须相应的接收数据。</p>
<p>以下实例通过两个 goroutine 来计算数字之和，在 goroutine 完成计算后，它会计算两个结果的和：</p>
<pre tabindex="0"><code>package main

import &#34;fmt&#34;

func sum(s []int, c chan int) {
        sum := 0
        for _, v := range s {
                sum += v
        }
        c &lt;- sum // 把 sum 发送到通道 c
}

func main() {
        s := []int{7, 2, 8, -9, 4, 0}

        c := make(chan int)
        go sum(s[:len(s)/2], c)
        go sum(s[len(s)/2:], c)
        x, y := &lt;-c, &lt;-c // 从通道 c 中接收

        fmt.Println(x, y, x+y)
}
</code></pre><ul>
<li>通道缓冲区</li>
</ul>
<p>通道可以设置缓冲区，通过 make 的第二个参数指定缓冲区大小：
<img src="/images/learn-golang/15487536331518.jpg" alt=""></p>
<p>带缓冲区的通道允许发送端的数据发送和接收端的数据获取处于异步状态，就是说发送端发送的数据可以放在缓冲区里面，可以等待接收端去获取数据，而不是立刻需要接收端去获取数据。</p>
<p>不过由于缓冲区的大小是有限的，所以还是必须有接收端来接收数据的，否则缓冲区一满，数据发送端就无法再发送数据了。</p>
<p>**注意：**如果通道不带缓冲，发送方会阻塞直到接收方从通道中接收了值。如果通道带缓冲，发送方则会阻塞直到发送的值被拷贝到缓冲区内；如果缓冲区已满，则意味着需要等待直到某个接收方获取到一个值。接收方在有值可以接收之前会一直阻塞。</p>
<pre tabindex="0"><code>package main

import &#34;fmt&#34;

func main() {
    // 这里我们定义了一个可以存储整数类型的带缓冲通道
        // 缓冲区大小为2
        ch := make(chan int, 2)

        // 因为 ch 是带缓冲的通道，我们可以同时发送两个数据
        // 而不用立刻需要去同步读取数据
        ch &lt;- 1
        ch &lt;- 2

        // 获取这两个数据
        fmt.Println(&lt;-ch)
        fmt.Println(&lt;-ch)
}
</code></pre><ul>
<li>遍历和关闭通道</li>
</ul>
<p>go通过range关键字来实现遍历读取道的数据，类似于数组或切片。格式如下：
<img src="/images/learn-golang/15487543745937.jpg" alt=""></p>
<p>如果通道接收不到数据后ok就为false，这时通道就可以使用close()函数来关闭。</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-go" data-lang="go"><span class="line"><span class="cl"><span class="kn">package</span> <span class="nx">main</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="kn">import</span> <span class="p">(</span>
</span></span><span class="line"><span class="cl">        <span class="s">&#34;fmt&#34;</span>
</span></span><span class="line"><span class="cl"><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="kd">func</span> <span class="nf">fibonacci</span><span class="p">(</span><span class="nx">n</span> <span class="kt">int</span><span class="p">,</span> <span class="nx">c</span> <span class="kd">chan</span> <span class="kt">int</span><span class="p">)</span> <span class="p">{</span>
</span></span><span class="line"><span class="cl">        <span class="nx">x</span><span class="p">,</span> <span class="nx">y</span> <span class="o">:=</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span>
</span></span><span class="line"><span class="cl">        <span class="k">for</span> <span class="nx">i</span> <span class="o">:=</span> <span class="mi">0</span><span class="p">;</span> <span class="nx">i</span> <span class="p">&lt;</span> <span class="nx">n</span><span class="p">;</span> <span class="nx">i</span><span class="o">++</span> <span class="p">{</span>
</span></span><span class="line"><span class="cl">                <span class="nx">c</span> <span class="o">&lt;-</span> <span class="nx">x</span>
</span></span><span class="line"><span class="cl">                <span class="nx">x</span><span class="p">,</span> <span class="nx">y</span> <span class="p">=</span> <span class="nx">y</span><span class="p">,</span> <span class="nx">x</span><span class="o">+</span><span class="nx">y</span>
</span></span><span class="line"><span class="cl">        <span class="p">}</span>
</span></span><span class="line"><span class="cl">        <span class="nb">close</span><span class="p">(</span><span class="nx">c</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="p">}</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="kd">func</span> <span class="nf">main</span><span class="p">()</span> <span class="p">{</span>
</span></span><span class="line"><span class="cl">        <span class="nx">c</span> <span class="o">:=</span> <span class="nb">make</span><span class="p">(</span><span class="kd">chan</span> <span class="kt">int</span><span class="p">,</span> <span class="mi">10</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="k">go</span> <span class="nf">fibonacci</span><span class="p">(</span><span class="nb">cap</span><span class="p">(</span><span class="nx">c</span><span class="p">),</span> <span class="nx">c</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="c1">// range 函数遍历每个从通道接收到的数据，因为 c 在发送完 10 个
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>        <span class="c1">// 数据之后就关闭了通道，所以这里我们 range 函数在接收到 10 个数据
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>        <span class="c1">// 之后就结束了。如果上面的 c 通道不关闭，那么 range 函数就不
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>        <span class="c1">// 会结束，从而在接收第 11 个数据的时候就阻塞了。
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>        <span class="k">for</span> <span class="nx">i</span> <span class="o">:=</span> <span class="k">range</span> <span class="nx">c</span> <span class="p">{</span>
</span></span><span class="line"><span class="cl">                <span class="nx">fmt</span><span class="p">.</span><span class="nf">Println</span><span class="p">(</span><span class="nx">i</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="p">}</span>
</span></span><span class="line"><span class="cl"><span class="p">}</span>
</span></span></code></pre></div><h2 id="三参考">三、参考</h2>
<p><a href="https://gobyexample.com">1. gobyexample</a></p>
]]></content>
		</item>
		
		<item>
			<title>Jenkins &#43; AWS CodeDeploy &#43; AutoScaling 持续集成</title>
			<link>http://www.heyuan110.com/posts/linux/2018-11-20-jenkins-codedeploy-autoscaling/</link>
			<pubDate>Tue, 20 Nov 2018 11:05:40 +0000</pubDate>
			
			<guid>http://www.heyuan110.com/posts/linux/2018-11-20-jenkins-codedeploy-autoscaling/</guid>
			<description>本文主要记录如何结合jenkins,codedeploy,s3, autoscaling等相关服务搭建一套可持续交付和应用部署的服务。
Aws AutoScaling部分 1、使用Auto Scaling的优点 1)、保持基础设置堆栈配置一致(例如软件nginx、php等安装配置一致)
2)、快速设置扩展(只需要设定Auto Scaling组内的所需实例数量即可完成实例的扩展)
3)、制定明确的扩展策略(比如根据CPU的利用率时增加或是缩减实例数量)
4)、控制实例资源成本(在Auto Scaling组内的实例通常都比较小，不然就失去了AutoScaling自动扩展的意义)
2、Auto Scaling组件说明 Auto Scaling组：EC2实例放在组中，用于扩展和管理的逻辑单元，在创建组时，可以指定其最小，最大和所需EC2的实例数量
(备注：auto Scaling 组是与启动配置相关联的)
Auto Scaling启动配置：EC2实例启动时的模板(指定实例类型，密钥对，安全组和磁盘空间大小)
3、创建启动配置步骤 1)、为EC2实例创建IAM角色
https://console.aws.amazon.com/iam/
2)、为Auto Scaling 创建启动配置(下图为已经设置好的启动配置模板)
3)、为EC2实例启动时添加必要的用户数据(主要为应用程序事先搭建好基础环境)
脚本如下：
#!/bin/bash #run all command as root,system: ubuntu16.04 #enter /opt/patpat-devops folder cd /opt/patpat-devops #download aws codedeploy agent,and start rm -rf codedeploy-agent mkdir codedeploy-agent cd codedeploy-agent wget https://xxxx.com/latest/install chmod +x ./install ./install auto service codedeploy-agent start service codedeploy-agent status #backto patpat-devops folder cd /opt/patpat-devops #download nginx1.</description>
			<content type="html"><![CDATA[<p>本文主要记录如何结合jenkins,codedeploy,s3, autoscaling等相关服务搭建一套可持续交付和应用部署的服务。</p>
<h2 id="aws-autoscaling部分">Aws AutoScaling部分</h2>
<h3 id="1使用auto-scaling的优点">1、使用Auto Scaling的优点</h3>
<p>1)、保持基础设置堆栈配置一致(例如软件nginx、php等安装配置一致)</p>
<p>2)、快速设置扩展(只需要设定Auto Scaling组内的所需实例数量即可完成实例的扩展)</p>
<p>3)、制定明确的扩展策略(比如根据CPU的利用率时增加或是缩减实例数量)</p>
<p>4)、控制实例资源成本(在Auto Scaling组内的实例通常都比较小，不然就失去了AutoScaling自动扩展的意义)</p>
<h3 id="2auto-scaling组件说明">2、Auto Scaling组件说明</h3>
<p>Auto Scaling组：EC2实例放在组中，用于扩展和管理的逻辑单元，在创建组时，可以指定其最小，最大和所需EC2的实例数量</p>
<p>(备注：auto Scaling 组是与启动配置相关联的)</p>
<p>Auto Scaling启动配置：EC2实例启动时的模板(指定实例类型，密钥对，安全组和磁盘空间大小)</p>
<h3 id="3创建启动配置步骤">3、创建启动配置步骤</h3>
<p>1)、为EC2实例创建IAM角色</p>
<p><a href="https://console.aws.amazon.com/iam/">https://console.aws.amazon.com/iam/</a></p>
<p><img src="https://raw.githubusercontent.com/heyuan110/static-source/master/media/15426810514625/15426812146538.jpg" alt=""></p>
<p><img src="https://raw.githubusercontent.com/heyuan110/static-source/master/media/15426810514625/15426812429125.jpg" alt=""></p>
<p><img src="https://raw.githubusercontent.com/heyuan110/static-source/master/media/15426810514625/15426812509358.jpg" alt="">
<img src="https://raw.githubusercontent.com/heyuan110/static-source/master/media/15426810514625/15426812612000.jpg" alt=""></p>
<p>2)、为Auto Scaling 创建启动配置(下图为已经设置好的启动配置模板)</p>
<p><img src="media/15426810514625/15426813227709.jpg" alt=""></p>
<p>3)、为EC2实例启动时添加必要的用户数据(主要为应用程序事先搭建好基础环境)</p>
<p><img src="https://raw.githubusercontent.com/heyuan110/static-source/master/media/15426810514625/15426814249267.jpg" alt=""></p>
<p>脚本如下：</p>
<pre tabindex="0"><code>#!/bin/bash

#run all command as root,system: ubuntu16.04

#enter /opt/patpat-devops folder

cd /opt/patpat-devops

#download aws codedeploy agent,and start

rm -rf codedeploy-agent

mkdir codedeploy-agent

cd codedeploy-agent

wget https://xxxx.com/latest/install

chmod +x ./install

./install auto

service codedeploy-agent start

service codedeploy-agent status

#backto patpat-devops folder

cd /opt/patpat-devops

#download nginx1.14, not need single start

wget https://xxxx.com/nginx/nginx1.14.tar

tar -xf nginx1.14.tar

mv nginx /usr/local/programs/

#replace /etc/logrotate.d/nginx

\cp -f /usr/local/programs/nginx/logrotate.d/nginx /etc/logrotate.d/nginx

#copy supervisor.d/nginx.conf to supervisor

\cp -f /usr/local/programs/nginx/supervisor.d/nginx.conf /usr/local/programs/supervisor/conf.d/

rm nginx1.14.tar

#download php7,not need single start

wget https://xxxx.com/php/php7.tar

tar -xf php7.tar

mv php7 /usr/local/programs/

#copy supervisor.d/php-fpm.conf to supervisor

\cp -f /usr/local/programs/php7/etc/supervisor.d/php-fpm.conf /usr/local/programs/supervisor/conf.d/

rm php7.tar

#start supervisor,nginx,php,zabbix start server

isExistApp=`pgrep supervisor`

if [ -n  $isExistApp ]; then

    echo &#34;supervisor is activing, will reload&#34;

    #restart server

    /usr/local/bin/supervisorctl reload 

else

    echo &#34;supervisor is not active, will start server&#34;

    #start server

   /usr/local/bin/supervisord -c /usr/local/programs/supervisor/supervisord.conf     

fi

#change nginx log permession

chmod -R 777 /usr/local/programs/nginx/logs

echo &#34;Install finished!&#34;
</code></pre><p>备注：具体在创建实例的时候在&quot;配置详细信息&quot;选项卡里面进行添加</p>
<p><img src="https://raw.githubusercontent.com/heyuan110/static-source/master/media/15426810514625/15426815907986.jpg" alt=""></p>
<p>4)、创建Auto Scaling 组 (下图为已经创建好的Auto Scaling组)</p>
<p><img src="https://raw.githubusercontent.com/heyuan110/static-source/master/media/15426810514625/15426816027339.jpg" alt=""></p>
<p>Auto Scaling结合ELB使用</p>
<p><img src="https://raw.githubusercontent.com/heyuan110/static-source/master/media/15426810514625/15426816334272.jpg" alt=""></p>
<p>此时aws auto scaling创建完成，随后Auto Scaling会根据给定的按需实例设置启动一台EC2实例</p>
<h2 id="aws-code-deploy部分">AWS Code Deploy部分</h2>
<h3 id="1codedeploy部署的前提条件">1、CodeDeploy部署的前提条件</h3>
<p>需要在Auto Scaling启动配置中的EC2启动模板事先安装好CodeDeploy agent代理
Install or reinstall the aws CodeDeploy agent for Amazon Ubuntu Server</p>
<pre tabindex="0"><code>
$ sudo apt-get install ruby

$ sudo apt-get install wget

$ cd /home/ubuntu

$ wget https://bucket-name.s3.amazonaws.com/latest/install

$ chmod +x ./install

$ sudo ./install auto

$ sudo service codedeploy-agent status

$ sudo service codedeploy-agent start

$ sudo service codedeploy-agent status
</code></pre><p>备注：bucket-name 是包含适用于您所在区域的AWS CodeDeploy 资源工具包文件的 Amazon S3sds-s3-latest-bucket-name 存储桶的名称，对于美国东部(俄亥俄)区域，bucket-name 替换为 aws-codedeploy-us-east-2</p>
<h3 id="2code-deploy组件">2、Code Deploy组件</h3>
<p><strong>部署</strong>：部署一个包括应用程序和AppSpec文件的新修订；AppSpec指定如何将应用程序部署到部署组中的实例</p>
<p><strong>应用程序</strong>：部署组和修订的集合；EC2/本地应用程序使用EC2/本地计算平台</p>
<p><strong>修订版</strong>：修订版是可部署内容(如源代码、构建后项目、网页、可执行文件和部署脚本以及 AppSpec 文件)的特定版本，AWS CodeDeploy 代理程序可通过 GitHub 或 Amazon S3 存储桶访问修订版</p>
<p><strong>部署组</strong>：部署组是用于在CodeDeploy部署中对EC2实例的AWS CodeDeploy实体；它是一组与您以之为目标进行部署的应用程序关联的实例；可以通过指定标签、Auto Scaling组名称或同时指定此二者，将实例添加到部署组中</p>
<p>备注：可以为一个应用程序定义多个部署组，如模拟和生产</p>
<p><strong>部署配置</strong>：部署配置为部署组指定如何进行部署的行为，包括如何处理部署故障；可以使用部署配置向多实例部署组执行零停机部署；例如，如果您的应用程序需要部署组中至少有50% 的实例在运行中且提供流量，可以在您的部署配置中指定这一点，从而使部署不会导致停机；如果没有与部署或者部署组相关联的部署配置，则在默认情况下，AWS CodeDeploy将会一次部署到一个实例中</p>
<h3 id="3aws-codedeploy部署类型">3、AWS CodeDeploy部署类型</h3>
<p><strong>就地部署</strong></p>
<p>停止部署组中每个实例上的应用程序，安装最新的应用程序修订版，然后启动和验证应用程序的新版本；您可以使用负载均衡器，以便在部署期间取消注册每个实例，然后在部署完成后让其重新提供服务；只有使用EC2/本地计算平台的部署才能使用就地部署</p>
<p>对部署组中的实例依次执行脱机操作/更新应用/恢复联机的操作，完成滚动部署</p>
<p><strong>蓝绿部署</strong></p>
<p>创建一组新的替换实例，并安装新版本的应用程序。成功后，切换流量到这些新实例，删除旧实例，完成部署；AWS CodeDeploy 运行您在切换流量之前，对新版本应用程序进行测试；如果发现问题，您可以快速回滚到旧版本</p>
<p>EC2/本地计算平台上的蓝/绿部署：部署组中的实例(原始环境)将被不同的实例集(替代环境)所代替，步骤如下：</p>
<p>1)、系统将为替代环境配置实例</p>
<p>2)、替代实例上将安装最新的应用程序修订</p>
<p>3)、对于应用程序测试和系统验证等活动来说，等待时间可选</p>
<p>4)、替代环境中的实例在Elastic Load Balancing负载均衡器中进行注册，使得流量重新路由至这些实例；系统将撤销原始环境中的实例注册，进而终止或因其他使用情形而保持运行</p>
<p>备注：蓝/绿部署只能与Amazon EC2实例配合使用</p>
<h3 id="4就地部署概述">4、就地部署概述</h3>
<p>停止部署组中每个实例上的应用程序，安装最新的应用程序修订版，然后启动和验证应用程序的新版本。您可以使用负载均衡器，以便在部署期间取消注册每个实例，然后在部署完成后让其重新提供服务</p>
<p><img src="https://raw.githubusercontent.com/heyuan110/static-source/master/media/15426810514625/15426818126546.jpg" alt=""></p>
<p>1)、在本地开发计算机或类似环境上创建可部署的内容，然后添加application specification file (AppSpec file)；AppSpec file对AWS CodeDeploy是唯一的；它定义了AWS CodeDeploy执行的部署操作；将可部署的内容和AppSpec file捆绑成一个存档文件，然后将其上传到Amazon S3存储桶或GitHub存储库；此存档文件称为应用程序修订(简称修订)</p>
<p>2)、向AWS CodeDeploy提供有关您的部署的信息，例如，要从中提取修订的Amazon S3存储桶或GitHub，以及要将其内容部署到的一组Amazon EC2实例；AWS CodeDeploy将一组Amazon EC2实例称为一个部署组，部署组中包含单独标记的Amazon EC2实例和/或Amazon EC2 Auto Scaling组中的Amazon EC2实例</p>
<p>每次您成功上传要部署到部署组的新应用程序修订时，该捆绑包就会设置为部署组的目标修订；也就是说，当前设为部署目标的应用程序修订为目标修订，这也是将为自动部署提取的修订</p>
<p>3)、每个实例上的CodeDeploy-Agent将轮询 AWS CodeDeploy，以确定从指定的Amazon S3存储桶或GitHub存储库中提取的内容和提取时间</p>
<p>4)、每个实例上的CodeDeploy-Agent将从指定的Amazon S3存储桶或GitHub存储库中提取目标修订，并按照 AppSpec file中的说明向实例部署内容</p>
<p>AWS CodeDeploy将保留您的部署的记录，以便您可以获取部署状态、部署配置参数、实例运行状况</p>
<h3 id="5蓝绿部署概述">5、蓝/绿部署概述</h3>
<p><em>在蓝/绿部署中将流量从一组实例(原始环境)重新路由到另一组实例(替换环境)</em>，相比就地部署提供了多种优势：</p>
<p>1)、可以提前在新实例上安装和测试应用程序，并通过直接将流量切换到新服务器来将应用程序部署到生产中</p>
<p>2)、可以更快、更可靠地切换回最近的应用程序版本，因为只要原始实例没有终止，就可以将流量路由回原始实例；而在就地部署中，必须通过重新部署上一个版本的应用程序来回滚版本</p>
<p>3)、如果您使用EC2/本地计算平台，则会为蓝/绿部署预置新实例，并且新实例反映最新的服务器配置；这将帮助您避免在长时间运行的实例上有时出现的问题类型</p>
<p>wiki：https://docs.aws.amazon.com/zh_cn/codedeploy/latest/userguide/welcome.html#welcome-deployment-overview-in-place</p>
<h3 id="6appspec-文件">6、AppSpec 文件</h3>
<p>appspec.yml是YAML格式、用于定于CodeDeploy服务在整个阶段所做的操作和文件拷贝路径和权限等。这个文档名称必须是appspec.yml,而且文档中的空格个数也有严格的要求,<a href="https://blog.csdn.net/fedora18/article/details/44237647">参考详细解析
</a>.</p>
<p>如果没有AppSpec file，AWS CodeDeploy无法将应用程序修订中的源文件映射到其目标，也无法为您向EC2/本地计算平台中进行的部署运行脚本</p>
<p>AppSpec 文件是一种配置文件，用于指定待复制文件和待执行脚本；AppSpec文件使用 YAML 格式，它位于您的修订版的根目录下；AppSpec文件为AWS CodeDeploy 代理程序所用，由两个部分组成；文件部分指定了您的版次中待复制的源文件，以及每个实例的目标文件夹；挂接部分指定了在部署各阶段运行的脚本的位置(作为从修订包根下起始的相对路径)；部署的各阶段被称为部署生命周期事件；下面是一个示例 AppSpec文件</p>
<pre tabindex="0"><code>appspec.yml示例：

version: 0.0                                      # 固定写法

os: linux

files:                                                 # You can specify one or more mappings in the files section.

  - source: /

    destination: /var/www/html/WordPress

hooks:                                              # The lifecycle hooks sections allows you to specify deployment scripts.

ApplicationStop:                             # Step 1: Stop Apache and MySQL if running.

    - location: helper_scripts/stop_server.sh

BeforeInstall:                                  # Step 2: Install Apache and MySQL.

# You can specify one or more scripts per deployment lifecycle event.

    - location: deploy_hooks/puppet-apply-apache.sh

    - location: deploy_hooks/puppet-apply-mysql.sh

AfterInstall:

    - location: deploy_hooks /change_permissions.sh              # Step 3: Set permissions.

      timeout: 30

      runas: root

    - location: helper_scripts/start_server.sh                             # Step 4: Start the server.

      timeout: 30

      runas: root
</code></pre><p>appspec.yml生产环境示例：</p>
<pre tabindex="0"><code>version: 0.0                                        # AppSpec file的版本；允许的唯一值为0.0

os: linux                                             # 指定部署到的实例的操作系统值(linux、windows)

files:                                                   # 定义文件映射关系

  - source: /                                        # 表示本版本包的全部文件和目录(相对路径，从修订的根目录开始)

    destination: /var/www/alpha-website_desktop/       # 被部署服务器的完整路径

hooks:                                               # 定义CodeDeploy各阶段执行的操作

  BeforeInstall:                                  # CodeDeploy部署之前

    - location: codedeploy-scripts/install_dependencies    # 运行的软件包依赖脚本

      timeout: 300                               # 安装超时时间

      runas: root                                 # 以什么用户进行软件安装

  AfterInstall:                                    # CodeDeploy部署之后

    - location: codedeploy-scripts/change_applications_configure

    - location: codedeploy-scripts/change_permissions

      timeout: 300

      runas: root

  ApplicationStart:                           # 应用启动

    - location: codedeploy-scripts/start_server

      timeout: 300

      runas: root

  ApplicationStop:                           # 应用停止

    - location: codedeploy-scripts/stop_server

      timeout: 300

      runas: root
</code></pre><p>appspec.yml部署生命周期：</p>
<p><img src="https://raw.githubusercontent.com/heyuan110/static-source/master/media/15426810514625/15426821571744.jpg" alt=""></p>
<p>部署生命周期说明</p>
<p>部署会经过一组预定义阶段，称为部署生命周期事件。部署生命周期事件可让您将代码作为部署的一部分运行</p>
<p>下表以执行顺序列出了目前支持的各种不同的部署生命周期事件，以及您可能想使用它们的时间示例
<img src="https://raw.githubusercontent.com/heyuan110/static-source/master/media/15426810514625/15426821846445.jpg" alt=""></p>
<p>In-place deployments(就地部署)
<img src="https://raw.githubusercontent.com/heyuan110/static-source/master/media/15426810514625/15426822011681.jpg" alt=""></p>
<p>Blue/green deployments(蓝绿部署生命周期)</p>
<p><img src="https://raw.githubusercontent.com/heyuan110/static-source/master/media/15426810514625/15426822146656.jpg" alt=""></p>
<p>蓝绿部署流量切换过程</p>
<p><img src="https://raw.githubusercontent.com/heyuan110/static-source/master/media/15426810514625/15426822261108.jpg" alt=""></p>
<p>CodeDeploy部署方式：</p>
<p><img src="https://raw.githubusercontent.com/heyuan110/static-source/master/media/15426810514625/15426822356524.jpg" alt=""></p>
<p>CodeDeploy与AutoScaling集成原理 <a href="https://aws.amazon.com/cn/blogs/devops/under-the-hood-aws-codedeploy-and-auto-scaling-integration/">https://aws.amazon.com/cn/blogs/devops/under-the-hood-aws-codedeploy-and-auto-scaling-integration/</a></p>
<h2 id="使用auto-scaling配置codedeploy">使用Auto Scaling配置CodeDeploy</h2>
<p>使用Auto Scaling配置CodeDeploy非常简单。只需转到AWS CodeDeploy控制台，然后在部署组配置中指定Auto Scaling组名称</p>
<p><img src="https://raw.githubusercontent.com/heyuan110/static-source/master/media/15426810514625/15426823243690.jpg" alt=""></p>
<p>此外，还需要：</p>
<p>1、在Auto Scaling实例上安装CodeDeploy代理。您可以将代理程序作为基本AMI的一部分进行烘焙，也可以在启动期间使用用户数据来安装代理程序</p>
<p>2、确保CodeDeploy用于与Auto Scaling交互的服务角色具有正确的权限</p>
<h3 id="auto-scaling-lifecycle-hook">Auto Scaling Lifecycle Hook</h3>
<p>事件中的Auto Scaling和CodeDeploy之间的通信基于Auto Scaling生命周期挂钩；建议不要尝试手动设置或修改这些挂钩，因为CodeDeploy可以为您执行此操作；Auto Scaling生命周期挂钩告诉Auto Scaling在实例即将更改为某些Auto Scaling生命周期状态时发送通知；CodeDeploy仅侦听有关已启动且即将放入InService的实例的通知；此状态发生在EC2实例完成引导之后，但在它被放置到您已配置的任何Elastic Load Balancing负载平衡器之后；Auto Scaling在继续处理实例之前等待CodeDeploy的成功响应</p>
<p><img src="https://raw.githubusercontent.com/heyuan110/static-source/master/media/15426810514625/15426823485910.jpg" alt=""></p>
<p>挂钩是Auto Scaling组配置的一部分；您可以使用describe-lifecycle-hooks CLI命令查看Auto Scaling组上安装的挂钩列表；创建或修改部署组以包含Auto Scaling组时，CodeDeploy将执行以下操作：</p>
<p>1)、使用传入的CodeDeploy服务角色与部署组一起使用以获取Auto Scaling组的权限</p>
<p>2)、在Auto Scaling组中安装生命周期挂钩，用于实例启动，将通知发送到CodeDeploy拥有的队列</p>
<p>3)、将已安装的挂钩的记录添加到部署组</p>
<p>从部署组中删除Auto Scaling组或删除部署组时，CodeDeploy将执行以下操作：</p>
<p>1)、使用部署组的服务角色来访问Auto Scaling组</p>
<p>2)、获取部署组中记录的挂钩，并将其从Auto Scaling挂钩中删除</p>
<p>3)、如果正在修改(未删除)部署组，请从部署组中删除该挂钩的记录</p>
<p>如果创建钩子有问题，CodeDeploy将尝试回滚更改；如果删除钩子有问题，CodeDeploy将在API响应中返回不成功的钩子删除并继续</p>
<p>以下是Auto Scaling scale-in事件期间发生的事件序列：</p>
<p>1、Auto Scaling要求EC2提供新实例</p>
<p>2、EC2使用Auto Scaling提供的配置旋转新实例</p>
<p>3、Auto Scaling查看新实例，将其置于Pending：Wait状态，并将通知发送到Code Deploy</p>
<p>4、CodeDeploy从Auto Scaling接收实例启动通知</p>
<p>5、CodeDeploy验证实例和部署组的配置</p>
<p>1)、如果通知看起来正确，但部署组不再包含Auto Scaling组(或者我们可以确定先前已删除部署组)，则CodeDeploy将不会部署任何内容，并通过实例启动将Auto Scaling告知CONTINUE；Auto Scaling将尊重实例启动时的任何其他约束; 如果出现其他问题，此步骤不会强制Auto Scaling继续</p>
<p>2)、如果CodeDeploy无法处理消息(例如，如果存储的服务角色未授予适当的权限)，则CodeDeploy将使挂钩超时；CodeDeploy的默认超时为10分钟</p>
<p>6、CodeDeploy为实例创建新部署以部署部署组的目标修订；(目标修订版是部署组的最后一个成功部署的修订版；它由CodeDeploy维护)；您需要至少部署到部署组一次，以便CodeDeploy识别目标修订版；您可以使用get-deployment-group CLI命令或CodeDeploy控制台获取部署组的目标修订</p>
<p>1)、部署正在运行时，它会将心跳发送到Auto Scaling，让它知道该实例仍在处理中</p>
<p>2)、如果部署出现问题，CodeDeploy将立即告知Auto Scaling ABANDON实例启动。Auto Scaling终止实例并使用新实例重新启动该过程</p>
<p><img src="https://raw.githubusercontent.com/heyuan110/static-source/master/media/15426810514625/15426823677871.jpg" alt=""></p>
<p>最佳实践
1)、设置或修改Auto Scaling生命周期挂钩 -不要手动设置或修改Auto Scaling挂钩，因为配置错误可能会破坏CodeDeploy集成(备注：在CodeDeploy中配置添加AutoScaling组，生命周期挂钩就已经建立)</p>
<p>2)、注意部署失败 - 当部署到新实例失败时，CodeDeploy会将实例标记为终止；Auto Scaling将终止实例，启动新实例，并通知CodeDeploy以启动部署；当你有暂时的错误时，这很好。但是，缺点是如果您的目标修订版存在问题(例如，如果部署脚本中存在错误)，则启动和终止实例的此循环可以进入循环；我们建议您密切监视部署并设置Auto Scaling 通知，以跟踪Auto Scaling启动和终止的EC2实例</p>
<p>3)、Auto Scaling部署疑难解答-对涉及Auto Scaling组的部署进行故障排除可能具有挑战性；如果部署失败，我们建议您取消Auto Scaling组与部署组的关联，以防止Auto Scaling不断启动和终止EC2实例。接下来，将使用相同基本AMI启动的标记EC2实例添加到部署组，将目标修订部署到该EC2实例，并使用该实例对脚本进行故障排除。如果您有信心，请将部署组与Auto Scaling组关联，将黄金版本部署到Auto Scaling组，扩展新的EC2实例（通过调整Min，Max和Desired（）），并验证部署是否成功</p>
<p>4)、订购启动脚本的执行 - CodeDeploy代理在启动时立即查找并执行部署；部署执行和启动脚本(如用户数据，cfn-init等)之间没有排序；我们建议您将启动脚本作为启动脚本的一部分(也可能是最后一步)安装，以便您可以确定在实例安装了不属于CodeDeploy部署的依赖项之前，不会执行部署；如果您希望将代理程序烘焙到基本AMI中，我们建议您将代理程序服务保持在停止状态，并使用启动脚本启动代理程序服务</p>
<p>5)、将多个部署组与同一Auto Scaling组关联 - 通常，应避免将多个部署组与同一Auto Scaling组关联；当Auto Scaling使用与多个部署组关联的多个挂钩扩展实例时，它会同时发送所有挂钩的通知；因此，将创建多个CodeDeploy部署；这有几个缺点。这些部署是并行执行的，因此您将无法依赖它们之间的任何顺序；如果任何部署失败，Auto Scaling将立即终止实例；当实例关闭时，正在运行的其他部署将开始失败，但它们可能需要一个小时才能完成；Host Agent一次只处理一个部署命令，因此您还需要考虑两个限制；第一，其中一个部署可能会因为时间过长而失败；例如，如果部署中的步骤需要五分钟以上才能完成，则可能会发生这种情况；其次，部署之间没有先发制人，因此无法在一个部署与另一个部署之间强制执行步骤排序；因此，我们建议您最小化与Auto Scaling组关联的部署组的数量，并将部署合并到单个部署中</p>
<h2 id="jenkinsgitcodedeploy持续集成">Jenkins+Git+CodeDeploy持续集成</h2>
<p>参考官方教程: <a href="https://aws.amazon.com/cn/blogs/china/aws-devops-jenkins-and-codedeploy/">https://aws.amazon.com/cn/blogs/china/aws-devops-jenkins-and-codedeploy/</a></p>
<p>需要Jenkins安装codedeploy插件，插件截图：</p>
<p><img src="https://raw.githubusercontent.com/heyuan110/static-source/master/media/15426810514625/15426825748300.jpg" alt=""></p>
<h3 id="jenkins关于项目配置目录规则">Jenkins关于项目配置目录规则</h3>
<pre tabindex="0"><code>project-configure/

├── geodata

│   └── geoip.mmdb

├── xxxx                                                                               # 公司名称

│   ├── alpha                                                                           # alpha环境

│   │   ├── xxxx-alpha-website_api                                    # 具体的项目名称

│   │   │   ├── codedeploy                                                      # CodeDeploy目录存放codedeploy必须的appspec.yml和脚本文件夹

│   │   │   │   ├── appspec.yml                                               # 用于定义CodeDeploy服务在整个阶段做的操作和文件拷贝路径和权限等

│   │   │   │   └── codedeploy-scripts                                   # CodeDeploy中脚本执行所在文件夹

│   │   │   │       ├── change_applications_configure          # CodeDeploy部署完成后，配置文件拷贝，服务重启操作

│   │   │   │       ├── change_permissions                            # codedeploy部署完成后，相关目录权限变更等设置

│   │   │   │       ├── install_dependencies                           # codedeploy部署前系统软件包依赖关系安装

│   │   │   │       ├── start_server                                           # 启动服务脚本

│   │   │   │       └── stop_server                                           # 停止服务脚本

│   │   │   ├── project-conf.d                                                # 项目中的.env配置文件目录

│   │   │   └── server-applications                                       # 软件(nginx，php)应用程序配置文件存放文件夹

│   │   │       └── nginx

│   │   │           └── conf.d

│   │   │               └── xxxx-alpha-website_api.conf            

│   ├── production                                                                # 线上生产环境

│   │   ├── xxxx-api

│   │   │   ├── codedeploy

│   │   │   │   ├── appspec.yml

│   │   │   │   └── codedeploy-scripts

│   │   │   │       ├── change_applications_configure

│   │   │   │       ├── change_permissions

│   │   │   │       ├── install_dependencies

│   │   │   │       ├── start_server

│   │   │   │       └── stop_server

│   │   │   ├── project-conf.d

│   │   │   └── server-applications

│   │   │       └── aws-kinesis-agent

│   │   │           └── agent.json

│   └── test                                                                           # 测试环境

└── README                                                                       # CodeDeploy目录说明
</code></pre><p><strong>相关目录说明：</strong></p>
<p>目录层级：</p>
<p>平台/环境/项目</p>
<p>目前只有patpat和ace平台，环境有production、test、alpha</p>
<p>项目目录包含项目配置，codedeploy配置，服务器端配置，每个项目配置下面分别有下面三个目录：</p>
<p>codedeploy/</p>
<p>project-conf.d/</p>
<p>server-applications/</p>
<p>说明：</p>
<ol>
<li>
<p>codedeploy目录存放codedeploy必须的appspec.yml和scripts脚本文件</p>
</li>
<li>
<p>project-conf.d目录存放项目参数配置文件，例如.env</p>
</li>
<li>
<p>server-applications目录存放目标服务器上的nginx，php，kinesis-agent等应用程序配置，需要结合上面的codedeploy使用</p>
</li>
</ol>
<p>务必严格按照此格式配置，每次修改配置后需要重新在jenkins上构建发布！</p>
<p>AWS codedeploy采取蓝绿部署，无状态部署，所以每次修改配置后需要重新构建启动新机器</p>
<h3 id="构建截图">构建截图</h3>
<p><img src="https://raw.githubusercontent.com/heyuan110/static-source/master/media/15426810514625/15426828768145.jpg" alt=""></p>
<h3 id="jenkins与codedeploy结合部署文件上传至指定的s3存储桶">Jenkins与codedeploy结合部署文件上传至指定的S3存储桶</h3>
<p><img src="https://raw.githubusercontent.com/heyuan110/static-source/master/media/15426810514625/15426829980489.jpg" alt=""></p>
<p><img src="https://raw.githubusercontent.com/heyuan110/static-source/master/media/15426810514625/15426830240171.jpg" alt=""></p>
<h3 id="发布流程">发布流程</h3>
<p>Jenkins主要实现将构建好的部署包上传至s3存储桶，事先在EC2实例上的CodeDeploy-Agent在轮询过程中发现s3存储桶上有新的修订版(jenkins部署上传到S3的压缩包)时，获取存储桶的新的修订版并解压，CodeDeploy根据新的修订版里的appspec.yml对EC2实例进行自动部署，这样保证每次在同一个CodeDeploy组内的实例获取的都是最新的部署包.</p>
]]></content>
		</item>
		
		<item>
			<title>Supervisor安装配置与使用</title>
			<link>http://www.heyuan110.com/posts/linux/2018-10-07-supervisor/</link>
			<pubDate>Sun, 07 Oct 2018 00:35:04 +0000</pubDate>
			
			<guid>http://www.heyuan110.com/posts/linux/2018-10-07-supervisor/</guid>
			<description>Supervisor (http://supervisord.org) 是一个用 Python 写的进程管理工具，可以很方便的用来启动、重启、关闭进程（不仅仅是 Python 进程）。除了对单个进程的控制，还可以同时启动、关闭多个进程，比如很不幸的服务器出问题导致所有应用程序都被杀死，此时可以用 supervisor 同时启动所有应用程序而不是一个一个地敲命令启动。
安装 服务器上所有应用统一安装到目录/usr/local/programs/，所以采用源码安装
提前配置好python(2.7)环境，下载相关文件：
wget wget https://pypi.python.org/packages/2.7/s/setuptools/setuptools-0.6c11-py2.7.egg &amp;ndash;no-check-certificate
wget https://pypi.python.org/packages/80/37/964c0d53cbd328796b1aeb7abea4c0f7b0e8c7197ea9b0b9967b7d004def/supervisor-3.3.1.tar.gz
按下面步骤执行:
1. sh setuptools-0.6c11-py2.7.egg 2. tar -axvf supervisor-3.3.1.tar.gz 3. cd supervisor-3.3.1 4. python setup.py install 5. echo_supervisord_conf &amp;gt; /usr/local/programs/supervisoretc/supervisord.conf 6. supervisord -c /usr/local/programs/supervisoretc/supervisord.conf 7. supervisorctl 8. done 配置文件supervisord.conf：
; Sample supervisor config file. ; ; For more information on the config file, please see: ; http://supervisord.org/configuration.html ; ; Notes: ; - Shell expansion (&amp;#34;~&amp;#34; or &amp;#34;$HOME&amp;#34;) is not supported.</description>
			<content type="html"><![CDATA[<p>Supervisor (<a href="http://supervisord.org">http://supervisord.org</a>) 是一个用 Python 写的进程管理工具，可以很方便的用来启动、重启、关闭进程（不仅仅是 Python 进程）。除了对单个进程的控制，还可以同时启动、关闭多个进程，比如很不幸的服务器出问题导致所有应用程序都被杀死，此时可以用 supervisor 同时启动所有应用程序而不是一个一个地敲命令启动。</p>
<h2 id="安装">安装</h2>
<p>服务器上所有应用统一安装到目录/usr/local/programs/，所以采用源码安装</p>
<p>提前配置好python(2.7)环境，下载相关文件：</p>
<ul>
<li>
<p>wget wget <a href="https://pypi.python.org/packages/2.7/s/setuptools/setuptools-0.6c11-py2.7.egg">https://pypi.python.org/packages/2.7/s/setuptools/setuptools-0.6c11-py2.7.egg</a>  &ndash;no-check-certificate</p>
</li>
<li>
<p>wget <a href="https://pypi.python.org/packages/80/37/964c0d53cbd328796b1aeb7abea4c0f7b0e8c7197ea9b0b9967b7d004def/supervisor-3.3.1.tar.gz">https://pypi.python.org/packages/80/37/964c0d53cbd328796b1aeb7abea4c0f7b0e8c7197ea9b0b9967b7d004def/supervisor-3.3.1.tar.gz</a></p>
</li>
</ul>
<p>按下面步骤执行:</p>
<pre tabindex="0"><code>    1. sh setuptools-0.6c11-py2.7.egg
    2. tar -axvf supervisor-3.3.1.tar.gz
    3. cd supervisor-3.3.1
    4. python setup.py install
    5. echo_supervisord_conf &gt; /usr/local/programs/supervisoretc/supervisord.conf
    6. supervisord -c /usr/local/programs/supervisoretc/supervisord.conf
    7. supervisorctl
    8. done
</code></pre><p>配置文件supervisord.conf：</p>
<pre tabindex="0"><code> ; Sample supervisor config file.
;
; For more information on the config file, please see:
; http://supervisord.org/configuration.html
;
; Notes:
;  - Shell expansion (&#34;~&#34; or &#34;$HOME&#34;) is not supported.  Environment
;    variables can be expanded using this syntax: &#34;%(ENV_HOME)s&#34;.
;  - Comments must have a leading space: &#34;a=b ;comment&#34; not &#34;a=b;comment&#34;.

[unix_http_server]
file=/tmp/supervisor.sock   ; (the path to the socket file)
;chmod=0700                 ; socket file mode (default 0700)
;chown=nobody:nogroup       ; socket file uid:gid owner
;username=user              ; (default is no username (open server))
;password=123               ; (default is no password (open server))

[inet_http_server]         ; inet (TCP) server disabled by default
port=0.0.0.0:9001        ; (ip_address:port specifier, *:port for all iface)
;username=user              ; (default is no username (open server))
;password=123               ; (default is no password (open server))

[supervisord]
logfile=/tmp/supervisord.log ; (main log file;default $CWD/supervisord.log)
logfile_maxbytes=50MB        ; (max main logfile bytes b4 rotation;default 50MB)
logfile_backups=10           ; (num of main logfile rotation backups;default 10)
loglevel=info                ; (log level;default info; others: debug,warn,trace)
pidfile=/tmp/supervisord.pid ; (supervisord pidfile;default supervisord.pid)
nodaemon=false               ; (start in foreground if true;default false)
minfds=1024                  ; (min. avail startup file descriptors;default 1024)
minprocs=200                 ; (min. avail process descriptors;default 200)
;umask=022                   ; (process file creation umask;default 022)
;user=chrism                 ; (default is current user, required if root)
;identifier=supervisor       ; (supervisord identifier, default is &#39;supervisor&#39;)
;directory=/tmp              ; (default is not to cd during start)
;nocleanup=true              ; (don&#39;t clean up tempfiles at start;default false)
;childlogdir=/tmp            ; (&#39;AUTO&#39; child log dir, default $TEMP)
;environment=KEY=&#34;value&#34;     ; (key value pairs to add to environment)
;strip_ansi=false            ; (strip ansi escape codes in logs; def. false)

; the below section must remain in the config file for RPC
; (supervisorctl/web interface) to work, additional interfaces may be
; added by defining them in separate rpcinterface: sections
[rpcinterface:supervisor]
supervisor.rpcinterface_factory = supervisor.rpcinterface:make_main_rpcinterface

[supervisorctl]
serverurl=unix:///tmp/supervisor.sock ; use a unix:// URL  for a unix socket
;serverurl=http://127.0.0.1:9001 ; use an http:// url to specify an inet socket
;username=chris              ; should be same as http_username if set
;password=123                ; should be same as http_password if set
;prompt=mysupervisor         ; cmd line prompt (default &#34;supervisor&#34;)
;history_file=~/.sc_history  ; use readline history if available

; The below sample program section shows all possible program subsection values,
; create one or more &#39;real&#39; program: sections to be able to control them under
; supervisor.

;[program:theprogramname]
;command=/bin/cat              ; the program (relative uses PATH, can take args)
;process_name=%(program_name)s ; process_name expr (default %(program_name)s)
;numprocs=1                    ; number of processes copies to start (def 1)
;directory=/tmp                ; directory to cwd to before exec (def no cwd)
;umask=022                     ; umask for process (default None)
;priority=999                  ; the relative start priority (default 999)
;autostart=true                ; start at supervisord start (default: true)
;startsecs=1                   ; # of secs prog must stay up to be running (def. 1)
;startretries=3                ; max # of serial start failures when starting (default 3)
;autorestart=unexpected        ; when to restart if exited after running (def: unexpected)
;exitcodes=0,2                 ; &#39;expected&#39; exit codes used with autorestart (default 0,2)
;stopsignal=QUIT               ; signal used to kill process (default TERM)
;stopwaitsecs=10               ; max num secs to wait b4 SIGKILL (default 10)
;stopasgroup=false             ; send stop signal to the UNIX process group (default false)
;killasgroup=false             ; SIGKILL the UNIX process group (def false)
;user=chrism                   ; setuid to this UNIX account to run the program
;redirect_stderr=true          ; redirect proc stderr to stdout (default false)
;stdout_logfile=/a/path        ; stdout log path, NONE for none; default AUTO
;stdout_logfile_maxbytes=1MB   ; max # logfile bytes b4 rotation (default 50MB)
;stdout_logfile_backups=10     ; # of stdout logfile backups (default 10)
;stdout_capture_maxbytes=1MB   ; number of bytes in &#39;capturemode&#39; (default 0)
;stdout_events_enabled=false   ; emit events on stdout writes (default false)
;stderr_logfile=/a/path        ; stderr log path, NONE for none; default AUTO
;stderr_logfile_maxbytes=1MB   ; max # logfile bytes b4 rotation (default 50MB)
;stderr_logfile_backups=10     ; # of stderr logfile backups (default 10)
;stderr_capture_maxbytes=1MB   ; number of bytes in &#39;capturemode&#39; (default 0)
;stderr_events_enabled=false   ; emit events on stderr writes (default false)
;environment=A=&#34;1&#34;,B=&#34;2&#34;       ; process environment additions (def no adds)
;serverurl=AUTO                ; override serverurl computation (childutils)

; The below sample eventlistener section shows all possible
; eventlistener subsection values, create one or more &#39;real&#39;
; eventlistener: sections to be able to handle event notifications
; sent by supervisor.

;[eventlistener:theeventlistenername]
;command=/bin/eventlistener    ; the program (relative uses PATH, can take args)
;process_name=%(program_name)s ; process_name expr (default %(program_name)s)
;numprocs=1                    ; number of processes copies to start (def 1)
;events=EVENT                  ; event notif. types to subscribe to (req&#39;d)
;buffer_size=10                ; event buffer queue size (default 10)
;directory=/tmp                ; directory to cwd to before exec (def no cwd)
;umask=022                     ; umask for process (default None)
;priority=-1                   ; the relative start priority (default -1)
;autostart=true                ; start at supervisord start (default: true)
;startsecs=1                   ; # of secs prog must stay up to be running (def. 1)
;startretries=3                ; max # of serial start failures when starting (default 3)
;autorestart=unexpected        ; autorestart if exited after running (def: unexpected)
;exitcodes=0,2                 ; &#39;expected&#39; exit codes used with autorestart (default 0,2)
;stopsignal=QUIT               ; signal used to kill process (default TERM)
;stopwaitsecs=10               ; max num secs to wait b4 SIGKILL (default 10)
;stopasgroup=false             ; send stop signal to the UNIX process group (default false)
;killasgroup=false             ; SIGKILL the UNIX process group (def false)
;user=chrism                   ; setuid to this UNIX account to run the program
;redirect_stderr=false         ; redirect_stderr=true is not allowed for eventlisteners
;stdout_logfile=/a/path        ; stdout log path, NONE for none; default AUTO
;stdout_logfile_maxbytes=1MB   ; max # logfile bytes b4 rotation (default 50MB)
;stdout_logfile_backups=10     ; # of stdout logfile backups (default 10)
;stdout_events_enabled=false   ; emit events on stdout writes (default false)
;stderr_logfile=/a/path        ; stderr log path, NONE for none; default AUTO
;stderr_logfile_maxbytes=1MB   ; max # logfile bytes b4 rotation (default 50MB)
;stderr_logfile_backups=10     ; # of stderr logfile backups (default 10)
;stderr_events_enabled=false   ; emit events on stderr writes (default false)
;environment=A=&#34;1&#34;,B=&#34;2&#34;       ; process environment additions
;serverurl=AUTO                ; override serverurl computation (childutils)

; The below sample group section shows all possible group values,
; create one or more &#39;real&#39; group: sections to create &#34;heterogeneous&#34;
; process groups.

;[group:thegroupname]
;programs=progname1,progname2  ; each refers to &#39;x&#39; in [program:x] definitions
;priority=999                  ; the relative start priority (default 999)

; The [include] section can just contain the &#34;files&#34; setting.  This
; setting can list multiple files (separated by whitespace or
; newlines).  It can also contain wildcards.  The filenames are
; interpreted as relative to this file.  Included files *cannot*
; include files themselves.

[include]
files = conf.d/*.conf
</code></pre><p>注意最下面一行，重点，要考！</p>
<h2 id="配置管理程序">配置管理程序</h2>
<p>以nginx为例，在/usr/local/programs/supervisor/conf.d下创建</p>
<p>vi nginx.conf</p>
<pre tabindex="0"><code>[program:nginx]
command=/usr/local/programs/nginx/nginx ;需要执行的命令wd
user=root   ;(default  is  current  user , required  if  root)
autostart=true ;start at supervisord start (default: true)
autorestart=true  ;whether/when to restart (default: unexpected)
startsecs=3  ;number of secs prog must stay running ( def . 1)
stderr_logfile=/usr/local/programs/supervisor/logs/nginx_stderr_err.log  ;redirect proc stderr to stdout (default false) 错误输出重定向
stdout_logfile=/usr/local/programs/supervisor/logs/nginx_stdout.log  ;stdout log path, NONE  for  none; default AUTO, log输出
</code></pre><p><code>wq</code>保存退出，启动 <code>supervisord -c /etc/supervisord.conf</code></p>
<h2 id="supervisorctl工具">Supervisorctl工具</h2>
<p>进入交互模式<code>supervisorctl</code></p>
<pre tabindex="0"><code>&gt; status    # 查看程序状态
&gt; stop usercenter   # 关闭 usercenter 程序
&gt; start usercenter  # 启动 usercenter 程序
&gt; restart usercenter    # 重启 usercenter 程序
&gt; reread    ＃ 读取有更新（增加）的配置文件，不会启动新添加的程序
&gt; update    ＃ 重启配置文件修改过的程序
</code></pre><p>也可以不进入交互环境</p>
<pre tabindex="0"><code>$ supervisorctl status
$ supervisorctl stop usercenter
$ supervisorctl start usercenter
$ supervisorctl restart usercenter
$ supervisorctl reread
$ supervisorctl update
</code></pre><h2 id="开机启动">开机启动</h2>
<h3 id="ubuntu">ubuntu</h3>
<p>打开配置<code>vi /etc/rc.local</code></p>
<p>增加自启动配置项目</p>
<pre tabindex="0"><code>#!/bin/sh -e
#
# rc.local
#
# This script is executed at the end of each multiuser runlevel.
# Make sure that the script will &#34;exit 0&#34; on success or any other
# value on error.
#
# In order to enable or disable this script just change the execution
# bits.
#
# By default this script does nothing.

#开机自启动
/bin/bash -c &#34;/usr/local/bin/supervisord -c /usr/local/programs/supervisor/supervisord.conf&#34;

exit 0
</code></pre><p>保存并退出。
最后修改rc.local权限 <code>chmod +x /etc/rc.local</code></p>
]]></content>
		</item>
		
		<item>
			<title>IP地址与CIDR</title>
			<link>http://www.heyuan110.com/posts/linux/2018-10-06-ip-cidr/</link>
			<pubDate>Sat, 06 Oct 2018 23:51:44 +0000</pubDate>
			
			<guid>http://www.heyuan110.com/posts/linux/2018-10-06-ip-cidr/</guid>
			<description>IP(v4)地址是一个4字节（共32bit），32位的二进制的数字，被分为4段，每段8位，段与段之间用.号分隔，为了便于表达和识别，IP地址是以十进制形式表示,例如：127.0.0.1。由网络ID和主机ID组成，网络中唯一标识一台计算机。网络ID标识计算机所处的网段，主机ID标识计算机在网段中所处的位置。
网络ID的是Internet上的一个子网，而主机ID的是子网中的某台主机。网际地址分解成两个域后，带来了一个重要的优点：IP数据包从网际上的一个网络到达另一个网络时，选择路径可以基于网络而不是主机。在大型的网际中，这一点优势特别明显，因为路由表中只存储网络信息而不是主机信息，这样可以大大简化路由表。
IP地址分类： 为了方便IP寻址分为A、B、C、D、E五类，每类IP地址对各个IP地址中用来表示网络ID和主机ID的位数作了明确的规定。
1. A类 A类地址用IP地址前8位表示网络ID（1字节），后24位表示主机ID（3字节）。A类地址用来表示网络ID的第一位必须以0开始，其他7位可以是任意值， 当其他7位全为0是网络ID最小，即为0；当其他7位全为1时网络ID最大，即为127。完整的IP二进制：
00000000 . 000000000 . 000000000 . 000000000 a b c d 看a部分: 第一位为0，其他7位为0，那么a部分为00000000，转成十进制0*2^7+0*2^6+0*2^5+0*2^4+0*2^3+0*2^2+0*2^1+0*2^0 = 0 第一位为0，其他7位为1，那么a部分为01111111，转成十进制 0*2^7+1*2^6+1*2^5+1*2^4+1*2^3+1*2^2+1*2^1+1*2^0 = 127 网络ID不能为0，它有特殊的用途，用来表示所有网段，所以网络 ID最小为1. 网络ID不能为127；127用来作为网络环回测试用。
所以A类网络网络ID的有效范围是1-126共126个网络1.0.0.0~126.255.255.255,默认子网掩码/8,即255.0.0.0 (其中127.0.0.0~127.255.255.255为环回地址,用于本地环回测试等用途)。每个A类网络最多可以连接2^24-2台主机（2个保留地址）。
2. B类 B类地址用IP地址前16位表示网络ID（2字节），后16位表示主机ID（2字节）。B类地址用来表示网络ID的前两位必须以10开始，其他14位可以是任意值， 当其他14位全为0是网络ID最小，即为128；当其他14位全为1时网络ID最大，即为191。完整的IP二进制：
10000000 . 000000000 . 000000000 . 000000000 a b c d 看ab部分: 前2位为10，其他14位为0，那么ab部分为10000000 00000000，转成十进制1*2^7+0*2^6+0*2^5+0*2^4+0*2^3+0*2^2+0*2^1+0*2^0 = 128 前2位为10，其他14位为1，那么ab部分为10111111 11111111，转成十进制 1*2^7+0*2^6+1*2^5+1*2^4+1*2^3+1*2^2+1*2^1+1*2^0 = 191 所以B类网络网络ID第一个字节有效范围是128-191，共16384个（2^14）B类网络128.0.0.0~191.255.255.255,默认子网掩码/16.每个B类网络最多可以连接2^16-2台主机（2个保留地址）。
3. C类 C类地址用IP地址前24位表示网络ID（3字节），后8位表示主机ID（1字节）。C类地址用来表示网络ID的前三位必须以110开始，其他21位可以是任意值， 当其他21位全为0是网络ID最小，即为192；当其他21位全为1时网络ID最大，即为223。，完整的IP二进制：
10000000 . 000000000 . 000000000 . 000000000 a b c d 看abc部分: 前3位为110，其他21位为0，那么ab部分为11000000 00000000 00000000，转成十进制1*2^7+1*2^6+0*2^5+0*2^4+0*2^3+0*2^2+0*2^1+0*2^0 = 192 前3位为110，其他21位为1，那么ab部分为11011111 11111111 11111111，转成十进制 1*2^7+1*2^6+0*2^5+1*2^4+1*2^3+1*2^2+1*2^1+1*2^0 = 223 所以C类网络网络ID第一个字节有效范围是192-223，共个2^21C类网络192.</description>
			<content type="html"><![CDATA[<p><img src="https://raw.githubusercontent.com/heyuan110/static-source/master/cover/ip.jpg" alt=""></p>
<p>IP(v4)地址是一个4字节（共32bit），32位的二进制的数字，被分为4段，每段8位，段与段之间用.号分隔，为了便于表达和识别，IP地址是以十进制形式表示,例如：127.0.0.1。由<strong>网络ID</strong>和<strong>主机ID</strong>组成，网络中唯一标识一台计算机。网络ID标识计算机所处的网段，主机ID标识计算机在网段中所处的位置。</p>
<p>网络ID的是Internet上的一个子网，而主机ID的是子网中的某台主机。网际地址分解成两个域后，带来了一个重要的优点：IP数据包从网际上的一个网络到达另一个网络时，选择路径可以基于网络而不是主机。在大型的网际中，这一点优势特别明显，因为路由表中只存储网络信息而不是主机信息，这样可以大大简化路由表。</p>
<h2 id="ip地址分类">IP地址分类：</h2>
<p>为了方便IP寻址分为A、B、C、D、E五类，每类IP地址对各个IP地址中用来表示网络ID和主机ID的位数作了明确的规定。</p>
<h3 id="1-a类">1. A类</h3>
<p>A类地址用IP地址<strong>前8位表示网络ID</strong>（1字节），<strong>后24位表示主机ID</strong>（3字节）。A类地址用来表示网络ID的第一位必须以0开始，其他7位可以是任意值， 当其他7位全为0是网络ID最小，即为0；当其他7位全为1时网络ID最大，即为127。完整的IP二进制：</p>
<pre tabindex="0"><code>00000000 . 000000000 . 000000000 . 000000000
   a           b           c          d
看a部分:
第一位为0，其他7位为0，那么a部分为00000000，转成十进制0*2^7+0*2^6+0*2^5+0*2^4+0*2^3+0*2^2+0*2^1+0*2^0 = 0
第一位为0，其他7位为1，那么a部分为01111111，转成十进制  0*2^7+1*2^6+1*2^5+1*2^4+1*2^3+1*2^2+1*2^1+1*2^0 = 127
    
</code></pre><p>网络ID不能为0，它有特殊的用途，用来表示所有网段，所以网络 ID最小为1.
网络ID不能为127；127用来作为网络环回测试用。</p>
<p>所以A类网络网络ID的有效范围是1-126共126个网络<strong>1.0.0.0~126.255.255.255</strong>,默认子网掩码/8,即255.0.0.0 (其中127.0.0.0~127.255.255.255为环回地址,用于本地环回测试等用途)。每个A类网络最多可以连接2^24-2台主机（2个保留地址）。</p>
<h3 id="2-b类">2. B类</h3>
<p>B类地址用IP地址<strong>前16位表示网络ID</strong>（2字节），<strong>后16位表示主机ID</strong>（2字节）。B类地址用来表示网络ID的前两位必须以10开始，其他14位可以是任意值， 当其他14位全为0是网络ID最小，即为128；当其他14位全为1时网络ID最大，即为191。完整的IP二进制：</p>
<pre tabindex="0"><code>10000000 . 000000000 . 000000000 . 000000000
   a           b           c          d
看ab部分:
前2位为10，其他14位为0，那么ab部分为10000000 00000000，转成十进制1*2^7+0*2^6+0*2^5+0*2^4+0*2^3+0*2^2+0*2^1+0*2^0 = 128
前2位为10，其他14位为1，那么ab部分为10111111 11111111，转成十进制  1*2^7+0*2^6+1*2^5+1*2^4+1*2^3+1*2^2+1*2^1+1*2^0 = 191
    
</code></pre><p>所以B类网络网络ID第一个字节有效范围是128-191，共16384个（2^14）B类网络<strong>128.0.0.0~191.255.255.255</strong>,默认子网掩码/16.每个B类网络最多可以连接2^16-2台主机（2个保留地址）。</p>
<h3 id="3-c类">3. C类</h3>
<p>C类地址用IP地址<strong>前24位表示网络ID</strong>（3字节），<strong>后8位表示主机ID</strong>（1字节）。C类地址用来表示网络ID的前三位必须以110开始，其他21位可以是任意值， 当其他21位全为0是网络ID最小，即为192；当其他21位全为1时网络ID最大，即为223。，完整的IP二进制：</p>
<pre tabindex="0"><code>10000000 . 000000000 . 000000000 . 000000000
   a           b           c          d
看abc部分:
前3位为110，其他21位为0，那么ab部分为11000000 00000000 00000000，转成十进制1*2^7+1*2^6+0*2^5+0*2^4+0*2^3+0*2^2+0*2^1+0*2^0 = 192
前3位为110，其他21位为1，那么ab部分为11011111 11111111 11111111，转成十进制  1*2^7+1*2^6+0*2^5+1*2^4+1*2^3+1*2^2+1*2^1+1*2^0 = 223
    
</code></pre><p>所以C类网络网络ID第一个字节有效范围是192-223，共个2^21C类网络<strong>192.0.0.0~223.255.255.255</strong>,默认子网掩码/24.每个C类网络最多可以连接2^8-2(254台)台主机（2个保留地址）。</p>
<h3 id="4-d类">4. D类</h3>
<p>一般于用组播，没有网络ID和主机ID之分，D类IP地址的第一个字节前四位必须以1110开始，其他28位可以是任何值，IP范围224.0.0.0~239.255.255.255。</p>
<h3 id="5-e类">5. E类</h3>
<p>一般用于研究用途，没有网络ID和主机ID之分，E类IP地址的第一字节前四位必须以1111开始，其它28位可以是任何值，240.0.0.0~255.255.255.255(其中255.255.255.255为全网广播地址)</p>
<h2 id="cidr无类域间路由">CIDR(无类域间路由)</h2>
<p>将子网掩码转换为二进制，就会发现网络ID部分全部是1、主机ID部分全部是0。</p>
<p>CIDR（Classless Inter-Domain Routing，无类域间路由选择）它消除了传统的A类、B类和C类地址以及划分子网的概念，因而可以更加有效地分配IPv4的地址空间。它可以将好几个IP网络结合在一起，使用一种无类别的域际路由选择算法，使它们合并成一条路由从而较少路由表中的路由条目减轻Internet路由器的负担。</p>
<p>CIDR技术用子网掩码中连续的1部份表示网络ID，连续的0部份表示主机ID。比如，网络中包含2000台计算机，只需要用11位表示 主机ID，用21位表网络ID，则子网掩码表示为11111111.11111111.11100000.00000000，转换为十进制则为 255.255.224.0。此时，该网络将包含2046台计算机，既不会造成IP地址的浪费，也不会利用路由器连接网络，增加额外的管理维护量。</p>
<p>CIDR 还使用“斜线记法”，它又称为CIDR记法，即在IP地址后面加上一个斜线“/”，然后写上网络前缀所占的比特数（这个数值对应于三级编址中子网掩码中比特1的个数）。</p>
<p><strong>CIDR表示方法：IP地址/网络ID的位数，比如192.168.23.35/21，其中用21位表示网络ID。</strong></p>
<p>网络ID相同的计算机称之为本地网络，本地网络中的计算机相互通信不需要路由器连接；网络ID不相同的计算机称之为远程网络，远程网络中的计算机要相互通信必须通过路由器连接。</p>
<p>{% alert warning %}
注意：为什么计算IP地址时要减2，而计算子网数目时不减2呢？IP地址减2的原因是主机ID不能全为0也不能全为1；子网就不存在这个问题。
{% endalert %}</p>
]]></content>
		</item>
		
		<item>
			<title>Elasticsearch学习</title>
			<link>http://www.heyuan110.com/posts/elasticsearch/2018-09-12-elasticsearch/</link>
			<pubDate>Wed, 12 Sep 2018 18:52:59 +0000</pubDate>
			
			<guid>http://www.heyuan110.com/posts/elasticsearch/2018-09-12-elasticsearch/</guid>
			<description>Elasticsearch是一个基于Apache Lucene(TM)的开源搜索引擎(以下简称ES),是目前全文搜索引擎的首选。它可以快速存储、搜索和分析海量数据，Github，StackOverflow都在采用它。
一、ES组成 ES对照RMDB快速了解ES基本组成，它可以包含多个索引(indices)（数据库），每一个索引可以包含多个类型(types)（表），每一个类型包含多个文档(documents)（行），然后每个文档包含多个字段(Fields)（列）,简化如下:
索引 -&amp;gt; 数据库 类型 -&amp;gt; 表 文档 -&amp;gt; 行 字段 -&amp;gt; 列
二、常用查询命令 1. 查看_cat相关命令 GET /_cat/
结果:
&amp;gt; ➜ ~ curl -i -XGET http://192.168.11.119:9200/_cat/ HTTP/1.1 200 OK content-type: text/plain; charset=UTF-8 content-length: 493 &amp;gt;=^.^= /_cat/allocation /_cat/shards /_cat/shards/{index} /_cat/master /_cat/nodes /_cat/tasks /_cat/indices /_cat/indices/{index} /_cat/segments /_cat/segments/{index} /_cat/count /_cat/count/{index} /_cat/recovery /_cat/recovery/{index} /_cat/health /_cat/pending_tasks /_cat/aliases /_cat/aliases/{alias} /_cat/thread_pool /_cat/thread_pool/{thread_pools} /_cat/plugins /_cat/fielddata /_cat/fielddata/{fields} /_cat/nodeattrs /_cat/repositories /_cat/snapshots/{repository} /_cat/templates 2.查看集群健康 GET /_cat/health?v
结果：</description>
			<content type="html"><![CDATA[<p><img src="https://raw.githubusercontent.com/heyuan110/static-source/master/cover/es.jpg" alt=""></p>
<p>Elasticsearch是一个基于Apache Lucene(TM)的开源搜索引擎(以下简称ES),是目前全文搜索引擎的首选。它可以快速存储、搜索和分析海量数据，Github，StackOverflow都在采用它。</p>
<h2 id="一es组成">一、ES组成</h2>
<p>ES对照RMDB快速了解ES基本组成，它可以包含多个索引(indices)（数据库），每一个索引可以包含多个类型(types)（表），每一个类型包含多个文档(documents)（行），然后每个文档包含多个字段(Fields)（列）,简化如下:</p>
<p>索引  <strong>-&gt;</strong>  数据库
类型  <strong>-&gt;</strong>  表
文档  <strong>-&gt;</strong>  行
字段  <strong>-&gt;</strong>  列</p>
<h2 id="二常用查询命令">二、常用查询命令</h2>
<h3 id="1-查看_cat相关命令">1. 查看_cat相关命令</h3>
<blockquote>
<p><code>GET /_cat/</code></p>
</blockquote>
<p>结果:</p>
<pre tabindex="0"><code>&gt;
➜  ~ curl -i -XGET http://192.168.11.119:9200/_cat/
HTTP/1.1 200 OK
content-type: text/plain; charset=UTF-8
content-length: 493

&gt;=^.^=
/_cat/allocation
/_cat/shards
/_cat/shards/{index}
/_cat/master
/_cat/nodes
/_cat/tasks
/_cat/indices
/_cat/indices/{index}
/_cat/segments
/_cat/segments/{index}
/_cat/count
/_cat/count/{index}
/_cat/recovery
/_cat/recovery/{index}
/_cat/health
/_cat/pending_tasks
/_cat/aliases
/_cat/aliases/{alias}
/_cat/thread_pool
/_cat/thread_pool/{thread_pools}
/_cat/plugins
/_cat/fielddata
/_cat/fielddata/{fields}
/_cat/nodeattrs
/_cat/repositories
/_cat/snapshots/{repository}
/_cat/templates
</code></pre><h3 id="2查看集群健康">2.查看集群健康</h3>
<blockquote>
<p><code>GET /_cat/health?v</code></p>
</blockquote>
<p>结果：</p>
<pre tabindex="0"><code>➜  ~ curl -XGET http://192.168.11.119:9200/_cat/health\?v
epoch      timestamp cluster       status node.total node.data shards pri relo init unassign pending_tasks max_task_wait_time active_shards_percent
1533717572 08:39:32  elasticsearch yellow          1         1    315 315    0    0      315             0                  -                 50.0%
</code></pre><p>green：每个索引的primary shard和replica shard都是active状态的
yellow：每个索引的primary shard都是active状态的，但是部分replica shard不是active状态，处于不可用的状态
red：不是所有索引的primary shard都是active状态的，部分索引有数据丢失了</p>
<p>为什么现在会处于一个yellow状态？</p>
<p>我们现在就一台服务器，就启动了一个es进程，相当于就只有一个node。现在es中有一个index，就是kibana自己内置建立的index。由于默认的配置是给每个index分配5个primary shard和5个replica shard，而且primary shard和replica shard不能在同一台机器上（为了容错）。现在kibana自己建立的index是1个primary shard和1个replica shard。当前就一个node，所以只有1个primary shard被分配了和启动了，但是一个replica shard没有第二台机器去启动。</p>
<h3 id="3-查看集群有哪些索引">3. 查看集群有哪些索引</h3>
<blockquote>
<p><code>GET /_cat/indices\?v</code></p>
</blockquote>
<p>结果:</p>
<pre tabindex="0"><code>➜  ~ curl -i -XGET http://192.168.11.119:9200/_cat/indices\?v
HTTP/1.1 200 OK
content-type: text/plain; charset=UTF-8
content-length: 8840

&gt;health status index                                    uuid                   pri rep docs.count docs.deleted store.size pri.store.size
yellow open   es_es_category_products                  u2TdPYcXS5yyFF8P3a3jYQ   5   1      95311         7103      156mb          156mb
yellow open   web_product_ar_new                       8qhhh9C7QvuwEEu-YYrIgA   5   1      37610           77     55.6mb         55.6mb
yellow open   en_27_category_product                   VtVXVTuHQ3-xyNw4txpEXg   5   1      41206           20       68mb           68mb
yellow open   ar_27_category_product                   Id43cmuDQnKYkhaCepxrIg   5   1      41206           17     67.9mb         67.9mb
yellow open   it_28_category_product                   Gltx9R80Qn6PI22i6-Mflg   5   1      12659           25     22.5mb         22.5mb
yellow open   db_search                                WKYGbjjLSZmh0s_LyuT2tQ   5   1     230133            0     28.7mb         28.7mb
yellow open   de_28_category_product                   IUCYcmTIR6K4AzUpAWJmHg   5   1      12659           27     22.5mb         22.5mb
</code></pre><h3 id="4-创建索引">4. 创建索引</h3>
<p><code>PUT /test_index?pretty</code></p>
<p>结果：</p>
<pre tabindex="0"><code>➜  ~ curl -i -XPUT http://192.168.11.119:9200/test_index\?pretty
HTTP/1.1 200 OK
content-type: application/json; charset=UTF-8
content-length: 60
{
  &#34;acknowledged&#34; : true,
  &#34;shards_acknowledged&#34; : true
</code></pre><h3 id="5删除索引">5.删除索引</h3>
<p><code>DELETE /test_index?pretty</code></p>
<h3 id="6-新增文档并建立索引">6. 新增文档并建立索引</h3>
<p>语法格式：</p>
<pre tabindex="0"><code>PUT /index/type/id
{
    &#34;json数据&#34;
}
</code></pre><p>index索引名、type类型名、id数据的id</p>
<pre tabindex="0"><code>PUT /test_index/user/1
{
    &#34;name&#34;: &#34;小明&#34;,
    &#34;email&#34;: &#34;xiaoming@test.com&#34;,
    &#34;tags&#34;: [&#34;篮球&#34;,&#34;游泳&#34;]
}
</code></pre><p>结果如下：</p>
<pre tabindex="0"><code>➜  ~ curl -i -XPUT http://192.168.11.119:9200/test_index/user/1 -d &#39;{
    &#34;name&#34;: &#34;小明&#34;,
    &#34;email&#34;: &#34;xiaoming@test.com&#34;,
    &#34;tags&#34;: [&#34;篮球&#34;,&#34;游泳&#34;]
}&#39;

&gt;HTTP/1.1 201 Created
Location: /test_index/user/1
Warning: 299 Elasticsearch-5.5.2-b2f0c09 &#34;Content type detection for rest requests is deprecated. Specify the content type using the [Content-Type] header.&#34; &#34;Wed, 08 Aug 2018 08:58:29 GMT&#34;
content-type: application/json; charset=UTF-8
content-length: 143

&gt;{&#34;_index&#34;:&#34;test_index&#34;,&#34;_type&#34;:&#34;user&#34;,&#34;_id&#34;:&#34;1&#34;,&#34;_version&#34;:1,&#34;result&#34;:&#34;created&#34;,&#34;_shards&#34;:{&#34;total&#34;:2,&#34;successful&#34;:1,&#34;failed&#34;:0},&#34;created&#34;:true}%
</code></pre><h3 id="61-查询新增的文档">6.1 查询新增的文档</h3>
<p><code>GET /索引/类型/字段值</code></p>
<p>例如：</p>
<pre tabindex="0"><code>➜  ~ curl -i -XGET http://192.168.11.119:9200/test_index/user/1\?pretty
HTTP/1.1 200 OK
content-type: application/json; charset=UTF-8
content-length: 232
{
  &#34;_index&#34; : &#34;test_index&#34;,
  &#34;_type&#34; : &#34;user&#34;,
  &#34;_id&#34; : &#34;1&#34;,
  &#34;_version&#34; : 1,
  &#34;found&#34; : true,
  &#34;_source&#34; : {
    &#34;name&#34; : &#34;小明&#34;,
    &#34;email&#34; : &#34;xiaoming@test.com&#34;,
    &#34;tags&#34; : [
      &#34;篮球&#34;,
      &#34;游泳&#34;
    ]
  }
}
</code></pre><h3 id="7修改文档">7.修改文档</h3>
<p>修改分为全部修改或部分修改，全部修改就是直接替换，需要带上全部字段才能修改，例如：</p>
<pre tabindex="0"><code>➜  ~  curl -i -XPUT http://192.168.11.119:9200/test_index/user/1 -d &#39;{
    &#34;name&#34;: &#34;小明&#34;,
    &#34;email&#34;: &#34;xiaoming@test.com&#34;,
    &#34;tags&#34;: [&#34;篮球&#34;,&#34;游泳&#34;,&#34;足球&#34;]
}&#39;
HTTP/1.1 200 OK
Warning: 299 Elasticsearch-5.5.2-b2f0c09 &#34;Content type detection for rest requests is deprecated. Specify the content type using the [Content-Type] header.&#34; &#34;Wed, 08 Aug 2018 09:15:45 GMT&#34;
content-type: application/json; charset=UTF-8
content-length: 144
{&#34;_index&#34;:&#34;test_index&#34;,&#34;_type&#34;:&#34;user&#34;,&#34;_id&#34;:&#34;1&#34;,&#34;_version&#34;:2,&#34;result&#34;:&#34;updated&#34;,&#34;_shards&#34;:{&#34;total&#34;:2,&#34;successful&#34;:1,&#34;failed&#34;:0},&#34;created&#34;:false}
</code></pre><p>注意全部修改用的是PUT方法.
部分修改就是只更新部分,用的POST方法，参数部分增加了一个doc的key，例如:</p>
<pre tabindex="0"><code>➜  ~ curl -i -XPOST http://192.168.11.119:9200/test_index/user/1/_update -d &#39;{
        &#34;doc&#34;:{
            &#34;email&#34;: &#34;xiaoming@demo.com&#34;
        }
}&#39;
HTTP/1.1 200 OK
Warning: 299 Elasticsearch-5.5.2-b2f0c09 &#34;Content type detection for rest requests is deprecated. Specify the content type using the [Content-Type] header.&#34; &#34;Wed, 08 Aug 2018 09:18:26 GMT&#34;
content-type: application/json; charset=UTF-8
content-length: 128
{&#34;_index&#34;:&#34;test_index&#34;,&#34;_type&#34;:&#34;user&#34;,&#34;_id&#34;:&#34;1&#34;,&#34;_version&#34;:3,&#34;result&#34;:&#34;updated&#34;,&#34;_shards&#34;:{&#34;total&#34;:2,&#34;successful&#34;:1,&#34;failed&#34;:0}}
</code></pre><h3 id="8删除文档">8.删除文档</h3>
<p><code>DELETE /test_index/user/1</code></p>
<p>例如：</p>
<pre tabindex="0"><code>➜  ~ curl -i -XDELETE http://192.168.11.119:9200/test_index/user/2
HTTP/1.1 200 OK
content-type: application/json; charset=UTF-8
content-length: 141
{&#34;found&#34;:true,&#34;_index&#34;:&#34;test_index&#34;,&#34;_type&#34;:&#34;user&#34;,&#34;_id&#34;:&#34;2&#34;,&#34;_version&#34;:2,&#34;result&#34;:&#34;deleted&#34;,&#34;_shards&#34;:{&#34;total&#34;:2,&#34;successful&#34;:1,&#34;failed&#34;:0}}
</code></pre><h3 id="9查询字符串">9.查询字符串</h3>
<p><code>GET /test_index/user</code></p>
<p>例如：</p>
<pre tabindex="0"><code>➜  ~ curl -i -XGET http://192.168.11.119:9200/test_index/user/_search\?pretty
HTTP/1.1 200 OK
content-type: application/json; charset=UTF-8
content-length: 793
{
  &#34;took&#34; : 1,
  &#34;timed_out&#34; : false,
  &#34;_shards&#34; : {
    &#34;total&#34; : 5,
    &#34;successful&#34; : 5,
    &#34;failed&#34; : 0
  },
  &#34;hits&#34; : {
    &#34;total&#34; : 2,
    &#34;max_score&#34; : 1.0,
    &#34;hits&#34; : [
      {
        &#34;_index&#34; : &#34;test_index&#34;,
        &#34;_type&#34; : &#34;user&#34;,
        &#34;_id&#34; : &#34;2&#34;,
        &#34;_score&#34; : 1.0,
        &#34;_source&#34; : {
          &#34;name&#34; : &#34;小王&#34;,
          &#34;email&#34; : &#34;xiaowang@test.com&#34;,
          &#34;tags&#34; : [
            &#34;游泳&#34;
          ]
        }
      },
      {
        &#34;_index&#34; : &#34;test_index&#34;,
        &#34;_type&#34; : &#34;user&#34;,
        &#34;_id&#34; : &#34;1&#34;,
        &#34;_score&#34; : 1.0,
        &#34;_source&#34; : {
          &#34;name&#34; : &#34;小明&#34;,
          &#34;email&#34; : &#34;xiaoming@demo.com&#34;,
          &#34;tags&#34; : [
            &#34;篮球&#34;,
            &#34;游泳&#34;,
            &#34;足球&#34;
          ]
        }
      }
    ]
  }
}
</code></pre><p>查询返回值参数说明</p>
<pre tabindex="0"><code>took：耗费了几毫秒
timed_out：是否超时，这里是没有
_shards：数据拆成了5个分片，所以对于搜索请求，会打到所有的primary shard（或者是它的某个replica shard也可以）
hits.total：查询结果的数量，3个document
hits.max_score：score的含义，就是document对于一个search的相关度的匹配分数，越相关，就越匹配，分数也高
hits.hits：包含了匹配搜索的document的详细数据
</code></pre><p>搜索名字为bruce的用户，而且按照email倒序</p>
<pre tabindex="0"><code>➜  ~ curl -i -XGET http://192.168.11.119:9200/test_index/user/_search\?pretty\&amp;q=name:&#39;bruce&#39;&amp;sort=email:desc
[1] 26574
HTTP/1.1 200 OK
content-type: application/json; charset=UTF-8
content-length: 479
{
  &#34;took&#34; : 1,
  &#34;timed_out&#34; : false,
  &#34;_shards&#34; : {
    &#34;total&#34; : 5,
    &#34;successful&#34; : 5,
    &#34;failed&#34; : 0
  },
  &#34;hits&#34; : {
    &#34;total&#34; : 1,
    &#34;max_score&#34; : 1.1727304,
    &#34;hits&#34; : [
      {
        &#34;_index&#34; : &#34;test_index&#34;,
        &#34;_type&#34; : &#34;user&#34;,
        &#34;_id&#34; : &#34;4&#34;,
        &#34;_score&#34; : 1.1727304,
        &#34;_source&#34; : {
          &#34;name&#34; : &#34;Bruce&#34;,
          &#34;email&#34; : &#34;bruce@test.com&#34;,
          &#34;tags&#34; : [
            &#34;Hello&#34;
          ]
        }
      }
    ]
  }
}
[1]  + 26574 done       curl -i -XGET
</code></pre><p>通过这个例子发现这样搜索是不区分大小写的.适用于临时的在命令行使用一些工具，比如curl，快速的发出请求，来检索想要的信息；但是如果查询请求很复杂，是很难去构建,在实际的生产环境中，几乎很少使用查询字符串.</p>
<h3 id="10-查询索引的表和字段定义">10. 查询索引的表和字段定义</h3>
<p>查询es所有的表和字段定义
<code>GET /_mapping</code></p>
<p>查询某个索引的表定义
<code>GET /test_index/_mapping</code></p>
<p>查询某个索引的表的字段定义
<code>GET /test_index/user/_mapping</code></p>
<p>例如：</p>
<pre tabindex="0"><code>➜  ~ curl -i -XGET http://192.168.11.119:9200/test_index/_mapping\?pretty
HTTP/1.1 200 OK
content-type: application/json; charset=UTF-8
content-length: 1267
{
  &#34;test_index&#34; : {
    &#34;mappings&#34; : {
      &#34;user&#34; : {
        &#34;properties&#34; : {
          &#34;email&#34; : {
            &#34;type&#34; : &#34;text&#34;,
            &#34;fields&#34; : {
              &#34;keyword&#34; : {
                &#34;type&#34; : &#34;keyword&#34;,
                &#34;ignore_above&#34; : 256
              }
            }
          },
          &#34;name&#34; : {
            &#34;type&#34; : &#34;text&#34;,
            &#34;fields&#34; : {
              &#34;keyword&#34; : {
                &#34;type&#34; : &#34;keyword&#34;,
                &#34;ignore_above&#34; : 256
              }
            }
          },
          &#34;tags&#34; : {
            &#34;type&#34; : &#34;text&#34;,
            &#34;fields&#34; : {
              &#34;keyword&#34; : {
                &#34;type&#34; : &#34;keyword&#34;,
                &#34;ignore_above&#34; : 256
              }
            }
          }
        }
      },
      &#34;role&#34; : {
        &#34;properties&#34; : {
          &#34;flag&#34; : {
            &#34;type&#34; : &#34;text&#34;,
            &#34;fields&#34; : {
              &#34;keyword&#34; : {
                &#34;type&#34; : &#34;keyword&#34;,
                &#34;ignore_above&#34; : 256
              }
            }
          },
          &#34;name&#34; : {
            &#34;type&#34; : &#34;text&#34;,
            &#34;fields&#34; : {
              &#34;keyword&#34; : {
                &#34;type&#34; : &#34;keyword&#34;,
                &#34;ignore_above&#34; : 256
              }
            }
          }
        }
      }
    }
  }
}
</code></pre><h3 id="11查询dsldomain-specified-language特定领域的语言-">11.查询DSL(Domain Specified Language，特定领域的语言 )</h3>
<p>http request body：请求体，可以用json的格式来构建查询语法，比较方便，可以构建各种复杂的语法，比查询字符串肯定强大多了</p>
<ul>
<li><strong>11.1查询所有文档</strong></li>
</ul>
<pre tabindex="0"><code>➜  ~ curl -i -XGET http://192.168.11.119:9200/test_index/user/_search\?pretty -d &#39;
{
  &#34;query&#34;: {
                &#34;match_all&#34;: {
                }
  }
}
&#39;
HTTP/1.1 200 OK
Warning: 299 Elasticsearch-5.5.2-b2f0c09 &#34;Content type detection for rest requests is deprecated. Specify the content type using the [Content-Type] header.&#34; &#34;Wed, 08 Aug 2018 12:58:15 GMT&#34;
content-type: application/json; charset=UTF-8
content-length: 1895
{
  &#34;took&#34; : 1,
  &#34;timed_out&#34; : false,
  &#34;_shards&#34; : {
    &#34;total&#34; : 5,
    &#34;successful&#34; : 5,
    &#34;failed&#34; : 0
  },
  &#34;hits&#34; : {
    &#34;total&#34; : 6,
    &#34;max_score&#34; : 1.0,
    &#34;hits&#34; : [
      {
        &#34;_index&#34; : &#34;test_index&#34;,
        &#34;_type&#34; : &#34;user&#34;,
        &#34;_id&#34; : &#34;5&#34;,
        &#34;_score&#34; : 1.0,
        &#34;_source&#34; : {
          &#34;name&#34; : &#34;bruce&#34;,
          &#34;email&#34; : &#34;bruce@test.com&#34;,
          &#34;tags&#34; : [
            &#34;游泳1&#34;
          ]
        }
      },
      {
        &#34;_index&#34; : &#34;test_index&#34;,
        &#34;_type&#34; : &#34;user&#34;,
        &#34;_id&#34; : &#34;3&#34;,
        &#34;_score&#34; : 1.0,
        &#34;_source&#34; : {
          &#34;name&#34; : &#34;Alex&#34;,
          &#34;email&#34; : &#34;alex@test.com&#34;,
          &#34;tags&#34; : [
            &#34;吃饭&#34;
          ]
        }
      }
    ]
  }
}
</code></pre><p>注意match_all是包含在query字典里的，query处于root节点位置</p>
<ul>
<li><strong>11.2查询包含输入字符的文档</strong></li>
</ul>
<p>query还是处于root节点，增加一个键值sort排序与query同级，示例：</p>
<pre tabindex="0"><code>➜  ~ curl -i -XGET http://192.168.11.119:9200/test_index/user/_search\?pretty -d &#39;
{
  &#34;query&#34;: {
         &#34;match&#34;: {
            &#34;name&#34; : &#34;br&#34;
          }
  },
  &#34;sort&#34;: [
           {
             &#34;email&#34; : &#34;desc&#34;
           }
  ]
}
&#39;
HTTP/1.1 200 OK
Warning: 299 Elasticsearch-5.5.2-b2f0c09 &#34;Content type detection for rest requests is deprecated. Specify the content type using the [Content-Type] header.&#34; &#34;Wed, 08 Aug 2018 13:03:30 GMT&#34;
content-type: application/json; charset=UTF-8
content-length: 193
{
  &#34;took&#34; : 1,
  &#34;timed_out&#34; : false,
  &#34;_shards&#34; : {
    &#34;total&#34; : 5,
    &#34;successful&#34; : 5,
    &#34;failed&#34; : 0
  },
  &#34;hits&#34; : {
    &#34;total&#34; : 0,
    &#34;max_score&#34; : null,
    &#34;hits&#34; : [ ]
  }
}
</code></pre><p>查询包含Br字符的文档（行），并对结果以email倒序。第一次运行上面语句时报错<code>Fielddata is disabled on text fields by default. Set fielddata=true on [email] in order to load fielddata in memory by uninverting the inverted index. Note that this can however use significant memory.&quot;</code>,经查询资料，应该是5.x后对排序、聚合相关操作用单独的数据结构fileddata缓存到内存里，需调接口开启使用到的字段，<a href="https://www.elastic.co/guide/en/elasticsearch/reference/current/fielddata.html">官方解释</a>, 执行下面的操作开启:</p>
<pre tabindex="0"><code>➜  ~ curl -i -XPUT http://192.168.11.119:9200/test_index/_mapping/user\?pretty -d &#39;
{
  &#34;properties&#34;: {
    &#34;email&#34;: {
      &#34;type&#34;: &#34;text&#34;,
      &#34;fielddata&#34;: true
    }
  }
}&#39;
HTTP/1.1 200 OK
Warning: 299 Elasticsearch-5.5.2-b2f0c09 &#34;Content type detection for rest requests is deprecated. Specify the content type using the [Content-Type] header.&#34; &#34;Wed, 08 Aug 2018 13:11:11 GMT&#34;
content-type: application/json; charset=UTF-8
content-length: 28
{
  &#34;acknowledged&#34; : true
}
</code></pre><p>很多查询出来结果集很大，需要做分页，用DSL很简单，和query同级增加from和size键值，分表表示起始值和步长，示例</p>
<pre tabindex="0"><code>curl -i -XGET http://192.168.11.119:9200/test_index/user/_search?pretty -d &#39;
{
  &#34;query&#34;: {
   		&#34;match_all&#34;: {
   		} 
  },
  &#34;from&#34; : 1,
  &#34;size&#34; : 2,
  &#34;_source&#34; : [&#34;email&#34;],
  &#34;sort&#34;: [
  		{
  			&#34;email&#34; : &#34;asc&#34;
  		}
  ]
}
&#39;
</code></pre><ul>
<li><strong>11.3查询过滤器</strong></li>
</ul>
<p>搜索商品名包含Rhinestone，售卖价格小于3大于等于1的商品，结果按售卖价升序，构造DSL语句：</p>
<pre tabindex="0"><code>curl -i -XGET http://192.168.11.119:9200/en_es_category_products/product/_search?pretty -d &#39;
{
  &#34;query&#34;: {
   		&#34;bool&#34;: {
   			&#34;must&#34; : {
   				&#34;match&#34; : {
   					&#34;product_name&#34; : &#34;Rhinestone&#34;
   				}
   			},
   			&#34;filter&#34; : {
   				&#34;range&#34; : {
   					&#34;store_price&#34; : {
   					   &#34;gte&#34; :  1
   						&#34;lt&#34; : 3
   					}
   				}
   			}
   		}
  },
  &#34;_source&#34; : [
  		&#34;product_id&#34;,
  		&#34;product_name&#34;,
  		&#34;store_price&#34;,
  		&#34;icon&#34;
  ],
    &#34;sort&#34;: [
  		{
  			&#34;store_price&#34; : &#34;asc&#34;
  		}
  ]
}
&#39;
</code></pre><p>range操作符包含:</p>
<pre><code>* gt :: 大于
* gte:: 大于等于
* lt :: 小于
* lte:: 小于等于
</code></pre>
<p>查询结果:</p>
<pre tabindex="0"><code>HTTP/1.1 200 OK
Warning: 299 Elasticsearch-5.5.2-b2f0c09 &#34;Content type detection for rest requests is deprecated. Specify the content type using the [Content-Type] header.&#34; &#34;Wed, 08 Aug 2018 13:15:52 GMT&#34;
content-type: application/json; charset=UTF-8
content-length: 1141
{
  &#34;took&#34; : 2,
  &#34;timed_out&#34; : false,
  &#34;_shards&#34; : {
    &#34;total&#34; : 5,
    &#34;successful&#34; : 5,
    &#34;failed&#34; : 0
  },
  &#34;hits&#34; : {
    &#34;total&#34; : 2,
    &#34;max_score&#34; : null,
    &#34;hits&#34; : [
      {
        &#34;_index&#34; : &#34;en_es_category_products&#34;,
        &#34;_type&#34; : &#34;product&#34;,
        &#34;_id&#34; : &#34;22100&#34;,
        &#34;_score&#34; : null,
        &#34;_source&#34; : {
          &#34;product_id&#34; : 22100,
          &#34;icon&#34; : &#34;http://patpatdev.s3.amazonaws.com/Product/22100/1688I-SL-003-00008-001.jpg/1464845443.jpg&#34;,
          &#34;store_price&#34; : &#34;2.99&#34;,
          &#34;product_name&#34; : &#34;U-shape Silver Faux Perarl &amp; Rhinestone Clip&#34;
        },
        &#34;sort&#34; : [
          2.99
        ]
      },
      {
        &#34;_index&#34; : &#34;en_es_category_products&#34;,
        &#34;_type&#34; : &#34;product&#34;,
        &#34;_id&#34; : &#34;354460&#34;,
        &#34;_score&#34; : null,
        &#34;_source&#34; : {
          &#34;product_id&#34; : 354460,
          &#34;icon&#34; : &#34;http://patpatdev.s3.us-west-1.amazonaws.com/product/000766000119/5b0e5b0e49e8f.jpg&#34;,
          &#34;store_price&#34; : &#34;2.99&#34;,
          &#34;product_name&#34; : &#34;Pretty Star Decor Rhinestone Stud Hairband for Women&#34;
        },
        &#34;sort&#34; : [
          2.99
        ]
      }
    ]
  }
}
</code></pre><p>注意参数嵌套了好几层，很容易写错，query、_source、sort都处于root级，query/bool下包含must、filter两级</p>
]]></content>
		</item>
		
		<item>
			<title>搭建EKK日志收集分析系统</title>
			<link>http://www.heyuan110.com/posts/elasticsearch/2018-09-12-log-ekk/</link>
			<pubDate>Wed, 12 Sep 2018 18:52:59 +0000</pubDate>
			
			<guid>http://www.heyuan110.com/posts/elasticsearch/2018-09-12-log-ekk/</guid>
			<description>EKK是一套基于AWS相关服务搭建的日志收集系统，包含Amazon Elasticsearch Service, Amazon Kinesis, and Kibana，简称EKK.相比ELK搭建维护运维复杂，EKK更加简便。下图是EKK基本架构：
本文重点记录nginx日志怎样收集和以正确格式存到es，不会就每一步详细讲解。
一、准备工作： 开一台ec2，选择ubuntu16.04，搭建nginx一个nginx服务，设置nginx日志格式: log_format main &amp;#39;$remote_addr - $remote_user [$time_local] &amp;#34;$request&amp;#34; &amp;#39; &amp;#39;$status $body_bytes_sent &amp;#34;$http_referer&amp;#34; &amp;#39; &amp;#39;&amp;#34;$http_user_agent&amp;#34; &amp;#34;$http_x_forwarded_for&amp;#34; &amp;#39; &amp;#39;$connection &amp;#34;$upstream_addr&amp;#34; &amp;#39; &amp;#39;upstream_response_time $upstream_response_time request_time $request_time&amp;#39;; 最终access.log里的日志格式如下：
192.168.13.1 - - [12/Sep/2018:03:59:12 +0000] &amp;#34;GET /v1/home HTTP/1.1&amp;#34; 2002787 &amp;#34;https://test.com/product/Sweet-Ice-Cream-Short-sleeve-Top-and-Pink-Shorts-for-Toddler-Baby.html&amp;#34; &amp;#34;Mozilla/5.0 (iPhone; CPU iPhone OS 11_4_1 like Mac OS X) AppleWebKit/605.1.15 (KHTML, like Gecko) Mobile/15G77 [FBAN/FBIOS;FBDV/iPhone7,2;FBMD/iPhone;FBSN/iOS;FBSV/11.4.1;FBSS/2;FBCR/Telekom.de;FBID/phone;FBLC/de_DE;FBOP/5;FBRV/123725744]&amp;#34; &amp;#34;2002:c7:6f02:9801:d506:6bda:e6ca:b6f9, 112.118.106.116&amp;#34; 12340 &amp;#34;127.0.0.1:9000&amp;#34; upstream_response_time 0.11 request_time 0.11 创建可访问Kinesis stream或Kinesis firehose, AWS ES服务的IAM账号，保存awsAccessKeyId和awsSecretAccessKey。 AWS上启动ES服务TestES，创建时类型务必选择public，后面再做安全策略。 创建Kinesis firehose(如果有一个源对多个标的的需求可以使用Kinesis stream)，数据流向选择上面创建的TestES。 准备工作大概完成。</description>
			<content type="html"><![CDATA[<p>EKK是一套基于AWS相关服务搭建的日志收集系统，包含Amazon Elasticsearch Service, Amazon Kinesis, and Kibana，简称EKK.相比ELK搭建维护运维复杂，EKK更加简便。下图是EKK基本架构：</p>
<p><img src="https://d2908q01vomqb2.cloudfront.net/472b07b9fcf2c2451e8781e944bf5f77cd8457c8/2017/09/07/1-2.png" alt="EKK"></p>
<p>本文重点记录nginx日志怎样收集和以正确格式存到es，不会就每一步详细讲解。</p>
<h2 id="一准备工作">一、准备工作：</h2>
<ol>
<li>开一台ec2，选择ubuntu16.04，搭建nginx一个nginx服务，设置nginx日志格式:</li>
</ol>
<pre tabindex="0"><code>log_format  main  &#39;$remote_addr - $remote_user [$time_local] &#34;$request&#34; &#39;
                      &#39;$status $body_bytes_sent &#34;$http_referer&#34; &#39;
                      &#39;&#34;$http_user_agent&#34; &#34;$http_x_forwarded_for&#34; &#39;
                      &#39;$connection &#34;$upstream_addr&#34; &#39;
                      &#39;upstream_response_time $upstream_response_time request_time $request_time&#39;;
</code></pre><p>最终access.log里的日志格式如下：</p>
<pre tabindex="0"><code>192.168.13.1 - - [12/Sep/2018:03:59:12 +0000] 
&#34;GET /v1/home HTTP/1.1&#34; 2002787 &#34;https://test.com/product/Sweet-Ice-Cream-Short-sleeve-Top-and-Pink-Shorts-for-Toddler-Baby.html&#34; &#34;Mozilla/5.0 (iPhone; CPU iPhone OS 11_4_1 like Mac OS X) AppleWebKit/605.1.15 (KHTML, like Gecko) Mobile/15G77 [FBAN/FBIOS;FBDV/iPhone7,2;FBMD/iPhone;FBSN/iOS;FBSV/11.4.1;FBSS/2;FBCR/Telekom.de;FBID/phone;FBLC/de_DE;FBOP/5;FBRV/123725744]&#34; &#34;2002:c7:6f02:9801:d506:6bda:e6ca:b6f9, 112.118.106.116&#34; 12340 &#34;127.0.0.1:9000&#34; upstream_response_time 0.11 request_time 0.11
</code></pre><ol start="2">
<li>创建可访问Kinesis stream或Kinesis firehose, AWS ES服务的IAM账号，保存awsAccessKeyId和awsSecretAccessKey。</li>
<li>AWS上启动ES服务TestES，创建时类型务必选择public，后面再做安全策略。</li>
<li>创建Kinesis firehose(如果有一个源对多个标的的需求可以使用Kinesis stream)，数据流向选择上面创建的TestES。</li>
</ol>
<p>准备工作大概完成。</p>
<h2 id="二收集日志">二、收集日志</h2>
<ol>
<li>在ec2上安装Amazon Kinesis Agent:</li>
</ol>
<pre tabindex="0"><code>1. 下载源码
git clone https://github.com/awslabs/amazon-kinesis-agent.git

2. 在aws的ubuntu16.04上需再安装java jdk
sudo apt-get install openjdk-8-jdk

3. 开始安装
sudo ./setup --install

完成没报错会有安装成功提示，并提示怎么配置和启动服务
</code></pre><ol start="2">
<li>编辑agent配置文件/etc/aws-kinesis/agent.json，默认如下：</li>
</ol>
<pre tabindex="0"><code>{
    &#34;cloudwatch.emitMetrics&#34;: true,
    &#34;kinesis.endpoint&#34;: &#34;https://your/kinesis/endpoint&#34;, 
    &#34;firehose.endpoint&#34;: &#34;https://your/firehose/endpoint&#34;, 
    &#34;flows&#34;: [
        {
            &#34;filePattern&#34;: &#34;/tmp/app1.log*&#34;, 
            &#34;kinesisStream&#34;: &#34;yourkinesisstream&#34;
        }, 
        {
            &#34;filePattern&#34;: &#34;/tmp/app2.log*&#34;,
            &#34;deliveryStream&#34;: &#34;yourfirehosedeliverystream&#34; 
        }
    ] 
}
</code></pre><p>cloudwatch.emitMetrics：是否开启cloudwatch监控
kinesis.endpoint： Kinesis stream的endpoint设置
firehose.endpoint：firehose的endpoint
各end point地址: <a href="https://docs.aws.amazon.com/general/latest/gr/rande.html">https://docs.aws.amazon.com/general/latest/gr/rande.html</a></p>
<p>这里不搬教程，关于上面参数详细参考<a href="https://docs.aws.amazon.com/streams/latest/dev/writing-with-agents.html">https://docs.aws.amazon.com/streams/latest/dev/writing-with-agents.html</a></p>
<p>官方默认的那个配置有点坑，直接贴可以用的agent.json:</p>
<p><strong>配置1</strong></p>
<pre tabindex="0"><code>{
&#34;awsAccessKeyId&#34;: &#34;xxxxx&#34;,
&#34;awsSecretAccessKey&#34;: &#34;xxxxxxxxxxxxxxxxx&#34;,
&#34;cloudwatch.emitMetrics&#34;: false,
&#34;firehose.endpoint&#34;: &#34;firehose.us-west-2.amazonaws.com&#34;,
&#34;cloudwatch.endpoint&#34;: &#34;https://monitoring.us-west-2.amazonaws.com&#34;,
&#34;kinesis.endpoint&#34;: &#34;https://kinesis.us-west-2.amazonaws.com&#34;,
  &#34;flows&#34;: [
    {
      &#34;filePattern&#34;: &#34;/usr/local/programs/nginx/logs/access.log&#34;,
      &#34;deliveryStream&#34;: &#34;api-nginx-access-log&#34;,
      &#34;dataProcessingOptions&#34;: [
                {
                    &#34;optionName&#34;: &#34;LOGTOJSON&#34;,
                    &#34;logFormat&#34;: &#34;COMMONAPACHELOG&#34;,
                    &#34;matchPattern&#34;: &#34;^([\\d.]+) \\S+ \\S+ \\[([\\w:/]+)\\s[+\\-]\\d{4}\\] \&#34;([A-Z]+) (.+?) ([\\w./]+)\&#34; (\\d{3}) (\\d+) \&#34;(.+?)\&#34; \&#34;(.+?)\&#34; \&#34;(.+?)\&#34; (\\d+) \&#34;(.+?)\&#34; upstream_response_time (\\d.+) request_time (\\d.+)&#34;,
                                &#34;customFieldNames&#34;: [&#34;remote_addr&#34;, &#34;datetime&#34;, &#34;request_type&#34;, &#34;request_url&#34;, &#34;http_version&#34;, &#34;response_status&#34;, &#34;body_bytes_sent&#34;, &#34;http_referer&#34;, &#34;http_user_agent&#34;, &#34;http_x_forwarded_for&#34;, &#34;connection_serial_number&#34;, &#34;upstream_addr&#34;, &#34;upstream_response_time&#34;, &#34;request_time&#34;]
                }
        ]
    }
  ]
}
</code></pre><p><strong>配置2</strong></p>
<pre tabindex="0"><code>{
&#34;awsAccessKeyId&#34;: &#34;xxxxx&#34;,
&#34;awsSecretAccessKey&#34;: &#34;xxxxxxxxxxxxxxxxxxxx&#34;,
&#34;cloudwatch.emitMetrics&#34;: false,
&#34;cloudwatch.endpoint&#34;: &#34;https://monitoring.us-west-2.amazonaws.com&#34;,
&#34;kinesis.endpoint&#34;: &#34;https://kinesis.us-west-2.amazonaws.com&#34;,
  &#34;flows&#34;: [
    {
      &#34;filePattern&#34;: &#34;/usr/local/programs/nginx/logs/access.log&#34;,
      &#34;kinesisStream&#34;: &#34;api-nginx-access-log&#34;,
      &#34;partitionKeyOption&#34;: &#34;RANDOM&#34;,
      &#34;dataProcessingOptions&#34;: [
                {
                    &#34;optionName&#34;: &#34;LOGTOJSON&#34;,
                    &#34;logFormat&#34;: &#34;COMMONAPACHELOG&#34;
                }
        ]
    }
  ]
}
</code></pre><p>配置1是firehose收集，配置2 kinesis stream收集。</p>
<p>awsAccessKeyId和awsSecretAccessKey访问授权的，注意end-point是分区域的，每个区域地址不一样。</p>
<p>logFormat用COMMONAPACHELOG默认格式无法解析到全部想要字段，需要自定义正则和字段去解析，Kinesis agent是java程序，所以这里的matchPattern要用java格式正则，这个必须要注意。</p>
<p>找到了一个好的调试办法，打开<a href="https://tool.lu/coderunner">https://tool.lu/coderunner</a>,选择java语言粘贴如下代码：</p>
<pre tabindex="0"><code>import java.util.regex.Matcher;
import java.util.regex.Pattern;

public class RegexMatches
{
	public static void main( String args[] ){

		// 按指定模式在字符串查找
		String line = &#34;132.31.43.24 - - [12/Sep/2018:05:58:36 +0000] \&#34;POST /v1/tracks/hello HTTP/1.1\&#34; 200 79993 \&#34;https://test.com/category/Baby-Toddlers.html?category_id=27&amp;son_category_id=%5B%5D&amp;tag_id=&amp;last_id=0&amp;filter=%7B%22On%20Sale%22%3A%5B%5D,%22Size%22%3A%5B%5D,%22Color%22%3A%5B%5D,%22Season%22%3A%5B%5D,%22Style%22%3A%5B%5D,%22Occasion%22%3A%5B%5D,%22Price%22%3A%5B%5D%7D&amp;sort=3&amp;page=1&amp;is_sale=&amp;start_price=&amp;end_price=&amp;utm_source=FB&amp;utm_medium=Dannie&amp;utm_campaign=09-06-Baby-Toddlers-12&amp;adlk_id=30051\&#34; \&#34;Mozilla/5.0 (iPhone; CPUiPhone OS 11_4_1 like Mac OS X) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/11.0 Mobile/15E148 Safari/604.1\&#34; \&#34;17.47.23.134, 12.128.106.104\&#34; 74518 \&#34;127.0.0.1:9000\&#34; upstream_response_time 20.186 request_time 0.186&#34;;
		
		String pattern = &#34;^([\\d.]+) (\\S+) (\\S+) \\[([\\w:/]+\\s[+\\-]\\d{4})\\] \&#34;([A-Z]+) (.+?) ([\\w./]+)\&#34; (\\d{3}) (\\d+) \&#34;(.+?)\&#34; \&#34;(.+?)\&#34; \&#34;(.+?)\&#34; (\\d+) \&#34;(.+?)\&#34; upstream_response_time (\\d.+) request_time (\\d.+)&#34;;

		// 创建 Pattern 对象
		Pattern r = Pattern.compile(pattern);

		// 现在创建 matcher 对象
		Matcher m = r.matcher(line);
		if (m.find( )) {
			System.out.println(&#34;remote_addr: &#34; + m.group(1) );
			System.out.println(&#34;ident: &#34; + m.group(2) );
			System.out.println(&#34;authuser: &#34; + m.group(3) );
			System.out.println(&#34;datetime: &#34; + m.group(4) ); 
			System.out.println(&#34;request_type: &#34; + m.group(5) ); 
			System.out.println(&#34;request_url: &#34; + m.group(6) ); 
			System.out.println(&#34;http_version: &#34; + m.group(7) ); 
			System.out.println(&#34;response_status: &#34; + m.group(8) );
			System.out.println(&#34;body_bytes_sent: &#34; + m.group(9) );
			System.out.println(&#34;http_referer: &#34; + m.group(10) );
			System.out.println(&#34;http_user_agent: &#34; + m.group(11) );
			System.out.println(&#34;http_x_forwarded_for: &#34; + m.group(12) );
			System.out.println(&#34;connection_serial_number: &#34; + m.group(13) );
			System.out.println(&#34;upstream_addr: &#34; + m.group(13) );
			System.out.println(&#34;connection_serial_number: &#34; + m.group(13) );
			System.out.println(&#34;upstream_addr: &#34; + m.group(14) );
			System.out.println(&#34;upstream_response_time: &#34; + m.group(15) );
			System.out.println(&#34;request_time: &#34; + m.group(16) );
		} else {
			System.out.println(&#34;NO MATCH&#34;);
		}
	}
}
</code></pre><p>字符串要java转义过的，可以用下面网站先转义再用<a href="http://tool.what21.com/tool/javaStr.html">http://tool.what21.com/tool/javaStr.html</a></p>
<p>可以自己改上面的源字符串和正则调试。当正则调好符合要求时把它复制到matchPattern配置里。</p>
<p>Kinesis agent相关操作：
启动： <code>sudo service aws-kinesis-agent start</code>
重启：<code>sudo service aws-kinesis-agent restart</code>
停止：<code>sudo service aws-kinesis-agent status</code></p>
<p>每次调整了配置重启即可</p>
<h2 id="三配置es索引模板">三、配置ES索引模板</h2>
<p>上面的数据直接从agent-&gt;firehose-&gt;eS可以直接跑通，但有字段类型问题，全部是text类型，例如我们希望进去的datetime是date类型，怎么办？通过ES template解决。创建如下的ES Template:</p>
<pre tabindex="0"><code> curl -i -XPUT https://192.168.11.120:9200/_template/nginx-access-log_template -d &#39;{
    &#34;template&#34;: &#34;*-nginx-access-log-*&#34;,
    &#34;mappings&#34;: {
        &#34;log&#34;: {
            &#34;_all&#34;: { &#34;enabled&#34;: false }, 
            &#34;properties&#34;: {
                &#34;remote_addr&#34;: {
                    &#34;type&#34;: &#34;text&#34;,
                    &#34;fields&#34;: {
                        &#34;keyword&#34;: {
                            &#34;type&#34;: &#34;keyword&#34;
                        }
                    }
                },
                &#34;request_type&#34;: {
                    &#34;type&#34;: &#34;text&#34;,
                    &#34;fields&#34;: {
                        &#34;keyword&#34;: {
                            &#34;type&#34;: &#34;keyword&#34;
                        }
                    }
                },
                &#34;request_url&#34;: {
                    &#34;type&#34;: &#34;text&#34;,
                    &#34;fields&#34;: {
                        &#34;keyword&#34;: {
                            &#34;type&#34;: &#34;keyword&#34;
                        }
                    }
                },
                &#34;http_version&#34;: {
                    &#34;type&#34;: &#34;text&#34;,
                    &#34;fields&#34;: {
                        &#34;keyword&#34;: {
                            &#34;type&#34;: &#34;keyword&#34;
                        }
                    }
                },
                &#34;response_status&#34;: {
                    &#34;type&#34;: &#34;text&#34;,
                    &#34;fields&#34;: {
                        &#34;keyword&#34;: {
                            &#34;type&#34;: &#34;keyword&#34;
                        }
                    }
                },
                &#34;body_bytes_sent&#34;: {
                    &#34;type&#34;: &#34;long&#34;
                },
                &#34;http_referer&#34;: {
                    &#34;type&#34;: &#34;text&#34;,
                    &#34;fields&#34;: {
                        &#34;keyword&#34;: {
                            &#34;type&#34;: &#34;keyword&#34;
                        }
                    }
                },
                &#34;http_user_agent&#34;: {
                    &#34;type&#34;: &#34;text&#34;,
                    &#34;fields&#34;: {
                        &#34;keyword&#34;: {
                            &#34;type&#34;: &#34;keyword&#34;
                        }
                    }
                },
                &#34;http_x_forwarded_for&#34;: {
                    &#34;type&#34;: &#34;text&#34;,
                    &#34;fields&#34;: {
                        &#34;keyword&#34;: {
                            &#34;type&#34;: &#34;keyword&#34;
                        }
                    }
                },
                &#34;connection_serial_number&#34;: {
                    &#34;type&#34;: &#34;long&#34;
                },
                &#34;upstream_addr&#34;: {
                    &#34;type&#34;: &#34;text&#34;,
                    &#34;fields&#34;: {
                        &#34;keyword&#34;: {
                            &#34;type&#34;: &#34;keyword&#34;
                        }
                    }
                },
                &#34;upstream_response_time&#34;: {
                    &#34;type&#34;: &#34;double&#34;
                },
                &#34;request_time&#34;: {
                    &#34;type&#34;: &#34;double&#34;
                },
                &#34;datetime&#34;: {
                    &#34;type&#34;: &#34;date&#34;,
                    &#34;format&#34;: &#34;dd/MMM/YYYY:HH:mm:ss&#34;
                }
            }
        }
    }
}&#39;
</code></pre><p>模板名称nginx-access-log_template，设置模板套用规则*-nginx-access-log-*，例如aaaa-nginx-access-log-2018-08-02，bbbbb-ccc-nginx-access-log-2018-08-08类似的索引会自动套用，非常方便~</p>
<p>*<em>需要注意datetime字段类型是date，format格式和常见的不太一样，这个坑被忽略爬了半天~_~,nginx log的时间默认是time_local，常见的是time_iso8601</em></p>
<p>怎么查询模板，删除模板，查看索引，删除索引可以在es专栏查看。</p>
<h2 id="四完成">四、完成</h2>
<p>贴一张日志传到kibana的截图：</p>
<p><img src="/uploads/2018/kb.png" alt="EKK"></p>
<p>未解决：没有国家信息，浏览器设备信息没细化，解决思路在Firehose往ES传输之间增加lambda处理</p>
]]></content>
		</item>
		
		<item>
			<title>搭建ELK日志收集分析系统</title>
			<link>http://www.heyuan110.com/posts/elasticsearch/2018-09-11-log-elk/</link>
			<pubDate>Tue, 11 Sep 2018 20:02:19 +0000</pubDate>
			
			<guid>http://www.heyuan110.com/posts/elasticsearch/2018-09-11-log-elk/</guid>
			<description>日志主要包含系统日志、应用日志和安全日志。运维和开发人员通过日志可以了解服务器、程序运行情况，发现错误及检查错误发生原因。一个可靠、安全、可扩展的日志收集分析解决方案在程序或系统异常时能够让一切都变得轻松起来。
对比了ELK几种搭建模式：
filebeat-&amp;gt;elasticsearch-&amp;gt;kibana filebeat-&amp;gt;logstash-&amp;gt;kafaka&amp;amp;zookeeper-&amp;gt;logstash-&amp;gt;elasticsearch-&amp;gt;kibana filebeat-&amp;gt;kafaka&amp;amp;zookeeper-&amp;gt;logstash-&amp;gt;elasticsearch-&amp;gt;kibana 架构 从左到右分别为：
1)、数据采集层，将采集到的日志分别发送到kafka broker的集群队列上去
2)、数据缓存层，将采集到的日志临时转存到本地的kafka broker集群中(相当于队列的生产者)
3)、数据处理转发层，logstash实时去kafka broker集群拉去日志，在经过本地logstash后进行日志分析处理，然后转发到后端elasticsearch(相当于队列的消费者)
4)、数据存储展示层，elasticsearch将收集到的日志进行本地存储，然后通过kibana展示出来；由于elasticsearch采用集群的方式，前端通过nginx在反向代理kibana的访问地址，使用户访问入口只有一个
资源列表 服务器名称 IP地址 角色 功能 kz1 172.31.2.2 kafka+zookeeper kafka broker节点1 kz2 172.31.2.3 kafka+zookeeper kafka broker节点2 logstash-web 172.31.2.4 logstash 处理转发web相关日志 logstash-app 172.31.2.5 logstash 处理转发app相关日志 es-node1 172.31.2.6 elasticsearch+kibana 数据存储展示 es-node2 172.31.2.7 elasticsearch+kibana 数据存储展示 硬件配置 服务器类型 实例类型 CPU 内存 Disk Kafka broker集群 r5.xlarge 4 32 1T Logstash c5.2xlarge 8 16 100G Elasticsearch+kibana r5.xlarge 4 32 2T 部署前的准备工作 分别在这6台服务器上进行设置
1)、主机名设置 $ sudo vim /etc/hosts</description>
			<content type="html"><![CDATA[<p>日志主要包含系统日志、应用日志和安全日志。运维和开发人员通过日志可以了解服务器、程序运行情况，发现错误及检查错误发生原因。一个可靠、安全、可扩展的日志收集分析解决方案在程序或系统异常时能够让一切都变得轻松起来。</p>
<p>对比了ELK几种搭建模式：</p>
<ol>
<li>filebeat-&gt;elasticsearch-&gt;kibana</li>
<li>filebeat-&gt;logstash-&gt;kafaka&amp;zookeeper-&gt;logstash-&gt;elasticsearch-&gt;kibana</li>
<li>filebeat-&gt;kafaka&amp;zookeeper-&gt;logstash-&gt;elasticsearch-&gt;kibana</li>
</ol>
<h2 id="架构">架构</h2>
<p><img src="https://raw.githubusercontent.com/heyuan110/static-source/master/media/15525328567089.jpg" alt=""></p>
<p>从左到右分别为：</p>
<p>1)、数据采集层，将采集到的日志分别发送到kafka broker的集群队列上去</p>
<p>2)、数据缓存层，将采集到的日志临时转存到本地的kafka broker集群中(相当于队列的生产者)</p>
<p>3)、数据处理转发层，logstash实时去kafka broker集群拉去日志，在经过本地logstash后进行日志分析处理，然后转发到后端elasticsearch(相当于队列的消费者)</p>
<p>4)、数据存储展示层，elasticsearch将收集到的日志进行本地存储，然后通过kibana展示出来；由于elasticsearch采用集群的方式，前端通过nginx在反向代理kibana的访问地址，使用户访问入口只有一个</p>
<h2 id="资源列表">资源列表</h2>
<table>
<thead>
<tr>
<th>服务器名称</th>
<th>IP地址</th>
<th>角色</th>
<th>功能</th>
</tr>
</thead>
<tbody>
<tr>
<td>kz1</td>
<td>172.31.2.2</td>
<td>kafka+zookeeper</td>
<td>kafka broker节点1</td>
</tr>
<tr>
<td>kz2</td>
<td>172.31.2.3</td>
<td>kafka+zookeeper</td>
<td>kafka broker节点2</td>
</tr>
<tr>
<td>logstash-web</td>
<td>172.31.2.4</td>
<td>logstash</td>
<td>处理转发web相关日志</td>
</tr>
<tr>
<td>logstash-app</td>
<td>172.31.2.5</td>
<td>logstash</td>
<td>处理转发app相关日志</td>
</tr>
<tr>
<td>es-node1</td>
<td>172.31.2.6</td>
<td>elasticsearch+kibana</td>
<td>数据存储展示</td>
</tr>
<tr>
<td>es-node2</td>
<td>172.31.2.7</td>
<td>elasticsearch+kibana</td>
<td>数据存储展示</td>
</tr>
</tbody>
</table>
<h2 id="硬件配置">硬件配置</h2>
<table>
<thead>
<tr>
<th>服务器类型</th>
<th>实例类型</th>
<th>CPU</th>
<th>内存</th>
<th>Disk</th>
</tr>
</thead>
<tbody>
<tr>
<td>Kafka broker集群</td>
<td>r5.xlarge</td>
<td>4</td>
<td>32</td>
<td>1T</td>
</tr>
<tr>
<td>Logstash</td>
<td>c5.2xlarge</td>
<td>8</td>
<td>16</td>
<td>100G</td>
</tr>
<tr>
<td>Elasticsearch+kibana</td>
<td>r5.xlarge</td>
<td>4</td>
<td>32</td>
<td>2T</td>
</tr>
</tbody>
</table>
<h2 id="部署前的准备工作">部署前的准备工作</h2>
<p>分别在这6台服务器上进行设置</p>
<h3 id="1主机名设置">1)、主机名设置</h3>
<p><code>$ sudo vim /etc/hosts</code></p>
<pre tabindex="0"><code>172.31.2.2  kz1

172.31.2.3  kz2

172.31.2.4  logstash-web

172.31.2.5  logstash-app

172.31.2.6  es-node1

172.31.2.7  es-node2
</code></pre><p>验证：在其中任何一台服务器上ping 主机名，能通，则代表设置生效</p>
<p>(备注：需要在aws上的ec2的安全策略上分别开启ICMP流量)</p>
<h3 id="2系统优化">2)、系统优化</h3>
<p>2.1)、打开最大文件描述符</p>
<p><code>$ sudo vim /etc/security/limits.conf</code></p>
<pre tabindex="0"><code>*      soft        nofile    65535

*      hard       nofile      65535

*      soft        nproc      2048

*      hard       nproc      4096
</code></pre><p>验证：退出当前终端在重新登录，$ ulimit -n 显示65535，表示设置生效</p>
<p>2.2)、内核调整</p>
<p><code>$ sudo vim /etc/sysctl.conf</code></p>
<pre tabindex="0"><code>vm.max_map_count = 262144             # elasticsearch启动时所拥有的虚拟内存区域数量，过小，es会无法启动

vm.swappiness = 0                                   # 不使用虚拟内存
</code></pre><p>设置生效： <code>$ sudo sysctl -p</code></p>
<h3 id="3软件包准备">3)、软件包准备</h3>
<p>jdk-8u151-linux-x64.tar.gz</p>
<p>filebeat-5.5.2-linux-x86_64.tar.gz</p>
<p>kafka_2.12-2.0.0.tgz</p>
<p>zookeeper-3.4.13.tar.gz</p>
<p>logstash-5.5.2.tar.gz</p>
<p>elasticsearch-5.5.2.tar.gz</p>
<p>kibana-5.5.2-linux-x86_64.tar.gz</p>
<p>备注：软件包存放位置 /usr/local/programs/src</p>
<h3 id="4安装配置supervisor">4)、安装配置supervisor</h3>
<p><code>$ sudo mkdir /usr/local/programs/supervisor -pv</code></p>
<p><code>$ sudo apt-get update</code></p>
<p><code>$ sudo apt-get install python-pip –y</code></p>
<p><code>$ sudo locale-gen zh_CN.UTF-8 en_US.UTF-8</code></p>
<p><code>$ sudo pip install supervisor</code></p>
<p><code>$ sudo su</code></p>
<p><code>$ /usr/local/bin/echo_supervisord_conf &gt; /usr/local/programs/supervisor/supervisord.conf</code></p>
<p>supervisor配置文件修改调整</p>
<p><code>$ sudo vim supervisord.conf</code></p>
<pre tabindex="0"><code>[inet_http_server]                                                           # 去掉前面的注释

port=127.0.0.1:9001                                                       # 去掉前面的注释,开启supervisor端口监听

[supervisord]

logfile=/usr/local/programs/supervisor/supervisord.log  # 设置supervisor的日志文件路径

environment=JAVA_HOME=&#34;/usr/local/programs/jdk&#34;      # 设置java环境变量

[include]

files = conf.d/*.conf                                                        # supervisor包含的配置文件，此处使用相对路径
</code></pre><p><strong>备注：需创建服务配置目录：$ sudo mkdir /usr/local/programs/supervisor/conf.d</strong></p>
<h2 id="部署过程">部署过程</h2>
<h3 id="1jdk安装">1)、jdk安装</h3>
<p>以下操作分别在这6台服务器上安装</p>
<h4 id="11解压安装包并指定目录">1.1)、解压安装包并指定目录</h4>
<p><code>$ sudo tar -zxvf jdk-8u151-linux-x64.tar.gz -C /usr/local/programs</code></p>
<p><code>$ cd /usr/local/programs &amp;&amp; sudo mv jdk1.8.0_151 jdk</code></p>
<h4 id="12设置全局环境变量">1.2)、设置全局环境变量</h4>
<p>编辑/etc/profile在文件在最后添加如下内容：</p>
<p><code># set java environment</code></p>
<pre tabindex="0"><code>export JAVA_HOME=/usr/local/programs/jdk

export JRE_HOME=$JAVA_HOME/jre

export CLASSPATH=.:$JAVA_HOME/lib:$JRE_HOME/lib:$CLASSPATH

export PATH=$JAVA_HOME/bin:$JRE_HOME/bin:$PATH
</code></pre><h4 id="13使jdk环境变量配置生效">1.3)、使Jdk环境变量配置生效</h4>
<p><code>$ source /etc/profile</code></p>
<h4 id="14验证">1.4)、验证</h4>
<p><code>$ echo $JAVA_HOME</code></p>
<h3 id="2zookeeper安装配置">2)、zookeeper安装配置</h3>
<p>以下操作步骤在kz1和kz2服务器上进行安装部署</p>
<h5 id="21解压软件包到指定目录">2.1)、解压软件包到指定目录</h5>
<p><code>$ sudo tar -zxvf zookeeper-3.4.13.tar.gz -C /usr/local/programs</code></p>
<p><code>$ cd /usr/local/programs &amp;&amp; sudo mv zookeeper-3.4.13 zookeeper</code></p>
<h5 id="22编辑zookeeper配置文件">2.2)、编辑zookeeper配置文件</h5>
<p><code>$ cd /usr/local/programs/zookeeper/conf</code></p>
<p><code>$ cp -a zoo_sample.cfg zoo.cfg</code></p>
<p><code>$ sudo vim zoo.cfg</code></p>
<p>完整配置文件如下：</p>
<pre tabindex="0"><code>tickTime=2000

# zookeeper服务器之间或客户端与服务器之间维持心跳的时间间隔，每个tickTime时间会发送一次心跳

initLimit=10

# 集群中Zookeeper的leader和Follower服务器之间初始化连接时最长能忍受多少个心跳时间间隔数，总的时间长度为5*2000-10秒，当超过这个长度时，Zookeeper服务器还没有收到客户端的返回信息，表明客户端连接失败

syncLimit=5

# zookeeper集群中Leader与Follower之间发送消息，请求和应答时间长度，最长不能超过多少个tickTime的时间长度，此时为5*2000=10秒

dataDir=/usr/local/programs/zookeeper/data

# 设置zookeeper保存数据的目录，默认zookeeper将写数据的日志文件也保存在这个目录里

dataLogDir=/usr/local/programs/zookeeper/logs

# 设置Zookeeper保存日志的目录

clientPort=2181

# 客户端连接zookeeper服务器的端口，zookeeper会监听这个端口，接受客户端的访问请求

server.1=172.31.2.2:2888:3888

server.2=172.31.2.3:2888:3888

# 此选项为集群配置选项：server.1：代表是第几号服务器；172.31.2.2：代表这个服务器的IP地址；2888：表示这个服务器与集群中的Leader服务器交换信息的端口；3888：表示万一集群中的Leader服务器挂了，需要一个端口来重新进行选举，选出一个新的Leader，而这个端口就是用来执行选举时服务器相互通信的端口
</code></pre><p>备注：将此配置文件同步至kafka broker集群中的另外两台服务器上</p>
<h5 id="23创建myid文件">2.3)、创建myid文件</h5>
<p>在172.31.2.2(kz1)服务器上执行：</p>
<p><code>$ echo 1 &gt; /usr/local/programs/zookeeper/data/myid</code></p>
<p>在172.31.2.3(kz2)服务器上执行：</p>
<p><code>echo 2 &gt; /usr/local/programs/zookeeper/data/myid</code></p>
<p>备注：此时的myid文件必须创建在zoo.cfg配置文件里面的dataDir指定的目录内</p>
<p>myid文件说明：zookeeper启动时会读取这个文件，拿到里面的数据与zoo.cfg里面的配置信息比较从而判断自己到底是哪个server</p>
<h5 id="24启动zookeeper服务">2.4)、启动zookeeper服务</h5>
<p>分别在172.31.2.2、172.31.2.3这两台服务器上执行如下命令：</p>
<p><code>$ sudo /usr/local/programs/zookeeper/bin/zkServer.sh start</code></p>
<p>备注：zookeeper默认是以后台方式启动</p>
<p>前台启动方式为：<code>$ sudo /usr/local/programs/zookeeper/bin/zkServer.sh start-foreground</code></p>
<h5 id="25查看zookeeper集群状态">2.5)、查看zookeeper集群状态</h5>
<p>分别在172.31.2.2、172.31.2.3这两台服务器上执行如下命令：</p>
<pre tabindex="0"><code># 172.31.2.2

/usr/local/programs/zookeeper/bin/zkServer.sh status

ZooKeeper JMX enabled by default

Using config: /usr/local/programs/zookeeper/bin/../conf/zoo.cfg

Mode: follower


#172.31.2.3

/usr/local/programs/zookeeper/bin/zkServer.sh status

ZooKeeper JMX enabled by default

Using config: /usr/local/programs/zookeeper/bin/../conf/zoo.cfg

Mode: leader

Mode: follower
</code></pre><h3 id="3kafka集群安装配置">3)、kafka集群安装配置</h3>
<h4 id="31解压安装到指定目录">3.1)、解压安装到指定目录</h4>
<p><code>$ sudo tar -zxvf kafka_2.12-2.0.0.tgz -C /usr/local/programs/kafka</code></p>
<h4 id="32kafka-jvm内存调整">3.2)、Kafka jvm内存调整</h4>
<p><code>$ sudo vim /usr/local/programs/kafka/bin/kafka-server-start.sh</code></p>
<p>修改如下地方：</p>
<pre tabindex="0"><code>if [ &#34;x$KAFKA_HEAP_OPTS&#34; = &#34;x&#34; ]; then

export KAFKA_HEAP_OPTS=&#34;-Xmx4G -Xms4G&#34;          # 此处设置为内存的一半

fi
</code></pre><h4 id="33修改配置文件">3.3)、修改配置文件</h4>
<p><code>$ sudo vim /usr/local/programs/kafka/config/server.properties</code></p>
<p>完整配置文件如下：</p>
<pre tabindex="0"><code>
# see kafka.server.KafkaConfig for additional details and defaults

############################### Server Basics #########################################

broker.id=1                                              # 每个broker在集群中的唯一标识，要求为正数

port=9092                                               # kafka监听端口，不配置默认为9092

host.name=kz1                                         # broker的主机地址或主机名(重要)

############################### Socket Server Settings #################################

num.network.threads=4                                   # 接收消息的线程数量，接收线程会将接收到的消息放在内存中，然后再从内存中写入磁盘(建议调整为CPU的核心数，根据实际情况调整)

num.io.threads=8                                     # 消息从内存中写入磁盘的时候使用的线程数量，用来处理磁盘IO的线程数量(建议调整为CPU核心数的2倍)

socket.send.buffer.bytes=102400               # 发送套接字的缓冲区大小

socket.receive.buffer.bytes=102400            # 接收套接字的缓冲区大小

socket.request.max.bytes=104857600        # 请求套接字的缓冲区大小

############################### Log Basics ###########################################

log.dirs=/usr/local/programs/kafka/logs    # Kafka运行日志存放的路径

num.partitions=1                                      # topic在当前broker上的分片个数

num.recovery.threads.per.data.dir=1          # 设置恢复和清理data下数据的线程数量(segment文件默认会被保留7天的时间，超时的话就会被清理，清理需要线程来执行)

############################## Log Retention Policy #####################################

log.retention.hours=168                                   # segment文件保留最长时间，默认保留7天(168小时)，超时将被清除

log.segment.bytes=1073741824                # 日志文件每个segment的大小，默认为1G

log.retention.check.interval.ms=300000     # 周期性检查segment文件大小的时间(单位是毫秒)

############################### Zookeeper ###########################################

zookeeper.connect=172.31.2.2:2181,172.31.2.3:2181

# zookeeper集群的地址，可以是多个，多个之间用逗号隔开

zookeeper.connection.timeout.ms=6000    # zookeeper的连接超时时间

############################### Group Coordinator Settings ###########################

group.initial.rebalance.delay.ms=0                    # 新版本添加的参数；这个参数的主要效果就是让coordinator推迟空消费组接收到成员加入请求后本应立即开启的rebalance，在实际使用时，假设你预估你的所有consumer组成员加入需要在10s内完成，那么你就可以设置该参数=10000
</code></pre><p>将配置文件同步到kz2服务器上：</p>
<p><code>$ scp server.properties ubuntu@172.31.2.3:/usr/local/programs/kafka/config</code></p>
<p>修改配置文件：</p>
<p><code>broker.id=2</code></p>
<p><code>host.name=kz2</code></p>
<h4 id="34启动kafka服务">3.4)、启动kafka服务</h4>
<p>前台方式启动：</p>
<p><code>$ sudo /usr/local/programs/kafka/bin/kafka-server-start.sh /usr/local/programs/kafka/config/server.properties</code></p>
<p>后台启动方式：</p>
<p><code>$ sudo /usr/local/programs/kafka/bin/kafka-server-start.sh --daemon /usr/local/programs/kafka/config/server.properties</code></p>
<h4 id="35kafka消息监控-kafkaoffsetmonitor">3.5)、Kafka消息监控-KafkaOffsetMonitor</h4>
<p>简介：</p>
<p>1)、这个应用程序用来实时监控Kafka服务的Consumer以及它们所在的Partition中的Offset，我们可以浏览当前的消费者组，并且每个Topic的所有Partition的消费情况都可以观看的一清二楚</p>
<p>2)、它让我们很直观的知道，每个Partition的Message是否消费掉，有没有阻塞等等</p>
<p>3)、这个Web管理平台保留的Partition、Offset和它的Consumer的相关历史数据，我们可以通过浏览Web管理的相关模块，清楚的知道最近一段时间的消费情况</p>
<p>下载地址：https://github.com/quantifind/KafkaOffsetMonitor/releases/tag/v0.2.1</p>
<pre tabindex="0"><code>$ cd /usr/local/programs/

$ sudo mkdir kafka_monitor

$ sudo vim monitor_start.sh
</code></pre><p><code>#! /bin/bash</code></p>
<p><code>java -cp KafkaOffsetMonitor-assembly-0.2.0.jar \ com.quantifind.kafka.offsetapp.OffsetGetterWeb \ --zk h1:2181 \ --port 8089 \ --refresh 10.seconds \ --retain 1.days </code></p>
<p>服务启动：<code>$ cd /usr/local/programs/kafka_monitor &amp;&amp; $ bash monitor_start.sh</code></p>
<h3 id="4logstash安装配置">4)、logstash安装配置</h3>
<h4 id="41解压安装包到指定目录">4.1)、解压安装包到指定目录</h4>
<p><code>$ sudo tar -zxvf logstash-5.5.2.tar.gz -C /usr/local/programs/logstash</code></p>
<h4 id="42jvm内存优化调整">4.2)、jvm内存优化调整</h4>
<p><code>$ sudo vim /usr/local/programs/logstash/config/jvm.optons -Xms8g</code></p>
<p>-Xmx8g # 建议设置为内存的一半(根据实际情况进行调整)</p>
<h4 id="43修改配置文件">4.3)、修改配置文件</h4>
<pre tabindex="0"><code>$ sudo vim /usr/local/programs/logstash/config/logstash.yml

path.data: /usr/local/programs/logstash/data

pipeline.workers: 8                      # CPU核心数

pipeline.output.workers: 4           # 这里相当于output elasticsearch里面的workers数量

pipeline.batch.size: 1000                     # 根据qps，压力情况等调整

pipeline.batch.delay: 5

path.config: /usr/local/programs/logstash/config/conf.d  # logstash的配置文件存放位置

path.logs: /usr/local/programs/logstash/logs           # logstash的日志文件
</code></pre><h4 id="44启动logstash">4.4)、启动logstash</h4>
<p>logstash前台启动方式：</p>
<p><code>$ sudo /usr/local/programs/logstash/bin/logstash -f /usr/local/programs/logstash/conf/oc-logstash-kafka.conf</code></p>
<p>logstash后台启动方式：</p>
<p><code>$ sudo nohup /usr/local/programs/logstash/bin/logstash -f /usr/local/programs/logstash/conf/oc-logstash-kafka.conf &amp;</code></p>
<h4 id="45logstash安装geoip插件">4.5)、Logstash安装geoip插件</h4>
<p><code>$ cd /usr/local/programs/logstash</code></p>
<p><code>$ sudo ./bin/logstash-plugin install logstash-filter-geoip</code></p>
<p>验证插件是否安装：<code>$ sudo ./bin/logstash-plugin list | grep geoip</code></p>
<p>Logstash安装x-pack插件(插件按照后面elasticsearch的x-pack插件破解方式进行破解)</p>
<pre tabindex="0"><code>$ cd /usr/local/programs/logstash

$ sudo ./bin/logstash-plugin install x-pack

$ sudo vim logstash.yml

xpack.monitoring.elasticsearch.username: logstash_system

xpack.monitoring.elasticsearch.password: logstashpassword
</code></pre><h3 id="5elasticsearch集群安装配置">5)、Elasticsearch集群安装配置</h3>
<h4 id="51解压软件包至指定目录">5.1)、解压软件包至指定目录</h4>
<p><code>$ sudo tar -zxvf elasticsearch-5.5.2.tar.gz -C /usr/local/programs/elasticsearch</code></p>
<h4 id="52jvm配置">5.2)、JVM配置</h4>
<p>由于elasticsearch是Java开发的，所以可以通过修改/usr/local/programs/elasticsearch/jvm.options配置文件来设定JVM的相关设定</p>
<p><code>$ sudo vim /usr/local/programs/elasticsearch/jvm.options -Xms4g</code></p>
<p>-Xmx4g  # 建议设置为内存的一半(根据实际情况调整)</p>
<p>调整elasticsearch GC方法(此参数调整特别注意，容易导致elasticsearch无法启动)</p>
<h2 id="gc-configuration">GC configuration</h2>
<pre tabindex="0"><code>-XX:+UseConcMarkSweepGC

-XX:CMSInitiatingOccupancyFraction=75

-XX:+UseCMSInitiatingOccupancyOnly
</code></pre><p>修改为：</p>
<pre tabindex="0"><code>-XX:+UseG1GC

-XX:MaxGCPauseMillis=200
</code></pre><h4 id="53修改配置文件">5.3)、修改配置文件</h4>
<p><code>$ sudo vim elasticsearch.yml</code></p>
<pre tabindex="0"><code>cluster.name: elasticsearch-application                            # elasticsearch集群名称

node.name: node-1                                                 # node节点名称

node.master: true                                                   # 表示节点是否具有成为主节点的资格

node.data: true                                                      # 表示节点是否存储数据

node.attr.rack: r1                                                    # 将自定义的属性添加到节点·

path.data: /usr/local/programs/elasticsearch/data    # ES数据存放位置

path.logs: /usr/local/programs/elasticsearch/logs     # ES 日志存放位置

bootstrap.memory_lock: true                                         # 锁定物理内存地址, 防止elasticsearch内存被交换出去

# 备注

# Make sure that the heap size is set to about half the memory available on the system and that the owner of the process is allowed to use this limit.

# 确保ES_HEAP_SIZE参数设置为系统可用内存的一半左右

# Elasticsearch performs poorly when the system is swapping the memory

# 当系统进行内存交换的时候, es的性能很差

network.host: 192.168.2.6                                        # 为es设置IP绑定

http.port: 9200                                                       # 为es设置自定义端口，默认是9200

discovery.zen.ping.unicast.hosts: [&#34;172.31.2.6:9300&#34;, &#34;172.31.2.7:9300&#34;]

# 当启动新节点时, 通过ip列表进行节点发现, 组件集群

discovery.zen.minimum_master_nodes: 3                  # 防止集群脑裂现象(集群总节点数量/2+1)

gateway.recover_after_nodes: 3                               # 一个集群中的N各节点启动后, 才允许进行数据恢复处理

# x-pack和es-head插件配置参数

http.cors.enabled: true

http.cors.allow-origin: &#34;*&#34;

xpack.security.enabled: true (es登录通过x-pack插件验证)

xpack.security.transport.ssl.enabled: true

http.cors.allow-headers: Authorization,X-Requested-With,Content-Length,Content-Type

action.auto_create_index: .security,.monitoring*,.watches,.triggered_watches,.watcher-history*,.ml*,.security,.security-6

将elasticsearch的配置文件同步到另外一台服务器(172.31.2.7)

修改配置文件：

node.name: node-2                                                 # node节点名称

network.host: 192.168.2.7                                        # es设置IP绑定
</code></pre><h4 id="54启动elasticsearch服务">5.4)、启动elasticsearch服务</h4>
<p>Elasticsearch默认前台启动：</p>
<p><code>$ sudo /usr/local/programs/elasticsearch/bin/elasticsearch</code></p>
<h4 id="55elasticsearch-head插件安装">5.5)、elasticsearch head插件安装</h4>
<p>5.5.1)、下载elasticsearch-head插件</p>
<p><code>$ cd /usr/local/programs &amp;&amp; sudo git clone https://github.com/mobz/elasticsearch-head.git</code></p>
<p>5.5.2)、elasticsearch-head配置文件修改</p>
<pre tabindex="0"><code>$ cd elasticsearch-head

$ sudo vim Gruntfile.js

connect: {

        server: {

              options: {

                     port: 9100,

                     hostname: &#39;*&#39;,

                     base: &#39;.&#39;,

                     keepalive: true

              }

       }

}
</code></pre><p><code>$ sudo vim _site/app.js</code></p>
<p>修改如下地方：</p>
<p>this.base_uri = this.config.base_uri || this.prefs.get(&ldquo;app-base_uri&rdquo;) || &ldquo;http://192.168.2.6:9200&rdquo;;</p>
<p>Enable CORS in elasticsearch</p>
<p>1)、add http.cors.enabled: true</p>
<p>2)、you must also set http.cors.allow-origin because no origin allowed by default. http.cors.allow-origin: &ldquo;*&rdquo; is valid value, however it&rsquo;s considered as a security risk as your cluster is open to cross origin from anywhere</p>
<pre tabindex="0"><code>$ sudo apt-get update &amp;&amp; $ sudo apt-get install nodejs

$ sudo apt-get install npm

$ sudo ln -s /usr/bin/nodejs /usr/bin/node
</code></pre><p>5.5.3)、elasticsearch-head插件服务启动方式</p>
<pre tabindex="0"><code>$ cd /usr/local/programs/elasticsearch/elasticsearch-head

$ npm install

$ npm run start
</code></pre><p>此时elasticsearch head插件安装完成</p>
<h4 id="56elasticsearch-x-pack插件安装">5.6)、elasticsearch x-pack插件安装</h4>
<p><code>$ cd /usr/local/programs/elasticsearch</code></p>
<p><code>$ sudo bin/elasticsearch-plugin install x-pack</code></p>
<p>安装完成后，再次登录 <a href="http://xxx.xxx.xxx.xxx:9200">http://xxx.xxx.xxx.xxx:9200</a>时，提示需要输入密码</p>
<p>默认账户密码：elastic，changeme</p>
<h4 id="57elasticsearch-x-pack插件破解">5.7)、elasticsearch x-pack插件破解</h4>
<p>反编译class文件：</p>
<p>在elasticsearch安装目录plugins/x-pack/找到x-pack-5.5.2.jar文件</p>
<p>新建测试目录test</p>
<p><code>$ cd /usr/local/programs/elasticsearch/plugins/x-pack/ &amp;&amp; sudo mkdir test</code></p>
<p>剪切x-pack-5.5.2.jar文件到测试目录test文件夹里面</p>
<p><code>$ sudo mv /usr/local/programs/elasticsearch/plugins/x-pack/x-pack-5.5.2.jar test/</code></p>
<p>切换到test目录，解压jar包</p>
<pre tabindex="0"><code>$ cd /usr/local/programs/elasticsearch/plugins/x-pack/test &amp;&amp; jar –xvf x-pack-5.5.2.jar

$ sudo rm -rf /usr/local/programs/elasticsearch/plugins/x-pack/test/x-pack-5.5.2.jar
</code></pre><p>找到文件org.elasticsearch/license/LicenseVerifier.class，并用Luyten反编译，</p>
<p>新建文件LicenseVerifier.java，内容如下：</p>
<pre tabindex="0"><code>package org.elasticsearch.license;

import java.nio.*;

import java.util.*;

import java.security.*;

import org.elasticsearch.common.xcontent.*;

import org.apache.lucene.util.*;

import org.elasticsearch.common.io.*;

import java.io.*;

public class LicenseVerifier

{

    public static boolean verifyLicense(final License license, final byte[] encryptedPublicKeyData) {

        return true;

    }

    public static boolean verifyLicense(final License license) {

        return true;

    }

}
</code></pre><p>在当前系统上的任意目录上重新编译LicenseVerifier.java文件</p>
<p><code>$ javac -cp &quot;/usr/local/programs/elasticsearch/lib/elasticsearch-5.2.2.jar:/usr/local/programs/elasticsearch/lib/lucene-core-6.0.1.jar:/usr/local/programs/elasticsearch/plugins/x-pack/x-pack-5.5.2.jar&quot; LicenseVerifier.java</code></p>
<p>此时会生成一个LicenseVerifier.class的文件</p>
<p>替换原来的class文件</p>
<p><code>$ sudo cp LicenseVerifier.class /usr/local/programs/elasticsearch/plugins/x-pack/test/org/elasticsearch/license/</code></p>
<p>重新打包jar包</p>
<p><code>$ cd /usr/local/programs/elasticsearch/plugins/x-pack/test &amp;&amp; jar -cvf x-pack-5.5.2.jar ./*</code></p>
<p>覆盖原来的x-pack的jar包</p>
<p><code>$ sudo mv /usr/local/programs/elasticsearch/plugins/x-pack/test/x-pack-5.5.2.jar /usr/local/programs/elasticsearch/plugins/x-pack</code></p>
<p>获取license文件</p>
<p>获取地址：https://license.elastic.co/registration</p>
<p>将下载下来的license文件重命名为license.json</p>
<p>修改文件内容的两处：</p>
<pre tabindex="0"><code>&#34;type&#34;: &#34;platinum&#34;,

&#34;expiry_date_in_millis&#34;: 2524579200999,
</code></pre><p>在更新license文件之前,需要修改elasticsearch配置文件elasticsearch.yml</p>
<p><code>xpack.security.enabled: false</code></p>
<p>导入修改好的license文件</p>
<p><code>$ curl -XPUT -u elastic 'http://192.168.2.6:9200/_xpack/license?acknowledge=true' -H &quot;Content-Type: application/json&quot; -d @license.json</code></p>
<p>生效之后，再开启security，并开启SSL\TLS：</p>
<pre tabindex="0"><code>xpack.security.enabled: true

xpack.security.transport.ssl.enabled: true
</code></pre><p>最后重启elasticsearch：</p>
<p>查看License状态：</p>
<p><code>$ curl -XGET -u elastic http://192.168.2.6:9200/_license</code></p>
<h3 id="6kibana安装配置">6)、Kibana安装配置</h3>
<h4 id="61解压软件包至指定目录">6.1)、解压软件包至指定目录</h4>
<p><code>$ sudo tar -zxvf kibana-5.5.2-linux-x86_64.tar.gz -C /usr/local/programs/kibana</code></p>
<h4 id="62修改配置文件">6.2)、修改配置文件</h4>
<pre tabindex="0"><code>server.port: 5601

server.host: &#34;0.0.0.0&#34;

server.name: &#34;elk-es1&#34;

elasticsearch.url: http://172.31.2.6:9200

kibana.index: &#34;.kibana&#34;

elasticsearch.username: &#34;kibana&#34;

elasticsearch.password: &#34;changeme&#34;
</code></pre><h4 id="63kibana-x-pack插件安装">6.3)、kibana x-pack插件安装</h4>
<pre tabindex="0"><code>$ cd /usr/local/programs/kibana

$ bin/kibana-plugin install x-pack

# Update Kibana to use the new password for the built-in kibana user, which you set up along with the other built-in users when you installed X-Pack on Elasticsearch. You must configure the elasticsearch.password setting in the kibana.yml configuration file with the new password for the kibana user

elasticsearch.username: &#34;kibana&#34;

elasticsearch.password: &#34;changeme&#34;

备注： kibana安装选择在从节点的进行安装就可以了，主节点上无需安装！

####################################################################################

### 7)、Elasticsearch+logstash+kibana5.5密码重置

https://www.elastic.co/guide/en/x-pack/5.5/setting-up-authentication.html

elastic：A built-in superuser. See Built-in Roles.

kibana：The user Kibana uses to connect and communicate with Elasticsearch.

logstash_system：The user Logstash uses when storing monitoring information in Elasticsearch.

You must reset the default passwords for all built-in users, and then disable default password support. You can update passwords from the Management &gt; Users UI in Kibana or with the Reset Password API：

PUT _xpack/security/user/elastic/_password

{

  &#34;password&#34;: &#34;elasticpassword&#34;

}

PUT _xpack/security/user/kibana/_password

{

  &#34;password&#34;: &#34;kibanapassword&#34;

}

PUT _xpack/security/user/logstash_system/_password

{

  &#34;password&#34;: &#34;logstashpassword&#34;

}
</code></pre><p>备注： 当密码被更改后，请将kibana配置文件中连接elasticsearch的密码也进行更换</p>
<h3 id="服务安装目录以及配置文件位置说明">服务安装目录以及配置文件位置说明</h3>
<p>kafka安装目录： /usr/local/programs/kafka</p>
<p>kafka配置文件： /usr/local/programs/kafka/config/server.properties</p>
<p>kafka jvm配置文件： /usr/local/programs/kafka/bin/kafka-server-start.sh</p>
<p>kafka monitor安装目录： /usr/local/programs/kafka_monitor</p>
<p>zookeeper安装目录： /usr/local/programs/zookeeper</p>
<p>zookeeper配置文件： /usr/local/programs/zookeeper/conf/zoo.cfg</p>
<p>logstash安装目录： /usr/local/programs/logstash</p>
<p>logstash配置文件： /usr/local/programs/logstash/config/logstash.yml</p>
<p>logstash生产配置文件目录文件存放位置： /usr/local/programs/logstash/config/conf.d   #里面文件为.yml结尾</p>
<p>logstash jvm配置文件： /usr/local/programs/logstash/config/jvm.options</p>
<p>elasticsearch安装目录： /usr/local/programs/elasticsearch</p>
<p>elasticsearch配置文件：/usr/local/programs/elasticsearch/config/elasticsearch.yml</p>
<p>elasticsearch jvm配置文件： /usr/local/programs/elasticsearch/config/jvm.options</p>
<p>kibana安装目录： /usr/local/programs/kibana</p>
<p>kibana 配置文件： /usr/local/programs/kibana/config/kibana.yml</p>
<p>备注：</p>
<p>所有elk服务启动都采用supervisor进程管理的方式维护</p>
<p>ELK中相关服务端口说明</p>
<p>9092： kafka监听的端口</p>
<p>2181： zookeeper提供给client连接的端口</p>
<p>2888： zookeeper集群内部通讯使用端口(Leader监听此端口)，意思是此端口不在集群哪台服务器上监听，就是Leader</p>
<p>3888： zookeeper选举Leader使用的端口</p>
<p>5044： logstash监听端口</p>
<p>5601：kibana监听访问端口</p>
<p>9200：elasticsearch监听访问端口</p>
<p>9300：elasticsearch集群内部通讯端口</p>
<h3 id="elk集群架构常用维护命令">ELK集群架构常用维护命令</h3>
<h4 id="1kafka常用操作命令">1)、Kafka常用操作命令</h4>
<p>1、创建kafka topic：</p>
<p><code>$ sudo bin/kafka-topics.sh --zookeeper zoo1.example.com:2181/kafka-cluster --create --topic my-topic --replication-factor 2 --partitions 8</code></p>
<p>备注：partitions指定topic分区数，replication-factor指定topic每个分区的副本数</p>
<p>partitions分区数：控制topic将分片成多少个log；可以显示指定，如果不指定则会使用broker(server.properties)中的num.partitions配置的数量</p>
<p>replication-factor副本：replication-factor控制消息保存在几个broker(服务器)上，一般情况下等于broker的个数</p>
<p>如果没有在创建时显示指定或通过API向一个不存在的topic生产消息时会使用broker(server.properties)中的default.replication.factor配置的数量</p>
<p>For example, increase the number of partitions for a topic named &ldquo;my-topic&rdquo; to 16：</p>
<p><code>$ sudo bin/kafka-topics.sh --zookeeper 172.31.2.2:2181,172.31.2.3:2181 --alter --topic my-topic --partitions 16</code></p>
<p>2、Deleting a Topic：</p>
<p>For example, delete the topic named &ldquo;my-topic&rdquo;：</p>
<p><code>$ sudo bin/kafka-topics.sh --zookeeper 172.31.2.2:2181,172.31.2.3:2181 --delete --topic my-topic</code></p>
<p>3、Listing All Topics in a Cluster</p>
<p><code>$ sudo bin/kafka-topics.sh --zookeeper 172.31.2.2:2181,172.31.2.3:2181 --list</code></p>
<p>4、Describing Topic Details</p>
<p><code>$ sudo bin/kafka-topics.sh --zookeeper 172.31.2.2:2181,172.31.2.3:2181 --describe --topic my-topic</code></p>
<p>5、分区监控指标(查找有问题的分区)</p>
<p>There are two filters used to find partitions that have problems. The &ndash;under-replicated-partitions argument</p>
<p>will show all partitions where one or more of the replicas for the partition are not in-sync with the leader. The &ndash;unavailable-partitions argument shows all partitions without a leader. This is a more serious situation</p>
<p>that means that the partition is currently offline and unavailable for produce or consume clients.</p>
<p><code>$ sudo bin/kafka-topics.sh --zookeeper 172.31.2.2:2181,172.31.2.3:2181 –describe –under-replicated-partitions</code></p>
<p>6、查看topic消费进度</p>
<p>这个会显示出consumer group的offset情况，必须参数为&ndash;group，不指定&ndash;topic，默认为所有topic</p>
<p>Displays the: Consumer Group，Topic，Partitions，Offset，logSize，Lag，Owner for the specified set of Topics and Consumer Group</p>
<p><code>$ sudo bin/kafka-run-class.sh kafka.tools.ConsumerOffsetChecker --group pv</code></p>
<p>7、Describing Configuration Overrides</p>
<p>For example, show all configuration overrides for the topic named &ldquo;my-topic&rdquo;：</p>
<p><code>$ kafka-configs.sh --zookeeper 172.31.2.2:2181,172.31.2.3:2181 --describe --entity-type topics --entity-name my-topic</code></p>
<p>8、Removing Configuration Overrides</p>
<p><code>$ kafka-configs.sh --zookeeper 172.31.2.2:2181,172.31.2.3:2181 --alter --entity-type topics --entity-name my-topic --delete-config retention.ms</code></p>
<h4 id="2zookeeper常用操作命令">2)、Zookeeper常用操作命令</h4>
<p>Zookeeper支持某些特定的四字命令字母与其的交互；它们大多是查询的命令，用来获取Zookeeper服务的当前状态及相关信息；用户在客户端可以通过telnet或nc向Zookeeper提交相应的命令</p>
<pre tabindex="0"><code>echo stat | nc localhost 2181              # 查看哪个节点被选择作为follower或者leader

echo ruok | nc localhost 2181      # 测试是否启动了该server，若回复imok表示已经启动

echo dump | nc localhost 2181    # 列出未经处理的会话和临时节点

echo kill | nc localhost 2181         # 关掉server

echo conf | nc localhost 2181              # 输出相关服务配置的详细信息

echo cons | nc localhost 2181      # 列出所有连接到服务器的客户端的完全的连接/会话的详细信息

echo envi | nc localhost 2181              # 输出关于服务环境的详细信息(区别于conf命令)

echo reqs | nc localhost 2181             # 列出未经处理的请求

echo wchs | nc localhost 2181      # 列出服务器watch的详细信息

echo wchc | nc localhost 2181      # 通过session列出服务器watch的详细信息，输出与watch相关的会话的列表

echo wchp | nc localhost 2181     # 通过路径列出服务器watch的详细信息；它输出一个与session相关的路径上
</code></pre><p>ZooKeeper命令行工具类似于Linux的shell环境，不过功能肯定不及shell，但是使用它我们可以简单的对ZooKeeper进行访问，数据创建，数据修改等操作</p>
<p>当启动ZooKeeper服务成功之后，输入下述命令，连接到ZooKeeper服务：</p>
<p><code>zkCli.sh -server zkserver: 2181</code></p>
<p>命令行工具的一些简单操作如下：</p>
<p>使用ls命令来查看当前ZooKeeper中所包含的内容</p>
<p>[zk: zkserverIP:2181(CONNECTED) 1] ls /</p>
<p>创建一个新的znode，使用create /zk myData；这个命令创建了一个新的znode节点“zk”以及与它关联的字符串</p>
<p><code>[zk: zkserverIP:2181(CONNECTED) 2] create /zk &quot;myData&quot;</code></p>
<p>我们运行get 命令来确认znode 是否包含我们所创建的字符串：</p>
<p><code>[zk: zkserverIP:2181(CONNECTED) 3] get /zk</code></p>
<p>下面我们通过set 命令来对zk 所关联的字符串进行设置：</p>
<p><code>[zk: zkserverIP:2181(CONNECTED) 4] set /zk &quot;zsl&quot;</code></p>
<p>下面我们将刚才创建的znode 删除：</p>
<p><code>[zk: zkserverIP:2181(CONNECTED) 5] delete /zk</code></p>
<h4 id="3elasticsearch常用操作命令">3)、Elasticsearch常用操作命令</h4>
<p>1、查看索引文件</p>
<p><code>$ curl -XGET &quot;http://elastic:changeme@172.31.2.6:9200/_cat/indices?v&quot;</code></p>
<p>2、打开或关闭指定的索引文件</p>
<p><code>$ curl -XPOST 'http://elastic:changeme@172.31.2.6:9200/.monitoring-es-6-2018.05.21/_open'</code></p>
<p><code>$ curl -XPOST 'http://elastic:changeme@172.31.2.6:9200/.monitoring-es-6-2018.05.21/_close'</code></p>
<p>3、检索索引文件是否存在</p>
<p><code>$ curl --head http://elastic:changeme@172.31.2.6:9200/logstash-oc-nginx-access-2018.06.01</code></p>
<p>4、删除指定的索引</p>
<p><code>$ curl -XDELETE http://elastic:changeme@172.31.2.6:9200/.monitoring-es-6-2018.05.21</code></p>
<p>使用通配符批量删除索引文件：</p>
<p><code>$ curl -XDELETE 'http://elastic:changeme@172.31.2.6:9200/.monitoring-es-6-2018.05.*'</code></p>
<p>5、清空索引缓存</p>
<p><code>$ curl -XPOST 'http://elastic:changeme@172.31.2.6:9200/.monitoring-es-6-2018.05.21/_cache/clear'</code></p>
<p><code>$ curl -XPOST 'http://elastic:changeme@172.31.2.6:9200/.monitoring-es-6-2018.05.21, .monitoring-es-6-2018.05.22/_cache/clear'</code></p>
<p>6、刷新索引数据</p>
<p><code>$ curl -XPOST 'http://elastic:changeme@172.31.2.6:9200/.monitoring-es-6-2018.05.21/_refresh'</code></p>
<p>7、优化索引数据</p>
<p><code>$ curl -XPOST 'http://elastic:changeme@172.31.2.6:9200/.monitoring-es-6-2018.05.21/_optimize'</code></p>
<p>8、信息检索与结果过滤</p>
<p>在Elasticsearch中的RESTful接口方式中，完成信息检索功能的关键词是_search，通过POST的方式发送到</p>
<p>Elasticsearch，其后再跟“?q=查询词”等，其形式表现为：</p>
<p>http://ip address:port/index_name/type_name/_search?q=</p>
<p>可以以<code>curl -XGET 'http://localhost:9200/_search?q=hello+world'</code> 的方式完成简单的检索</p>
<p>输出结果带缩进：http://ip address:9200/index_file_name/type_name/_search?q=field_name:Hello &amp; pretty=true</p>
<p>上述方法是可以在指定的索引文件index_file_name、指定的类型文件type_name中，在指定的字段field_name中，查找包含Hello字符串的结果集</p>
<p>(1)、查询指定索引和指定类型下的信息(指定一个index和一个type名)</p>
<p><code>$ curl -XGET 'elastic:changeme@172.31.2.6:9200/page/pages/_search?q=field_name: Hello&amp;pretty=true'</code></p>
<p>(2)、查询指定索引下所有类型中的信息(指定一个index名,没指定type)</p>
<p><code>$ curl -XGET 'elastic:changeme@172.31.2.6:9200/page/_search?q=field_name:Hello&amp;pretty=true'</code></p>
<p>(3)、查询所有索引中的信息(没指定index和type名)</p>
<p><code>$ curl -XGET 'elastic:changeme@172.31.2.6:9200/_search?q=field_name:Hello&amp;pretty=true'</code></p>
<p>(4)、查询多个索引下所有类型中的信息(指定多个index名,没指定type名)</p>
<p><code>$ curl -XGET 'elastic:changeme@172.31.2.6:9200/page, whale/_search?q=field_name:Hello&amp;pretty=true'</code></p>
<p>(5)、查询多个索引下多个类型中的信息(指定多个index名和多个type名)</p>
<p><code>$ curl -XGET 'elastic:changeme@172.31.2.6:9200/page, whale/pages, log/_search?q=field_name:Hello&amp;pretty=true'</code></p>
<p>在索引过程中,可以控制结果的规模以及从哪个结果开始返回，在请求中可以设置相应的属性，其中：</p>
<p>from：该属性指定了从那个结果开始返回</p>
<p>size：该属性指定了查询的结果集中包含的最大文档数</p>
<p>基本查询：基本查询涉及term查询、terms查询、match查询、match_all查询、query_string查询、prefix查询、range查询、more_like_this查询等</p>
<p>9、elasticsearch集群查看：</p>
<p><code>$ curl -XGET -u elastic &quot;http://172.31.2.6:9200/_cat/nodes?pretty&quot;</code></p>
<p>访问地址</p>
<p>Kibana：http://x.x.x.x:5601</p>
<p>Elasticsearch： <a href="http://x.x.x.x:9200">http://x.x.x.x:9200</a></p>
<p>Elasticsearch-head：http://x.x.x.x:9100/?auth_user=elastic&amp;auth_password=changeme</p>
]]></content>
		</item>
		
		<item>
			<title>数据仓库Amazon Redshift</title>
			<link>http://www.heyuan110.com/posts/datawarehouse/2018-08-09-dw-redshift/</link>
			<pubDate>Thu, 09 Aug 2018 14:06:44 +0000</pubDate>
			
			<guid>http://www.heyuan110.com/posts/datawarehouse/2018-08-09-dw-redshift/</guid>
			<description>前言 Amazon Redshift 是一个快速、可扩展的数据仓库，可以简单、经济高效地分析数据仓库和数据湖中的所有数据。Redshift 通过在高性能磁盘上使用 Machine Learning、大规模并行查询执行和列式存储可提供比其他数据仓库快十倍的性能。
1.对系统表优化：vacuum • VACUUM操作分两个阶段执行：（1）对未排序区域中的行进行排序；（2）如有必要（95%），会将表结尾处的新排序的行与现有行合并。因此，如果您按排序键顺序加载数据，则 VACUUM操作的速度会很快。 VACUUM类型 • VACUUM DELETE ONLY：仅删除 vacuum。回收磁盘空间，但对新行不排序。 • VACUUM SORT ONLY：仅排序 vacuum。对新行排序，但不回收磁盘空间。 • VACUUM FULL：完全 vacuum。默认的vacuum。相当于VACUUM DELETE ONLY+ VACUUM SORT ONLY，但比两者串行运行更加高效。 • VACUUM REINDEX：完全 vacuum 重建索引。对交错排序键的表有意义，它重新分析表的排序键列中的值分配，然后执行完全 VACUUM 操作。VACUUM REINDEX 花费的时间比 VACUUM FULL 长得多。
估算vacuum大概多长时间运行完毕： select * from SVV_VACUUM_PROGRESS;
vacuum结束后查看效果： select table_name, (elapsed_time/1000000) as elapsed_time_s, sort_partitions, row_delta, sortedrow_delta, block_delta from SVV_VACUUM_SUMMARY order by xid;
查看vacuum结束后磁盘的回收率： select * from SVL_VACUUM_PERCENTAGE order by xid;</description>
			<content type="html"><![CDATA[<h2 id="前言">前言</h2>
<p>Amazon Redshift 是一个快速、可扩展的数据仓库，可以简单、经济高效地分析数据仓库和数据湖中的所有数据。Redshift 通过在高性能磁盘上使用 Machine Learning、大规模并行查询执行和列式存储可提供比其他数据仓库快十倍的性能。</p>
<h2 id="1对系统表优化vacuum">1.对系统表优化：vacuum</h2>
<p>• VACUUM操作分两个阶段执行：（1）对未排序区域中的行进行排序；（2）如有必要（95%），会将表结尾处的新排序的行与现有行合并。因此，如果您按排序键顺序加载数据，则 VACUUM操作的速度会很快。
VACUUM类型
• VACUUM DELETE ONLY：仅删除 vacuum。回收磁盘空间，但对新行不排序。
• VACUUM SORT ONLY：仅排序 vacuum。对新行排序，但不回收磁盘空间。
• VACUUM FULL：完全 vacuum。默认的vacuum。相当于VACUUM DELETE ONLY+ VACUUM SORT ONLY，但比两者串行运行更加高效。
• VACUUM REINDEX：完全 vacuum 重建索引。对交错排序键的表有意义，它重新分析表的排序键列中的值分配，然后执行完全 VACUUM 操作。VACUUM REINDEX 花费的时间比 VACUUM FULL 长得多。</p>
<p>估算vacuum大概多长时间运行完毕：
<code>select * from SVV_VACUUM_PROGRESS;</code></p>
<p>vacuum结束后查看效果：
<code>select table_name, (elapsed_time/1000000) as elapsed_time_s, sort_partitions, row_delta, sortedrow_delta, block_delta from SVV_VACUUM_SUMMARY order by xid;</code></p>
<p>查看vacuum结束后磁盘的回收率：
<code>select * from SVL_VACUUM_PERCENTAGE order by xid;</code></p>
<p>分析表格的那条语句，排列一下属性后，下面的语句会看得更加清晰<a href="https://docs.aws.amazon.com/zh_cn/redshift/latest/dg/r_SVV_TABLE_INFO.html">https://docs.aws.amazon.com/zh_cn/redshift/latest/dg/r_SVV_TABLE_INFO.html</a>：
<code>select &quot;table&quot;, size as size_MB, pct_used, tbl_rows, encoded, diststyle, sortkey_num, sortkey1, sortkey1_enc, unsorted, skew_sortkey1, skew_rows, max_varchar, stats_off from SVV_TABLE_INFO order by size_MB DESC;</code></p>
<ul>
<li>.Amazon Redshift不会自动回收和重用在您删除行和更新行时释放的空间。</li>
<li>当您使用 COPY、INSERT 或 UPDATE 语句更新表时，新行将存储在磁盘上的单独的未排序区域中，然后根据查询的需求进行排序。如果大量行在磁盘上保持未排序状态，依赖已排序数据的操作（例如，范围受限的扫描或合并联接）的查询性能可能会下降。因此，有必要运行VACUUM命令。VACUUM命令做的工作包括：（1）回收空间：将从已删除行中恢复空间。（2）还原排序顺序，提高查询性能。因此，对于带排序键的表，VACUUM 命令可确保表中的新数据在磁盘上完全排序。</li>
</ul>
<p>另外，ANALYZE命令会更新统计元数据，这使查询优化程序能够生成更准确的查询计划。因此当添加、删除或修改大量行时，您应运行 VACUUM 命令，然后运行 ANALYZE 命令。</p>
<h2 id="2统计系统相关数据">2.统计系统相关数据</h2>
<p><code>select * from SVV_TABLE_INFO;</code>
<a href="https://docs.aws.amazon.com/zh_cn/redshift/latest/dg/r_SVV_TABLE_INFO.html">https://docs.aws.amazon.com/zh_cn/redshift/latest/dg/r_SVV_TABLE_INFO.html</a></p>
<h2 id="3查看压缩表合适的格式">3.查看压缩表合适的格式</h2>
<p><code>analyze compression tablename;</code>
<a href="https://docs.aws.amazon.com/zh_cn/redshift/latest/dg/r_ANALYZE_COMPRESSION.html">https://docs.aws.amazon.com/zh_cn/redshift/latest/dg/r_ANALYZE_COMPRESSION.html</a></p>
<h2 id="4查看错误原因">4.查看错误原因</h2>
<p><code>select * from STL_LOAD_ERRORS ORDER BY starttime DESC;</code></p>
]]></content>
		</item>
		
		<item>
			<title>Nginx实现部分页面https</title>
			<link>http://www.heyuan110.com/posts/linux/nginx/2016-04-22-nginx-https/</link>
			<pubDate>Fri, 22 Apr 2016 20:33:37 +0000</pubDate>
			
			<guid>http://www.heyuan110.com/posts/linux/nginx/2016-04-22-nginx-https/</guid>
			<description>由于业务需要，在checkout页面需要实现https加密访问，之前只做过nginx的全站https，对于部分页面https搜索方法有说在代码里直接写成https，有说服务器上直接配置的，做了对比觉得还是nginx上直接配置靠谱，开始动手.
需求: 全站除了checkout页面https，其他都采取http访问, 如果不符合这个规则的，按照规则强制跳转.
思路: http访问时，在nginx里判断路径包含/checkout，就强制将http转到https；https访问时，判断非checkout，就强制调到http。思路是没有问题，问题是我想用nginx的location实现，研究了半天没找到很好的方案实现[非checkout]. 不过最后还是实现了~_~,用到了nginx的proxy_pass，下面讲具体实现，最后会放出完整的配置,也许还有问题，欢迎提出.
直接把nginx配置放上来, server_name自行做修改，用了反向代理proxy_pass到负载均衡服务器.
server { server_name heyuan110.com; rewrite ^/(.*) http://www.heyuan110.com/$1 permanent; } server { listen 80; server_name www.heyuan110.com; gzip on; gzip_min_length 1k; gzip_buffers 16 64k; gzip_http_version 1.1; gzip_comp_level 4; gzip_types text/plain application/javascript application/x-javascript text/css application/xml; gzip_vary on; access_log /var/log/nginx/access.log; error_log /var/log/nginx/error.log; location ~* /news/show/* { return 301 https://$host$request_uri; } location / { proxy_pass http://web; proxy_connect_timeout 600; proxy_read_timeout 600; proxy_send_timeout 600; proxy_buffer_size 64k; proxy_buffers 4 32k; proxy_busy_buffers_size 64k; proxy_temp_file_write_size 64k; proxy_set_header Host $host; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; proxy_redirect off; } location = /robots.</description>
			<content type="html"><![CDATA[<p>由于业务需要，在checkout页面需要实现https加密访问，之前只做过nginx的全站https，对于部分页面https搜索方法有说在代码里直接写成https，有说服务器上直接配置的，做了对比觉得还是nginx上直接配置靠谱，开始动手.</p>
<p>需求: 全站除了checkout页面https，其他都采取http访问, 如果不符合这个规则的，按照规则强制跳转.</p>
<p>思路: http访问时，在nginx里判断路径包含/checkout，就强制将http转到https；https访问时，判断非checkout，就强制调到http。思路是没有问题，问题是我想用nginx的location实现，研究了半天没找到很好的方案实现[非checkout]. 不过最后还是实现了~_~,用到了nginx的proxy_pass，下面讲具体实现，最后会放出完整的配置,也许还有问题，欢迎提出.</p>
<p>直接把nginx配置放上来, server_name自行做修改，用了反向代理proxy_pass到负载均衡服务器.</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-nginx" data-lang="nginx"><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="k">server</span> <span class="p">{</span>
</span></span><span class="line"><span class="cl">    <span class="kn">server_name</span> <span class="s">heyuan110.com</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">    <span class="kn">rewrite</span> <span class="s">^/(.*)</span> <span class="s">http://www.heyuan110.com/</span><span class="nv">$1</span> <span class="s">permanent</span><span class="p">;</span>
</span></span><span class="line"><span class="cl"><span class="p">}</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="k">server</span> <span class="p">{</span>
</span></span><span class="line"><span class="cl">    <span class="kn">listen</span>       <span class="mi">80</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">    <span class="kn">server_name</span>  <span class="s">www.heyuan110.com</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="kn">gzip</span> <span class="no">on</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">    <span class="kn">gzip_min_length</span> <span class="mi">1k</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">    <span class="kn">gzip_buffers</span> <span class="mi">16</span> <span class="mi">64k</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">    <span class="kn">gzip_http_version</span> <span class="mi">1</span><span class="s">.1</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">    <span class="kn">gzip_comp_level</span> <span class="mi">4</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">    <span class="kn">gzip_types</span> <span class="s">text/plain</span> <span class="s">application/javascript</span> <span class="s">application/x-javascript</span> <span class="s">text/css</span> <span class="s">application/xml</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">    <span class="kn">gzip_vary</span> <span class="no">on</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="kn">access_log</span>  <span class="s">/var/log/nginx/access.log</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">    <span class="kn">error_log</span>   <span class="s">/var/log/nginx/error.log</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="kn">location</span> <span class="p">~</span><span class="sr">*</span> <span class="s">/news/show/*</span> <span class="p">{</span>
</span></span><span class="line"><span class="cl">        <span class="kn">return</span>  <span class="mi">301</span> <span class="s">https://</span><span class="nv">$host$request_uri</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">    <span class="p">}</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="kn">location</span> <span class="s">/</span> <span class="p">{</span>
</span></span><span class="line"><span class="cl">           <span class="kn">proxy_pass</span>        <span class="s">http://web</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">           <span class="kn">proxy_connect_timeout</span> <span class="mi">600</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">           <span class="kn">proxy_read_timeout</span> <span class="mi">600</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">           <span class="kn">proxy_send_timeout</span> <span class="mi">600</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">           <span class="kn">proxy_buffer_size</span> <span class="mi">64k</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">           <span class="kn">proxy_buffers</span>  <span class="mi">4</span> <span class="mi">32k</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">           <span class="kn">proxy_busy_buffers_size</span> <span class="mi">64k</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">           <span class="kn">proxy_temp_file_write_size</span> <span class="mi">64k</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">           <span class="kn">proxy_set_header</span>   <span class="s">Host</span>             <span class="nv">$host</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">           <span class="kn">proxy_set_header</span>   <span class="s">X-Real-IP</span>        <span class="nv">$remote_addr</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">           <span class="kn">proxy_set_header</span>   <span class="s">X-Forwarded-For</span>  <span class="nv">$proxy_add_x_forwarded_for</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">           <span class="kn">proxy_redirect</span>     <span class="no">off</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">    <span class="p">}</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="kn">location</span> <span class="p">=</span> <span class="s">/robots.txt</span> <span class="p">{</span>
</span></span><span class="line"><span class="cl">        <span class="kn">return</span> <span class="mi">200</span> <span class="s">&#34;User-agent:</span> <span class="s">*\nDisallow:&#34;</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">    <span class="p">}</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="kn">location</span> <span class="p">~</span> <span class="sr">^/nginx_status/</span> <span class="p">{</span>
</span></span><span class="line"><span class="cl">        <span class="kn">stub_status</span> <span class="no">on</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">        <span class="kn">access_log</span> <span class="no">off</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">    <span class="p">}</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1">#    location ~* \.(ttf|woff|ttf|svg|eot)$ {
</span></span></span><span class="line"><span class="cl"><span class="c1">#       add_header &#39;Access-Control-Allow-Origin&#39; &#39;*&#39;;
</span></span></span><span class="line"><span class="cl"><span class="c1">#       add_header &#39;Access-Control-Allow-Credentials&#39; &#39;true&#39;;
</span></span></span><span class="line"><span class="cl"><span class="c1">#       add_header &#39;Access-Control-Allow-Methods&#39; &#39;GET,POST,HEAD&#39;;
</span></span></span><span class="line"><span class="cl"><span class="c1">#    }
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>
</span></span><span class="line"><span class="cl"><span class="c1">#    location ~ \.(gif|jpg|jpeg|js|css|png|bmp|ico)$ {
</span></span></span><span class="line"><span class="cl"><span class="c1">#        expires 30d;
</span></span></span><span class="line"><span class="cl"><span class="c1">#    }
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>
</span></span><span class="line"><span class="cl"><span class="c1">#     location ~* \.(jpg|jpeg|gif|css|png|js|ico|html|woff)$ {
</span></span></span><span class="line"><span class="cl"><span class="c1">#       expires max;
</span></span></span><span class="line"><span class="cl"><span class="c1">#     }
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>
</span></span><span class="line"><span class="cl"><span class="p">}</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="k">server</span> <span class="p">{</span>
</span></span><span class="line"><span class="cl">    <span class="kn">listen</span>       <span class="mi">443</span> <span class="s">ssl</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">    <span class="kn">server_name</span>  <span class="s">www.heyuan110.com</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="kn">access_log</span>  <span class="s">/var/log/nginx/sslaccess.log</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">    <span class="kn">error_log</span>   <span class="s">/var/log/nginx/sslerror.log</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="kn">ssl</span> <span class="no">on</span><span class="p">;</span>
</span></span><span class="line"><span class="cl"><span class="kn">ssl_prefer_server_ciphers</span> <span class="s">On</span><span class="p">;</span>
</span></span><span class="line"><span class="cl"><span class="kn">ssl_protocols</span> <span class="s">TLSv1</span> <span class="s">TLSv1.1</span> <span class="s">TLSv1.2</span><span class="p">;</span>
</span></span><span class="line"><span class="cl"><span class="c1">#ssl_ciphers ECDH+AESGCM:DH+AESGCM:ECDH+AES256:DH+AES256:ECDH+AES128:DH+AES:ECDH+3DES:DH+3DES:RSA+AESGCM:RSA+AES:RSA+3DES:!aNULL:!MD5:!DSS;
</span></span></span><span class="line"><span class="cl"><span class="c1"></span><span class="kn">ssl_ciphers</span> <span class="s">ALL:!ADH:!EXP:!LOW:!RC2:!3DES:!SEED:!RC4:+HIGH:+MEDIUM</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">    <span class="kn">ssl_certificate</span> <span class="s">/usr/local/nginx/conf/ssl/website_ssl.crt</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">    <span class="kn">ssl_certificate_key</span> <span class="s">/usr/local/nginx/conf/ssl/website_ssl.key</span><span class="p">;</span>
</span></span><span class="line"><span class="cl"><span class="c1">#    ssl_ciphers ALL:!ADH:!EXPORT56:RC4+RSA:+HIGH:+MEDIUM:+LOW:+SSLv2:+EXP;
</span></span></span><span class="line"><span class="cl"><span class="c1">#    ssl_prefer_server_ciphers on;
</span></span></span><span class="line"><span class="cl"><span class="c1">#    keepalive_timeout   70;
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>
</span></span><span class="line"><span class="cl">    <span class="kn">location</span> <span class="p">~</span><span class="sr">*</span> <span class="s">/news/show/*</span> <span class="p">{</span>
</span></span><span class="line"><span class="cl">        <span class="kn">proxy_pass</span> <span class="s">http://web</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">        <span class="kn">proxy_read_timeout</span> <span class="mi">300</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">        <span class="kn">proxy_set_header</span> <span class="s">Host</span> <span class="nv">$host</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">        <span class="kn">proxy_set_header</span> <span class="s">X-Real-IP</span> <span class="nv">$remote_addr</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">        <span class="kn">proxy_set_header</span> <span class="s">X-Forwarded-For</span> <span class="nv">$proxy_add_x_forwarded_for</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">        <span class="kn">proxy_redirect</span>     <span class="no">off</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">        <span class="c1">### Most PHP, Python, Rails, Java App can use this header -&gt; https ###
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>        <span class="kn">proxy_set_header</span> <span class="s">X-Forwarded-Proto</span>  <span class="nv">$scheme</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">    <span class="p">}</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="kn">location</span> <span class="p">~</span> <span class="sr">\.(css|js|gif|jpg|woff|woff2|png|ico)$</span> <span class="p">{</span>
</span></span><span class="line"><span class="cl">        <span class="kn">proxy_pass</span>  <span class="s">http://web</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">    <span class="p">}</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="kn">location</span> <span class="s">/</span> <span class="p">{</span>
</span></span><span class="line"><span class="cl">      <span class="kn">return</span>  <span class="mi">301</span> <span class="s">http://</span><span class="nv">$server_name$request_uri</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">    <span class="p">}</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="p">}</span>
</span></span></code></pre></div>]]></content>
		</item>
		
		<item>
			<title>网络抓包工具Charles</title>
			<link>http://www.heyuan110.com/posts/macos/charles/</link>
			<pubDate>Sat, 15 Aug 2015 11:33:11 +0000</pubDate>
			
			<guid>http://www.heyuan110.com/posts/macos/charles/</guid>
			<description>&lt;p&gt;Charles是Mac下常用的网络抓包工具，常用来模拟数据和网络辅助接口调试，作为代理抓取网络请求数据，这篇文章记录了几个实用场景，希望对你有帮助。&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;http://pan.baidu.com/s/1mgszWRu&#34;&gt;Charles下载传送门&lt;/a&gt;。经常会有这样的场景:&lt;/p&gt;
&lt;p&gt;场景一: 想看看其他的App是怎样设计请求，怎样设计返回数据格式，某一个功能点请求分几个实现的。最近我在用某听书软件听鬼故事（^0^）,它们限制非VIP每天只能下100篇离线，我试着用charles拦截修改返回数据，把我自己变成超级VIP了，然后, 没然后了&amp;hellip;.&lt;/p&gt;
&lt;p&gt;场景二: 一个请求发起直接返回各种看起来奇葩的错误，检查半天代码好像也没问题，直接就大嘴巴叫后台的兄弟服务挂了，后台一看，好好的啊&amp;hellip;&lt;/p&gt;
&lt;p&gt;场景三: 开发新的功能，接口也先大概定义好了，可后台兄弟忙着和妹子聊天（&lt;em&gt;^&lt;/em&gt;），接口还没写好啊&amp;hellip;,虽然可以在代码里写死demo数据，但后台接口写好了，难道又去改一遍?有木有更好的方式呢？先把请求都写好，能正常返回数据，解析好结果绑定到界面，最后接口写好了直接就对接，charles可以帮助我们这么干。&lt;/p&gt;
&lt;p&gt;场景四: 除了WIFI我们还要测试2G,3G,4G等各种复杂网络条件下的情况，可手机上网资费不便宜啊，可以让charles限制网速模拟网络环境。&lt;/p&gt;
&lt;p&gt;就列举这么几个场景吧，下面进入本文的正题&lt;/p&gt;</description>
			<content type="html"><![CDATA[<p>Charles是Mac下常用的网络抓包工具，常用来模拟数据和网络辅助接口调试，作为代理抓取网络请求数据，这篇文章记录了几个实用场景，希望对你有帮助。</p>
<p><a href="http://pan.baidu.com/s/1mgszWRu">Charles下载传送门</a>。经常会有这样的场景:</p>
<p>场景一: 想看看其他的App是怎样设计请求，怎样设计返回数据格式，某一个功能点请求分几个实现的。最近我在用某听书软件听鬼故事（^0^）,它们限制非VIP每天只能下100篇离线，我试着用charles拦截修改返回数据，把我自己变成超级VIP了，然后, 没然后了&hellip;.</p>
<p>场景二: 一个请求发起直接返回各种看起来奇葩的错误，检查半天代码好像也没问题，直接就大嘴巴叫后台的兄弟服务挂了，后台一看，好好的啊&hellip;</p>
<p>场景三: 开发新的功能，接口也先大概定义好了，可后台兄弟忙着和妹子聊天（<em>^</em>），接口还没写好啊&hellip;,虽然可以在代码里写死demo数据，但后台接口写好了，难道又去改一遍?有木有更好的方式呢？先把请求都写好，能正常返回数据，解析好结果绑定到界面，最后接口写好了直接就对接，charles可以帮助我们这么干。</p>
<p>场景四: 除了WIFI我们还要测试2G,3G,4G等各种复杂网络条件下的情况，可手机上网资费不便宜啊，可以让charles限制网速模拟网络环境。</p>
<p>就列举这么几个场景吧，下面进入本文的正题</p>
<h2 id="一设置代理抓包">一.设置代理抓包</h2>
<p>打开charles软件,选择Proxy-&gt;Proxy Settings到如下界面:</p>
<p><img src="/images/charles/charles_proxysettings.png" alt="charles_proxysettings"></p>
<p>以iPhone手机为例，打开: 设置-&gt;无线局域网，选择一个网络进入，滚动到下面看到有&rsquo;HTTP代理&rsquo;模块，选择手动模式，按照如下图填好配置.</p>
<p><img src="/images/charles/iphone_proxy.png" alt="iphone_proxy"></p>
<p>服务器地址填写电脑的局域网ip，打开系统设置-&gt;网络，就能看到本机ip了
填写好了，随便打开一个app，在charles软件里应该会弹出一个提示框，是否同意通过本机代理上网，点是就好了。下面是我设置好代理后，打开手机上app，在charles软件里看到的。</p>
<p><img src="/images/charles/charles_maoyan.png" alt="charles_maoyan"></p>
<h2 id="二模拟慢网速请求">二.模拟慢网速请求</h2>
<p>App开发完后，我们要测试多环境，特别是在慢网速下的case，之前我有写过一篇关于<a href="http://www.heyuan110.com/2015/06/16/Mac%E6%B5%8B%E8%AF%95%E6%A8%A1%E6%8B%9F%E6%85%A2%E7%BD%91%E9%80%9F/">慢网速测试</a>，现在用charles也可以达到这目的。选择Proxy-&gt;Throtting Setting，打开后如下图设置</p>
<p><img src="/images/charles/charles_throttling.png" alt="charles_throttling"></p>
<p>如果要针对某一个地址限速，在Hosts里可以add要限速的url.</p>
<h2 id="三截获请求转到指定的地址">三.截获请求转到指定的地址</h2>
<p>比如api请求的是 <a href="http://api.test.com/user?user_id=1">http://api.test.com/user?user_id=1</a> , 但是后台这个没写好，我们就临时转到一个本地地址 http://10.1.1.111/user_info.json ，这个就一json文件编辑什么的特别方便，想怎么改都方便了，不过这个得在本地搭一个server环境，推荐用nginx或apache.</p>
<p>选择Tools-&gt;Map Local打开设计界面,设置好如下图:</p>
<p><img src="/images/charles/charles_mapremote.png" alt="charles_mapremote"></p>
<h2 id="四截获请求直接返回本地的文件内容">四.截获请求直接返回本地的文件内容</h2>
<p>如果懒得搭server环境，就可以用这种方式了，这个可以直接把一个请求返回内容映射到本地文件，例如把 <a href="http://api.test.com/user?user_id=1">http://api.test.com/user?user_id=1</a> 对应的请求返回内容映射到本地文件user_info.json，</p>
<p>选择Tools-&gt;Map Local打开设计界面,设置好如下图:</p>
<p><img src="/images/charles/charles_maplocal.png" alt="charles_maplocal"></p>
<h2 id="五截获请求修改请求信息">五.截获请求修改请求信息</h2>
<p>上面的方式是直接替换了整个，哪如果只想截获并做一定修改怎么处理呢?</p>
<p>选择Tools-&gt;Rewrite，设置如下图:</p>
<p><img src="/images/charles/charles_rewrite.png" alt="charles_rewrite"></p>
<h2 id="六设置请求的黑名单">六.设置请求的黑名单</h2>
<p>不想某些请求发起，直接返回404，可以用黑名单</p>
<p>选择Tools-&gt;Black List，设置如下图:</p>
<p><img src="/images/charles/charles_blacklist.png" alt="charles_blacklist"></p>
<h2 id="七dns欺骗">七.DNS欺骗</h2>
<p>dns欺骗，说简单点就是把域名解析到一个假的ip，
可以不必一定要用locahost,127.0.0.1,装个B把127.0.0.1对应到baidu.com来调试~
选择Tools-&gt;DNS Spoofing，设置如下图:
<img src="/images/charles/charles_dns.png" alt="charles_dns"></p>
<h2 id="八缓存请求返回的内容">八.缓存请求返回的内容</h2>
<p>这个我用来干过做缓存数据用，让app在没有server的时候也能跑，
选择Tools-&gt;Mirror，设置如下图:</p>
<p><img src="/images/charles/charles_mirror.png" alt="charles_mirror"></p>
<p>上面这些是我在开发过程中经常会用到的，基本能很好解决和后台联调的问题，我没有把每个地方都列的很细，基本都是只提到点，相信大家知道这个点去操作都很容易就上手，但我更想说的是，这些都只是工具，最好还是能了解web原理基础，理解HTTP协议。</p>
<p>另外介绍一个模拟请求的工具，Chrome下的插件postman，很方便就能模拟post,get,put,delete等请求，模拟文本，上传文件请求，附上一张截图:
<img src="/images/charles/post_man.png" alt="post_man"></p>
<p>有了这些工具的辅助，相信你对接口的调试再也不会叫苦啦&hellip;</p>
<p>总算写完了，又晕又困，睡觉去~</p>
<p>===</p>
<p>PS:补充breakpoints调试</p>
<h2 id="九-breakpoints">九. BreakPoints</h2>
<p>实用的断点调试，体验就像在xcode里断点调试一样，请求时会弹出断点调试的窗口。</p>
<ul>
<li>打断点</li>
</ul>
<p>首先打开设置窗口
<img src="/images/charles/charles_breakpoints1.png" alt="post_man">
点击add，添加想要断点调试的url如下图
<img src="/images/charles/charles_breakpoints2.png" alt="post_man">
打断点完成</p>
<ul>
<li>调试</li>
</ul>
<p>请求断点的url时会弹出断点调试窗口，如下图
<img src="/images/charles/charles_breakpoints3.png" alt="post_man"></p>
<p>这里可以看到编辑request和response，如下图（这里演示的url只打了response的断点）
<img src="/images/charles/charles_breakpoints4.png" alt="post_man"></p>
<p>编辑完成点execute，搞定!</p>]]></content>
		</item>
		
		<item>
			<title>ZSH配置和使用</title>
			<link>http://www.heyuan110.com/posts/linux/2015-06-17-shell-zsh/</link>
			<pubDate>Wed, 17 Jun 2015 17:03:18 +0000</pubDate>
			
			<guid>http://www.heyuan110.com/posts/linux/2015-06-17-shell-zsh/</guid>
			<description>&lt;p&gt;如果你使用Linux操作系统，那就免不了要和终端打交道，而shell是与系统交互的外壳，也是Linux的精髓，那么花一点时间使用配置一个强大的shell，绝对是物超所值的。通常系统默认安装的shell时bash，当然还有其他的shell。相对linux系统自带的bash，我更喜欢zsh(shell中的高富帅)，能安装各种插件，精美的主题，自定义各种快捷方式, zsh安装配置的方法也很简单，下面的方法我在ubuntu和mac上亲测有效。&lt;/p&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;p&gt;装完后看看你的vi吧，发两张截图&lt;/p&gt;
&lt;p&gt;&lt;!-- raw HTML omitted --&gt;&lt;!-- raw HTML omitted --&gt;&lt;!-- raw HTML omitted --&gt;&lt;/p&gt;</description>
			<content type="html"><![CDATA[<p>如果你使用Linux操作系统，那就免不了要和终端打交道，而shell是与系统交互的外壳，也是Linux的精髓，那么花一点时间使用配置一个强大的shell，绝对是物超所值的。通常系统默认安装的shell时bash，当然还有其他的shell。相对linux系统自带的bash，我更喜欢zsh(shell中的高富帅)，能安装各种插件，精美的主题，自定义各种快捷方式, zsh安装配置的方法也很简单，下面的方法我在ubuntu和mac上亲测有效。</p>
<!-- raw HTML omitted -->
<!-- raw HTML omitted -->
<p>装完后看看你的vi吧，发两张截图</p>
<p><!-- raw HTML omitted --><!-- raw HTML omitted --><!-- raw HTML omitted --></p>
<p><!-- raw HTML omitted --><!-- raw HTML omitted --><!-- raw HTML omitted --></p>
<h2 id="一先安装zsh">一、先安装zsh</h2>
<p><code>sudo apt-get install zsh</code></p>
<h2 id="二下载zsh配置文件">二、下载zsh配置文件</h2>
<p><code>git clone git://github.com/robbyrussell/oh-my-zsh.git ~/.oh-my-zsh</code></p>
<h2 id="三配置zsh">三、配置zsh</h2>
<p><code>cp ~/.oh-my-zsh/templates/zshrc.zsh-template ~/.zshrc</code></p>
<p><code>chsh -s /bin/zsh</code></p>
<h2 id="四把bash的配置文件加到zsh里">四、把bash的配置文件加到zsh里</h2>
<p>可以建一个zshrc配置文件:</p>
<p><code>vi ~/.zshrc.local</code></p>
<p>根据自己实际情况配置,vundle的安装向导：<a href="https://github.com/wxmcan/vundle">https://github.com/wxmcan/vundle</a></p>
<h2 id="五一些灵活的配置">五、一些灵活的配置</h2>
<p>按照步骤安装完后，可以配置一些常用的命令的“别名”，cd到根目录，看到的是这样的~
输入</p>
<p><code>vi .zshrc.local</code></p>
<p>打开后在里面输入</p>
<pre tabindex="0"><code>alias gs=&#39;git status&#39;

alias app=&#39;cd Documents/project/code/v2.0/&#39;
</code></pre><p>然后<code>wq</code>保存，</p>
<p>上面输入的内容可以根据自己的需要更改
<code>alias gs='git status'</code>意思就是给<code>git status</code>命令，取个别名<code>gs</code>,以后用的时候直接用<code>gs</code>代替<code>git status</code></p>
<p><code>alias app='cd Documents/project/code/v2.0/'</code>的意思是以后直接输入app就直接到v2.0这个目录了，这些根据你的需要自己配置啦</p>
<p>最后为了立即让设置生效，你可以重新打开终端或者直接执行命令</p>
<p><code>source .zshrc.local</code></p>
<p>最后直接在zsh里输入你刚自定义的短命令试试吧</p>]]></content>
		</item>
		
		<item>
			<title>MacOSX 隐藏和显示隐藏文件</title>
			<link>http://www.heyuan110.com/posts/macos/show-hide-files/</link>
			<pubDate>Tue, 18 Jun 2013 17:44:50 +0000</pubDate>
			
			<guid>http://www.heyuan110.com/posts/macos/show-hide-files/</guid>
			<description>&lt;p&gt;在osx里，.开头的文件会被自动隐藏的，但是如果想要显示所有隐藏文件怎么办呢？&lt;/p&gt;</description>
			<content type="html"><![CDATA[<p>在osx里，.开头的文件会被自动隐藏的，但是如果想要显示所有隐藏文件怎么办呢？</p>
<p><strong>打开终端输入下面的命令</strong></p>
<p>隐藏：<code>sh hideallfiles.sh</code></p>
<p>显示：<code>sh showallfiles.sh</code></p>
<p><img src="/images/showorhidefiles/2.jpg" alt="xgt"></p>
<p>下载sh文件：<a href="/download/showorhidefiles-sh.zip">sh.zip</a></p>
<p><strong>每次敲命令也是比较繁琐的</strong></p>
<p>所以写了个小工具有界面哦，截图</p>
<p><img src="/images/showorhidefiles/1.png" alt="xgt"></p>
<p>下载工具：<a href="/download/showorhidefiles-app.zip">ShowFiles</a></p>]]></content>
		</item>
		
	</channel>
</rss>
