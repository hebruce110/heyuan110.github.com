<!DOCTYPE html>
<html lang="zh-hans">

<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1.0">
	<meta http-equiv="X-UA-Compatible" content="ie=edge">
	<meta name="theme-color" content="#494f5c">
	<meta name="msapplication-TileColor" content="#494f5c">
<meta itemprop="name" content="搭建ELK日志收集分析系统">
<meta itemprop="description" content="日志主要包含系统日志、应用日志和安全日志。运维和开发人员通过日志可以了解服务器、程序运行情况，发现错误及检查错误发生原因。一个可靠、安全、可扩展的日志收集分析解决方案在程序或系统异常时能够让一切都变得轻松起来。
对比了ELK几种搭建模式：
 filebeat-&gt;elasticsearch-&gt;kibana filebeat-&gt;logstash-&gt;kafaka&amp;zookeeper-&gt;logstash-&gt;elasticsearch-&gt;kibana filebeat-&gt;kafaka&amp;zookeeper-&gt;logstash-&gt;elasticsearch-&gt;kibana  架构 从左到右分别为：
1)、数据采集层，将采集到的日志分别发送到kafka broker的集群队列上去
2)、数据缓存层，将采集到的日志临时转存到本地的kafka broker集群中(相当于队列的生产者)
3)、数据处理转发层，logstash实时去kafka broker集群拉去日志，在经过本地logstash后进行日志分析处理，然后转发到后端elasticsearch(相当于队列的消费者)
4)、数据存储展示层，elasticsearch将收集到的日志进行本地存储，然后通过kibana展示出来；由于elasticsearch采用集群的方式，前端通过nginx在反向代理kibana的访问地址，使用户访问入口只有一个
资源列表    服务器名称 IP地址 角色 功能     kz1 172.31.2.2 kafka&#43;zookeeper kafka broker节点1   kz2 172.31.2.3 kafka&#43;zookeeper kafka broker节点2   logstash-web 172.31.2.4 logstash 处理转发web相关日志   logstash-app 172.31.2.5 logstash 处理转发app相关日志   es-node1 172.31.2.6 elasticsearch&#43;kibana 数据存储展示   es-node2 172.31.2.7 elasticsearch&#43;kibana 数据存储展示    硬件配置    服务器类型 实例类型 CPU 内存 Disk     Kafka broker集群 r5.">
<meta itemprop="datePublished" content="2018-09-11T20:02:19&#43;00:00" />
<meta itemprop="dateModified" content="2018-09-11T20:02:19&#43;00:00" />
<meta itemprop="wordCount" content="1769">



<meta itemprop="keywords" content="elasticsearch,log,elk,kibana,kafaka,logstash," /><meta property="og:title" content="搭建ELK日志收集分析系统" />
<meta property="og:description" content="日志主要包含系统日志、应用日志和安全日志。运维和开发人员通过日志可以了解服务器、程序运行情况，发现错误及检查错误发生原因。一个可靠、安全、可扩展的日志收集分析解决方案在程序或系统异常时能够让一切都变得轻松起来。
对比了ELK几种搭建模式：
 filebeat-&gt;elasticsearch-&gt;kibana filebeat-&gt;logstash-&gt;kafaka&amp;zookeeper-&gt;logstash-&gt;elasticsearch-&gt;kibana filebeat-&gt;kafaka&amp;zookeeper-&gt;logstash-&gt;elasticsearch-&gt;kibana  架构 从左到右分别为：
1)、数据采集层，将采集到的日志分别发送到kafka broker的集群队列上去
2)、数据缓存层，将采集到的日志临时转存到本地的kafka broker集群中(相当于队列的生产者)
3)、数据处理转发层，logstash实时去kafka broker集群拉去日志，在经过本地logstash后进行日志分析处理，然后转发到后端elasticsearch(相当于队列的消费者)
4)、数据存储展示层，elasticsearch将收集到的日志进行本地存储，然后通过kibana展示出来；由于elasticsearch采用集群的方式，前端通过nginx在反向代理kibana的访问地址，使用户访问入口只有一个
资源列表    服务器名称 IP地址 角色 功能     kz1 172.31.2.2 kafka&#43;zookeeper kafka broker节点1   kz2 172.31.2.3 kafka&#43;zookeeper kafka broker节点2   logstash-web 172.31.2.4 logstash 处理转发web相关日志   logstash-app 172.31.2.5 logstash 处理转发app相关日志   es-node1 172.31.2.6 elasticsearch&#43;kibana 数据存储展示   es-node2 172.31.2.7 elasticsearch&#43;kibana 数据存储展示    硬件配置    服务器类型 实例类型 CPU 内存 Disk     Kafka broker集群 r5." />
<meta property="og:type" content="article" />
<meta property="og:url" content="http://www.heyuan110.com/posts/elasticsearch/2018-09-11-log-elk/" />
<meta property="article:published_time" content="2018-09-11T20:02:19+00:00" />
<meta property="article:modified_time" content="2018-09-11T20:02:19+00:00" />
<meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="搭建ELK日志收集分析系统"/>
<meta name="twitter:description" content="日志主要包含系统日志、应用日志和安全日志。运维和开发人员通过日志可以了解服务器、程序运行情况，发现错误及检查错误发生原因。一个可靠、安全、可扩展的日志收集分析解决方案在程序或系统异常时能够让一切都变得轻松起来。
对比了ELK几种搭建模式：
 filebeat-&gt;elasticsearch-&gt;kibana filebeat-&gt;logstash-&gt;kafaka&amp;zookeeper-&gt;logstash-&gt;elasticsearch-&gt;kibana filebeat-&gt;kafaka&amp;zookeeper-&gt;logstash-&gt;elasticsearch-&gt;kibana  架构 从左到右分别为：
1)、数据采集层，将采集到的日志分别发送到kafka broker的集群队列上去
2)、数据缓存层，将采集到的日志临时转存到本地的kafka broker集群中(相当于队列的生产者)
3)、数据处理转发层，logstash实时去kafka broker集群拉去日志，在经过本地logstash后进行日志分析处理，然后转发到后端elasticsearch(相当于队列的消费者)
4)、数据存储展示层，elasticsearch将收集到的日志进行本地存储，然后通过kibana展示出来；由于elasticsearch采用集群的方式，前端通过nginx在反向代理kibana的访问地址，使用户访问入口只有一个
资源列表    服务器名称 IP地址 角色 功能     kz1 172.31.2.2 kafka&#43;zookeeper kafka broker节点1   kz2 172.31.2.3 kafka&#43;zookeeper kafka broker节点2   logstash-web 172.31.2.4 logstash 处理转发web相关日志   logstash-app 172.31.2.5 logstash 处理转发app相关日志   es-node1 172.31.2.6 elasticsearch&#43;kibana 数据存储展示   es-node2 172.31.2.7 elasticsearch&#43;kibana 数据存储展示    硬件配置    服务器类型 实例类型 CPU 内存 Disk     Kafka broker集群 r5."/>

	<link rel="apple-touch-icon" sizes="180x180" href="/apple-touch-icon.png">
	<link rel="icon" type="image/png" sizes="32x32" href="/favicon-32x32.png">
	<link rel="icon" type="image/png" sizes="16x16" href="/favicon-16x16.png">
	<link rel="manifest" href="/site.webmanifest">
	<link rel="mask-icon" href="/safari-pinned-tab.svg" color="">
	<link rel="shortcut icon" href="/favicon.ico">

	<title>搭建ELK日志收集分析系统</title>
	<link rel="stylesheet" href="http://www.heyuan110.com/css/style.min.d3141168199607bf3a517216ce3c263814eecdbc8fca72a9a88700799a838219.css">
	
</head>

<body id="page">
	
	<header id="site-header" class="animated slideInUp faster">
		<div class="hdr-wrapper section-inner">
			<div class="hdr-left">
				<div class="site-branding">
					<a href="http://www.heyuan110.com">Bruce&#39;s Blog</a>
				</div>
				<nav class="site-nav hide-in-mobile">
					<a href="http://www.heyuan110.com/posts/">文章</a>
					<a href="http://www.heyuan110.com/go-categories/">Go系列</a>
					<a href="http://www.heyuan110.com/linux-categories/">Linux系列</a>
				</nav>
			</div>
			<div class="hdr-right hdr-icons">
				<button id="toc-btn" class="hdr-btn desktop-only-ib" title="Table of Contents"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-list"><line x1="8" y1="6" x2="21" y2="6"></line><line x1="8" y1="12" x2="21" y2="12"></line><line x1="8" y1="18" x2="21" y2="18"></line><line x1="3" y1="6" x2="3" y2="6"></line><line x1="3" y1="12" x2="3" y2="12"></line><line x1="3" y1="18" x2="3" y2="18"></line></svg></button><span class="hdr-social hide-in-mobile"><a href="https://github.com/heyuan110" target="_blank" rel="noopener me" title="Github"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-github"><path d="M9 19c-5 1.5-5-2.5-7-3m14 6v-3.87a3.37 3.37 0 0 0-.94-2.61c3.14-.35 6.44-1.54 6.44-7A5.44 5.44 0 0 0 20 4.77 5.07 5.07 0 0 0 19.91 1S18.73.65 16 2.48a13.38 13.38 0 0 0-7 0C6.27.65 5.09 1 5.09 1A5.07 5.07 0 0 0 5 4.77a5.44 5.44 0 0 0-1.5 3.78c0 5.42 3.3 6.61 6.44 7A3.37 3.37 0 0 0 9 18.13V22"></path></svg></a></span><button id="menu-btn" class="hdr-btn" title="Menu"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-menu"><line x1="3" y1="12" x2="21" y2="12"></line><line x1="3" y1="6" x2="21" y2="6"></line><line x1="3" y1="18" x2="21" y2="18"></line></svg></button>
			</div>
		</div>
	</header>
	<div id="mobile-menu" class="animated fast">
		<ul>
			<li><a href="http://www.heyuan110.com/posts/">文章</a></li>
			<li><a href="http://www.heyuan110.com/tags/">标签</a></li>
			<li><a href="http://www.heyuan110.com/about/">关于</a></li>
		</ul>
	</div>


	<main class="site-main section-inner animated fadeIn faster">
		<article class="thin">
			<header class="post-header">
				<div class="post-meta"><span>Sep 11, 2018</span></div>
				<h1>搭建ELK日志收集分析系统</h1>
			</header>
			<div class="content">
				<p>日志主要包含系统日志、应用日志和安全日志。运维和开发人员通过日志可以了解服务器、程序运行情况，发现错误及检查错误发生原因。一个可靠、安全、可扩展的日志收集分析解决方案在程序或系统异常时能够让一切都变得轻松起来。</p>
<p>对比了ELK几种搭建模式：</p>
<ol>
<li>filebeat-&gt;elasticsearch-&gt;kibana</li>
<li>filebeat-&gt;logstash-&gt;kafaka&amp;zookeeper-&gt;logstash-&gt;elasticsearch-&gt;kibana</li>
<li>filebeat-&gt;kafaka&amp;zookeeper-&gt;logstash-&gt;elasticsearch-&gt;kibana</li>
</ol>
<h2 id="架构">架构<a href="#架构" class="anchor" aria-hidden="true"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M15 7h3a5 5 0 0 1 5 5 5 5 0 0 1-5 5h-3m-6 0H6a5 5 0 0 1-5-5 5 5 0 0 1 5-5h3"></path><line x1="8" y1="12" x2="16" y2="12"></line></svg></a></h2>
<p><img src="https://raw.githubusercontent.com/heyuan110/static-source/master/media/15525328567089.jpg" alt=""></p>
<p>从左到右分别为：</p>
<p>1)、数据采集层，将采集到的日志分别发送到kafka broker的集群队列上去</p>
<p>2)、数据缓存层，将采集到的日志临时转存到本地的kafka broker集群中(相当于队列的生产者)</p>
<p>3)、数据处理转发层，logstash实时去kafka broker集群拉去日志，在经过本地logstash后进行日志分析处理，然后转发到后端elasticsearch(相当于队列的消费者)</p>
<p>4)、数据存储展示层，elasticsearch将收集到的日志进行本地存储，然后通过kibana展示出来；由于elasticsearch采用集群的方式，前端通过nginx在反向代理kibana的访问地址，使用户访问入口只有一个</p>
<h2 id="资源列表">资源列表<a href="#资源列表" class="anchor" aria-hidden="true"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M15 7h3a5 5 0 0 1 5 5 5 5 0 0 1-5 5h-3m-6 0H6a5 5 0 0 1-5-5 5 5 0 0 1 5-5h3"></path><line x1="8" y1="12" x2="16" y2="12"></line></svg></a></h2>
<table>
<thead>
<tr>
<th>服务器名称</th>
<th>IP地址</th>
<th>角色</th>
<th>功能</th>
</tr>
</thead>
<tbody>
<tr>
<td>kz1</td>
<td>172.31.2.2</td>
<td>kafka+zookeeper</td>
<td>kafka broker节点1</td>
</tr>
<tr>
<td>kz2</td>
<td>172.31.2.3</td>
<td>kafka+zookeeper</td>
<td>kafka broker节点2</td>
</tr>
<tr>
<td>logstash-web</td>
<td>172.31.2.4</td>
<td>logstash</td>
<td>处理转发web相关日志</td>
</tr>
<tr>
<td>logstash-app</td>
<td>172.31.2.5</td>
<td>logstash</td>
<td>处理转发app相关日志</td>
</tr>
<tr>
<td>es-node1</td>
<td>172.31.2.6</td>
<td>elasticsearch+kibana</td>
<td>数据存储展示</td>
</tr>
<tr>
<td>es-node2</td>
<td>172.31.2.7</td>
<td>elasticsearch+kibana</td>
<td>数据存储展示</td>
</tr>
</tbody>
</table>
<h2 id="硬件配置">硬件配置<a href="#硬件配置" class="anchor" aria-hidden="true"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M15 7h3a5 5 0 0 1 5 5 5 5 0 0 1-5 5h-3m-6 0H6a5 5 0 0 1-5-5 5 5 0 0 1 5-5h3"></path><line x1="8" y1="12" x2="16" y2="12"></line></svg></a></h2>
<table>
<thead>
<tr>
<th>服务器类型</th>
<th>实例类型</th>
<th>CPU</th>
<th>内存</th>
<th>Disk</th>
</tr>
</thead>
<tbody>
<tr>
<td>Kafka broker集群</td>
<td>r5.xlarge</td>
<td>4</td>
<td>32</td>
<td>1T</td>
</tr>
<tr>
<td>Logstash</td>
<td>c5.2xlarge</td>
<td>8</td>
<td>16</td>
<td>100G</td>
</tr>
<tr>
<td>Elasticsearch+kibana</td>
<td>r5.xlarge</td>
<td>4</td>
<td>32</td>
<td>2T</td>
</tr>
</tbody>
</table>
<h2 id="部署前的准备工作">部署前的准备工作<a href="#部署前的准备工作" class="anchor" aria-hidden="true"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M15 7h3a5 5 0 0 1 5 5 5 5 0 0 1-5 5h-3m-6 0H6a5 5 0 0 1-5-5 5 5 0 0 1 5-5h3"></path><line x1="8" y1="12" x2="16" y2="12"></line></svg></a></h2>
<p>分别在这6台服务器上进行设置</p>
<h3 id="1主机名设置">1)、主机名设置<a href="#1主机名设置" class="anchor" aria-hidden="true"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M15 7h3a5 5 0 0 1 5 5 5 5 0 0 1-5 5h-3m-6 0H6a5 5 0 0 1-5-5 5 5 0 0 1 5-5h3"></path><line x1="8" y1="12" x2="16" y2="12"></line></svg></a></h3>
<p><code>$ sudo vim /etc/hosts</code></p>
<pre><code>172.31.2.2  kz1

172.31.2.3  kz2

172.31.2.4  logstash-web

172.31.2.5  logstash-app

172.31.2.6  es-node1

172.31.2.7  es-node2
</code></pre><p>验证：在其中任何一台服务器上ping 主机名，能通，则代表设置生效</p>
<p>(备注：需要在aws上的ec2的安全策略上分别开启ICMP流量)</p>
<h3 id="2系统优化">2)、系统优化<a href="#2系统优化" class="anchor" aria-hidden="true"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M15 7h3a5 5 0 0 1 5 5 5 5 0 0 1-5 5h-3m-6 0H6a5 5 0 0 1-5-5 5 5 0 0 1 5-5h3"></path><line x1="8" y1="12" x2="16" y2="12"></line></svg></a></h3>
<p>2.1)、打开最大文件描述符</p>
<p><code>$ sudo vim /etc/security/limits.conf</code></p>
<pre><code>*      soft        nofile    65535

*      hard       nofile      65535

*      soft        nproc      2048

*      hard       nproc      4096
</code></pre><p>验证：退出当前终端在重新登录，$ ulimit -n 显示65535，表示设置生效</p>
<p>2.2)、内核调整</p>
<p><code>$ sudo vim /etc/sysctl.conf</code></p>
<pre><code>vm.max_map_count = 262144             # elasticsearch启动时所拥有的虚拟内存区域数量，过小，es会无法启动

vm.swappiness = 0                                   # 不使用虚拟内存

</code></pre><p>设置生效： <code>$ sudo sysctl -p</code></p>
<h3 id="3软件包准备">3)、软件包准备<a href="#3软件包准备" class="anchor" aria-hidden="true"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M15 7h3a5 5 0 0 1 5 5 5 5 0 0 1-5 5h-3m-6 0H6a5 5 0 0 1-5-5 5 5 0 0 1 5-5h3"></path><line x1="8" y1="12" x2="16" y2="12"></line></svg></a></h3>
<p>jdk-8u151-linux-x64.tar.gz</p>
<p>filebeat-5.5.2-linux-x86_64.tar.gz</p>
<p>kafka_2.12-2.0.0.tgz</p>
<p>zookeeper-3.4.13.tar.gz</p>
<p>logstash-5.5.2.tar.gz</p>
<p>elasticsearch-5.5.2.tar.gz</p>
<p>kibana-5.5.2-linux-x86_64.tar.gz</p>
<p>备注：软件包存放位置 /usr/local/programs/src</p>
<h3 id="4安装配置supervisor">4)、安装配置supervisor<a href="#4安装配置supervisor" class="anchor" aria-hidden="true"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M15 7h3a5 5 0 0 1 5 5 5 5 0 0 1-5 5h-3m-6 0H6a5 5 0 0 1-5-5 5 5 0 0 1 5-5h3"></path><line x1="8" y1="12" x2="16" y2="12"></line></svg></a></h3>
<p><code>$ sudo mkdir /usr/local/programs/supervisor -pv</code></p>
<p><code>$ sudo apt-get update</code></p>
<p><code>$ sudo apt-get install python-pip –y</code></p>
<p><code>$ sudo locale-gen zh_CN.UTF-8 en_US.UTF-8</code></p>
<p><code>$ sudo pip install supervisor</code></p>
<p><code>$ sudo su</code></p>
<p><code>$ /usr/local/bin/echo_supervisord_conf &gt; /usr/local/programs/supervisor/supervisord.conf</code></p>
<p>supervisor配置文件修改调整</p>
<p><code>$ sudo vim supervisord.conf</code></p>
<pre><code>[inet_http_server]                                                           # 去掉前面的注释

port=127.0.0.1:9001                                                       # 去掉前面的注释,开启supervisor端口监听

[supervisord]

logfile=/usr/local/programs/supervisor/supervisord.log  # 设置supervisor的日志文件路径

environment=JAVA_HOME=&quot;/usr/local/programs/jdk&quot;      # 设置java环境变量

[include]

files = conf.d/*.conf                                                        # supervisor包含的配置文件，此处使用相对路径
</code></pre><p><strong>备注：需创建服务配置目录：$ sudo mkdir /usr/local/programs/supervisor/conf.d</strong></p>
<h2 id="部署过程">部署过程<a href="#部署过程" class="anchor" aria-hidden="true"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M15 7h3a5 5 0 0 1 5 5 5 5 0 0 1-5 5h-3m-6 0H6a5 5 0 0 1-5-5 5 5 0 0 1 5-5h3"></path><line x1="8" y1="12" x2="16" y2="12"></line></svg></a></h2>
<h3 id="1jdk安装">1)、jdk安装<a href="#1jdk安装" class="anchor" aria-hidden="true"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M15 7h3a5 5 0 0 1 5 5 5 5 0 0 1-5 5h-3m-6 0H6a5 5 0 0 1-5-5 5 5 0 0 1 5-5h3"></path><line x1="8" y1="12" x2="16" y2="12"></line></svg></a></h3>
<p>以下操作分别在这6台服务器上安装</p>
<h4 id="11解压安装包并指定目录">1.1)、解压安装包并指定目录<a href="#11解压安装包并指定目录" class="anchor" aria-hidden="true"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M15 7h3a5 5 0 0 1 5 5 5 5 0 0 1-5 5h-3m-6 0H6a5 5 0 0 1-5-5 5 5 0 0 1 5-5h3"></path><line x1="8" y1="12" x2="16" y2="12"></line></svg></a></h4>
<p><code>$ sudo tar -zxvf jdk-8u151-linux-x64.tar.gz -C /usr/local/programs</code></p>
<p><code>$ cd /usr/local/programs &amp;&amp; sudo mv jdk1.8.0_151 jdk</code></p>
<h4 id="12设置全局环境变量">1.2)、设置全局环境变量<a href="#12设置全局环境变量" class="anchor" aria-hidden="true"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M15 7h3a5 5 0 0 1 5 5 5 5 0 0 1-5 5h-3m-6 0H6a5 5 0 0 1-5-5 5 5 0 0 1 5-5h3"></path><line x1="8" y1="12" x2="16" y2="12"></line></svg></a></h4>
<p>编辑/etc/profile在文件在最后添加如下内容：</p>
<p><code># set java environment</code></p>
<pre><code>export JAVA_HOME=/usr/local/programs/jdk

export JRE_HOME=$JAVA_HOME/jre

export CLASSPATH=.:$JAVA_HOME/lib:$JRE_HOME/lib:$CLASSPATH

export PATH=$JAVA_HOME/bin:$JRE_HOME/bin:$PATH
</code></pre><h4 id="13使jdk环境变量配置生效">1.3)、使Jdk环境变量配置生效<a href="#13使jdk环境变量配置生效" class="anchor" aria-hidden="true"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M15 7h3a5 5 0 0 1 5 5 5 5 0 0 1-5 5h-3m-6 0H6a5 5 0 0 1-5-5 5 5 0 0 1 5-5h3"></path><line x1="8" y1="12" x2="16" y2="12"></line></svg></a></h4>
<p><code>$ source /etc/profile</code></p>
<h4 id="14验证">1.4)、验证<a href="#14验证" class="anchor" aria-hidden="true"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M15 7h3a5 5 0 0 1 5 5 5 5 0 0 1-5 5h-3m-6 0H6a5 5 0 0 1-5-5 5 5 0 0 1 5-5h3"></path><line x1="8" y1="12" x2="16" y2="12"></line></svg></a></h4>
<p><code>$ echo $JAVA_HOME</code></p>
<h3 id="2zookeeper安装配置">2)、zookeeper安装配置<a href="#2zookeeper安装配置" class="anchor" aria-hidden="true"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M15 7h3a5 5 0 0 1 5 5 5 5 0 0 1-5 5h-3m-6 0H6a5 5 0 0 1-5-5 5 5 0 0 1 5-5h3"></path><line x1="8" y1="12" x2="16" y2="12"></line></svg></a></h3>
<p>以下操作步骤在kz1和kz2服务器上进行安装部署</p>
<h5 id="21解压软件包到指定目录">2.1)、解压软件包到指定目录<a href="#21解压软件包到指定目录" class="anchor" aria-hidden="true"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M15 7h3a5 5 0 0 1 5 5 5 5 0 0 1-5 5h-3m-6 0H6a5 5 0 0 1-5-5 5 5 0 0 1 5-5h3"></path><line x1="8" y1="12" x2="16" y2="12"></line></svg></a></h5>
<p><code>$ sudo tar -zxvf zookeeper-3.4.13.tar.gz -C /usr/local/programs</code></p>
<p><code>$ cd /usr/local/programs &amp;&amp; sudo mv zookeeper-3.4.13 zookeeper</code></p>
<h5 id="22编辑zookeeper配置文件">2.2)、编辑zookeeper配置文件<a href="#22编辑zookeeper配置文件" class="anchor" aria-hidden="true"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M15 7h3a5 5 0 0 1 5 5 5 5 0 0 1-5 5h-3m-6 0H6a5 5 0 0 1-5-5 5 5 0 0 1 5-5h3"></path><line x1="8" y1="12" x2="16" y2="12"></line></svg></a></h5>
<p><code>$ cd /usr/local/programs/zookeeper/conf</code></p>
<p><code>$ cp -a zoo_sample.cfg zoo.cfg</code></p>
<p><code>$ sudo vim zoo.cfg</code></p>
<p>完整配置文件如下：</p>
<pre><code>tickTime=2000

# zookeeper服务器之间或客户端与服务器之间维持心跳的时间间隔，每个tickTime时间会发送一次心跳

initLimit=10

# 集群中Zookeeper的leader和Follower服务器之间初始化连接时最长能忍受多少个心跳时间间隔数，总的时间长度为5*2000-10秒，当超过这个长度时，Zookeeper服务器还没有收到客户端的返回信息，表明客户端连接失败

syncLimit=5

# zookeeper集群中Leader与Follower之间发送消息，请求和应答时间长度，最长不能超过多少个tickTime的时间长度，此时为5*2000=10秒

dataDir=/usr/local/programs/zookeeper/data

# 设置zookeeper保存数据的目录，默认zookeeper将写数据的日志文件也保存在这个目录里

dataLogDir=/usr/local/programs/zookeeper/logs

# 设置Zookeeper保存日志的目录

clientPort=2181

# 客户端连接zookeeper服务器的端口，zookeeper会监听这个端口，接受客户端的访问请求

server.1=172.31.2.2:2888:3888

server.2=172.31.2.3:2888:3888

# 此选项为集群配置选项：server.1：代表是第几号服务器；172.31.2.2：代表这个服务器的IP地址；2888：表示这个服务器与集群中的Leader服务器交换信息的端口；3888：表示万一集群中的Leader服务器挂了，需要一个端口来重新进行选举，选出一个新的Leader，而这个端口就是用来执行选举时服务器相互通信的端口

</code></pre><p>备注：将此配置文件同步至kafka broker集群中的另外两台服务器上</p>
<h5 id="23创建myid文件">2.3)、创建myid文件<a href="#23创建myid文件" class="anchor" aria-hidden="true"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M15 7h3a5 5 0 0 1 5 5 5 5 0 0 1-5 5h-3m-6 0H6a5 5 0 0 1-5-5 5 5 0 0 1 5-5h3"></path><line x1="8" y1="12" x2="16" y2="12"></line></svg></a></h5>
<p>在172.31.2.2(kz1)服务器上执行：</p>
<p><code>$ echo 1 &gt; /usr/local/programs/zookeeper/data/myid</code></p>
<p>在172.31.2.3(kz2)服务器上执行：</p>
<p><code>echo 2 &gt; /usr/local/programs/zookeeper/data/myid</code></p>
<p>备注：此时的myid文件必须创建在zoo.cfg配置文件里面的dataDir指定的目录内</p>
<p>myid文件说明：zookeeper启动时会读取这个文件，拿到里面的数据与zoo.cfg里面的配置信息比较从而判断自己到底是哪个server</p>
<h5 id="24启动zookeeper服务">2.4)、启动zookeeper服务<a href="#24启动zookeeper服务" class="anchor" aria-hidden="true"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M15 7h3a5 5 0 0 1 5 5 5 5 0 0 1-5 5h-3m-6 0H6a5 5 0 0 1-5-5 5 5 0 0 1 5-5h3"></path><line x1="8" y1="12" x2="16" y2="12"></line></svg></a></h5>
<p>分别在172.31.2.2、172.31.2.3这两台服务器上执行如下命令：</p>
<p><code>$ sudo /usr/local/programs/zookeeper/bin/zkServer.sh start</code></p>
<p>备注：zookeeper默认是以后台方式启动</p>
<p>前台启动方式为：<code>$ sudo /usr/local/programs/zookeeper/bin/zkServer.sh start-foreground</code></p>
<h5 id="25查看zookeeper集群状态">2.5)、查看zookeeper集群状态<a href="#25查看zookeeper集群状态" class="anchor" aria-hidden="true"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M15 7h3a5 5 0 0 1 5 5 5 5 0 0 1-5 5h-3m-6 0H6a5 5 0 0 1-5-5 5 5 0 0 1 5-5h3"></path><line x1="8" y1="12" x2="16" y2="12"></line></svg></a></h5>
<p>分别在172.31.2.2、172.31.2.3这两台服务器上执行如下命令：</p>
<pre><code># 172.31.2.2

/usr/local/programs/zookeeper/bin/zkServer.sh status

ZooKeeper JMX enabled by default

Using config: /usr/local/programs/zookeeper/bin/../conf/zoo.cfg

Mode: follower


#172.31.2.3

/usr/local/programs/zookeeper/bin/zkServer.sh status

ZooKeeper JMX enabled by default

Using config: /usr/local/programs/zookeeper/bin/../conf/zoo.cfg

Mode: leader

Mode: follower

</code></pre><h3 id="3kafka集群安装配置">3)、kafka集群安装配置<a href="#3kafka集群安装配置" class="anchor" aria-hidden="true"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M15 7h3a5 5 0 0 1 5 5 5 5 0 0 1-5 5h-3m-6 0H6a5 5 0 0 1-5-5 5 5 0 0 1 5-5h3"></path><line x1="8" y1="12" x2="16" y2="12"></line></svg></a></h3>
<h4 id="31解压安装到指定目录">3.1)、解压安装到指定目录<a href="#31解压安装到指定目录" class="anchor" aria-hidden="true"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M15 7h3a5 5 0 0 1 5 5 5 5 0 0 1-5 5h-3m-6 0H6a5 5 0 0 1-5-5 5 5 0 0 1 5-5h3"></path><line x1="8" y1="12" x2="16" y2="12"></line></svg></a></h4>
<p><code>$ sudo tar -zxvf kafka_2.12-2.0.0.tgz -C /usr/local/programs/kafka</code></p>
<h4 id="32kafka-jvm内存调整">3.2)、Kafka jvm内存调整<a href="#32kafka-jvm内存调整" class="anchor" aria-hidden="true"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M15 7h3a5 5 0 0 1 5 5 5 5 0 0 1-5 5h-3m-6 0H6a5 5 0 0 1-5-5 5 5 0 0 1 5-5h3"></path><line x1="8" y1="12" x2="16" y2="12"></line></svg></a></h4>
<p><code>$ sudo vim /usr/local/programs/kafka/bin/kafka-server-start.sh</code></p>
<p>修改如下地方：</p>
<pre><code>if [ &quot;x$KAFKA_HEAP_OPTS&quot; = &quot;x&quot; ]; then

export KAFKA_HEAP_OPTS=&quot;-Xmx4G -Xms4G&quot;          # 此处设置为内存的一半

fi

</code></pre><h4 id="33修改配置文件">3.3)、修改配置文件<a href="#33修改配置文件" class="anchor" aria-hidden="true"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M15 7h3a5 5 0 0 1 5 5 5 5 0 0 1-5 5h-3m-6 0H6a5 5 0 0 1-5-5 5 5 0 0 1 5-5h3"></path><line x1="8" y1="12" x2="16" y2="12"></line></svg></a></h4>
<p><code>$ sudo vim /usr/local/programs/kafka/config/server.properties</code></p>
<p>完整配置文件如下：</p>
<pre><code>
# see kafka.server.KafkaConfig for additional details and defaults

############################### Server Basics #########################################

broker.id=1                                              # 每个broker在集群中的唯一标识，要求为正数

port=9092                                               # kafka监听端口，不配置默认为9092

host.name=kz1                                         # broker的主机地址或主机名(重要)

############################### Socket Server Settings #################################

num.network.threads=4                                   # 接收消息的线程数量，接收线程会将接收到的消息放在内存中，然后再从内存中写入磁盘(建议调整为CPU的核心数，根据实际情况调整)

num.io.threads=8                                     # 消息从内存中写入磁盘的时候使用的线程数量，用来处理磁盘IO的线程数量(建议调整为CPU核心数的2倍)

socket.send.buffer.bytes=102400               # 发送套接字的缓冲区大小

socket.receive.buffer.bytes=102400            # 接收套接字的缓冲区大小

socket.request.max.bytes=104857600        # 请求套接字的缓冲区大小

############################### Log Basics ###########################################

log.dirs=/usr/local/programs/kafka/logs    # Kafka运行日志存放的路径

num.partitions=1                                      # topic在当前broker上的分片个数

num.recovery.threads.per.data.dir=1          # 设置恢复和清理data下数据的线程数量(segment文件默认会被保留7天的时间，超时的话就会被清理，清理需要线程来执行)

############################## Log Retention Policy #####################################

log.retention.hours=168                                   # segment文件保留最长时间，默认保留7天(168小时)，超时将被清除

log.segment.bytes=1073741824                # 日志文件每个segment的大小，默认为1G

log.retention.check.interval.ms=300000     # 周期性检查segment文件大小的时间(单位是毫秒)

############################### Zookeeper ###########################################

zookeeper.connect=172.31.2.2:2181,172.31.2.3:2181

# zookeeper集群的地址，可以是多个，多个之间用逗号隔开

zookeeper.connection.timeout.ms=6000    # zookeeper的连接超时时间

############################### Group Coordinator Settings ###########################

group.initial.rebalance.delay.ms=0                    # 新版本添加的参数；这个参数的主要效果就是让coordinator推迟空消费组接收到成员加入请求后本应立即开启的rebalance，在实际使用时，假设你预估你的所有consumer组成员加入需要在10s内完成，那么你就可以设置该参数=10000
</code></pre><p>将配置文件同步到kz2服务器上：</p>
<p><code>$ scp server.properties ubuntu@172.31.2.3:/usr/local/programs/kafka/config</code></p>
<p>修改配置文件：</p>
<p><code>broker.id=2</code></p>
<p><code>host.name=kz2</code></p>
<h4 id="34启动kafka服务">3.4)、启动kafka服务<a href="#34启动kafka服务" class="anchor" aria-hidden="true"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M15 7h3a5 5 0 0 1 5 5 5 5 0 0 1-5 5h-3m-6 0H6a5 5 0 0 1-5-5 5 5 0 0 1 5-5h3"></path><line x1="8" y1="12" x2="16" y2="12"></line></svg></a></h4>
<p>前台方式启动：</p>
<p><code>$ sudo /usr/local/programs/kafka/bin/kafka-server-start.sh /usr/local/programs/kafka/config/server.properties</code></p>
<p>后台启动方式：</p>
<p><code>$ sudo /usr/local/programs/kafka/bin/kafka-server-start.sh --daemon /usr/local/programs/kafka/config/server.properties</code></p>
<h4 id="35kafka消息监控-kafkaoffsetmonitor">3.5)、Kafka消息监控-KafkaOffsetMonitor<a href="#35kafka消息监控-kafkaoffsetmonitor" class="anchor" aria-hidden="true"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M15 7h3a5 5 0 0 1 5 5 5 5 0 0 1-5 5h-3m-6 0H6a5 5 0 0 1-5-5 5 5 0 0 1 5-5h3"></path><line x1="8" y1="12" x2="16" y2="12"></line></svg></a></h4>
<p>简介：</p>
<p>1)、这个应用程序用来实时监控Kafka服务的Consumer以及它们所在的Partition中的Offset，我们可以浏览当前的消费者组，并且每个Topic的所有Partition的消费情况都可以观看的一清二楚</p>
<p>2)、它让我们很直观的知道，每个Partition的Message是否消费掉，有没有阻塞等等</p>
<p>3)、这个Web管理平台保留的Partition、Offset和它的Consumer的相关历史数据，我们可以通过浏览Web管理的相关模块，清楚的知道最近一段时间的消费情况</p>
<p>下载地址：https://github.com/quantifind/KafkaOffsetMonitor/releases/tag/v0.2.1</p>
<pre><code>$ cd /usr/local/programs/

$ sudo mkdir kafka_monitor

$ sudo vim monitor_start.sh

</code></pre><p><code>#! /bin/bash</code></p>
<p><code>java -cp KafkaOffsetMonitor-assembly-0.2.0.jar \ com.quantifind.kafka.offsetapp.OffsetGetterWeb \ --zk h1:2181 \ --port 8089 \ --refresh 10.seconds \ --retain 1.days</code></p>
<p>服务启动：<code>$ cd /usr/local/programs/kafka_monitor &amp;&amp; $ bash monitor_start.sh</code></p>
<h3 id="4logstash安装配置">4)、logstash安装配置<a href="#4logstash安装配置" class="anchor" aria-hidden="true"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M15 7h3a5 5 0 0 1 5 5 5 5 0 0 1-5 5h-3m-6 0H6a5 5 0 0 1-5-5 5 5 0 0 1 5-5h3"></path><line x1="8" y1="12" x2="16" y2="12"></line></svg></a></h3>
<h4 id="41解压安装包到指定目录">4.1)、解压安装包到指定目录<a href="#41解压安装包到指定目录" class="anchor" aria-hidden="true"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M15 7h3a5 5 0 0 1 5 5 5 5 0 0 1-5 5h-3m-6 0H6a5 5 0 0 1-5-5 5 5 0 0 1 5-5h3"></path><line x1="8" y1="12" x2="16" y2="12"></line></svg></a></h4>
<p><code>$ sudo tar -zxvf logstash-5.5.2.tar.gz -C /usr/local/programs/logstash</code></p>
<h4 id="42jvm内存优化调整">4.2)、jvm内存优化调整<a href="#42jvm内存优化调整" class="anchor" aria-hidden="true"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M15 7h3a5 5 0 0 1 5 5 5 5 0 0 1-5 5h-3m-6 0H6a5 5 0 0 1-5-5 5 5 0 0 1 5-5h3"></path><line x1="8" y1="12" x2="16" y2="12"></line></svg></a></h4>
<p><code>$ sudo vim /usr/local/programs/logstash/config/jvm.optons -Xms8g</code></p>
<p>-Xmx8g # 建议设置为内存的一半(根据实际情况进行调整)</p>
<h4 id="43修改配置文件">4.3)、修改配置文件<a href="#43修改配置文件" class="anchor" aria-hidden="true"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M15 7h3a5 5 0 0 1 5 5 5 5 0 0 1-5 5h-3m-6 0H6a5 5 0 0 1-5-5 5 5 0 0 1 5-5h3"></path><line x1="8" y1="12" x2="16" y2="12"></line></svg></a></h4>
<pre><code>$ sudo vim /usr/local/programs/logstash/config/logstash.yml

path.data: /usr/local/programs/logstash/data

pipeline.workers: 8                      # CPU核心数

pipeline.output.workers: 4           # 这里相当于output elasticsearch里面的workers数量

pipeline.batch.size: 1000                     # 根据qps，压力情况等调整

pipeline.batch.delay: 5

path.config: /usr/local/programs/logstash/config/conf.d  # logstash的配置文件存放位置

path.logs: /usr/local/programs/logstash/logs           # logstash的日志文件

</code></pre><h4 id="44启动logstash">4.4)、启动logstash<a href="#44启动logstash" class="anchor" aria-hidden="true"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M15 7h3a5 5 0 0 1 5 5 5 5 0 0 1-5 5h-3m-6 0H6a5 5 0 0 1-5-5 5 5 0 0 1 5-5h3"></path><line x1="8" y1="12" x2="16" y2="12"></line></svg></a></h4>
<p>logstash前台启动方式：</p>
<p><code>$ sudo /usr/local/programs/logstash/bin/logstash -f /usr/local/programs/logstash/conf/oc-logstash-kafka.conf</code></p>
<p>logstash后台启动方式：</p>
<p><code>$ sudo nohup /usr/local/programs/logstash/bin/logstash -f /usr/local/programs/logstash/conf/oc-logstash-kafka.conf &amp;</code></p>
<h4 id="45logstash安装geoip插件">4.5)、Logstash安装geoip插件<a href="#45logstash安装geoip插件" class="anchor" aria-hidden="true"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M15 7h3a5 5 0 0 1 5 5 5 5 0 0 1-5 5h-3m-6 0H6a5 5 0 0 1-5-5 5 5 0 0 1 5-5h3"></path><line x1="8" y1="12" x2="16" y2="12"></line></svg></a></h4>
<p><code>$ cd /usr/local/programs/logstash</code></p>
<p><code>$ sudo ./bin/logstash-plugin install logstash-filter-geoip</code></p>
<p>验证插件是否安装：<code>$ sudo ./bin/logstash-plugin list | grep geoip</code></p>
<p>Logstash安装x-pack插件(插件按照后面elasticsearch的x-pack插件破解方式进行破解)</p>
<pre><code>$ cd /usr/local/programs/logstash

$ sudo ./bin/logstash-plugin install x-pack

$ sudo vim logstash.yml

xpack.monitoring.elasticsearch.username: logstash_system

xpack.monitoring.elasticsearch.password: logstashpassword
</code></pre><h3 id="5elasticsearch集群安装配置">5)、Elasticsearch集群安装配置<a href="#5elasticsearch集群安装配置" class="anchor" aria-hidden="true"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M15 7h3a5 5 0 0 1 5 5 5 5 0 0 1-5 5h-3m-6 0H6a5 5 0 0 1-5-5 5 5 0 0 1 5-5h3"></path><line x1="8" y1="12" x2="16" y2="12"></line></svg></a></h3>
<h4 id="51解压软件包至指定目录">5.1)、解压软件包至指定目录<a href="#51解压软件包至指定目录" class="anchor" aria-hidden="true"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M15 7h3a5 5 0 0 1 5 5 5 5 0 0 1-5 5h-3m-6 0H6a5 5 0 0 1-5-5 5 5 0 0 1 5-5h3"></path><line x1="8" y1="12" x2="16" y2="12"></line></svg></a></h4>
<p><code>$ sudo tar -zxvf elasticsearch-5.5.2.tar.gz -C /usr/local/programs/elasticsearch</code></p>
<h4 id="52jvm配置">5.2)、JVM配置<a href="#52jvm配置" class="anchor" aria-hidden="true"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M15 7h3a5 5 0 0 1 5 5 5 5 0 0 1-5 5h-3m-6 0H6a5 5 0 0 1-5-5 5 5 0 0 1 5-5h3"></path><line x1="8" y1="12" x2="16" y2="12"></line></svg></a></h4>
<p>由于elasticsearch是Java开发的，所以可以通过修改/usr/local/programs/elasticsearch/jvm.options配置文件来设定JVM的相关设定</p>
<p><code>$ sudo vim /usr/local/programs/elasticsearch/jvm.options -Xms4g</code></p>
<p>-Xmx4g  # 建议设置为内存的一半(根据实际情况调整)</p>
<p>调整elasticsearch GC方法(此参数调整特别注意，容易导致elasticsearch无法启动)</p>
<h2 id="gc-configuration">GC configuration<a href="#gc-configuration" class="anchor" aria-hidden="true"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M15 7h3a5 5 0 0 1 5 5 5 5 0 0 1-5 5h-3m-6 0H6a5 5 0 0 1-5-5 5 5 0 0 1 5-5h3"></path><line x1="8" y1="12" x2="16" y2="12"></line></svg></a></h2>
<pre><code>-XX:+UseConcMarkSweepGC

-XX:CMSInitiatingOccupancyFraction=75

-XX:+UseCMSInitiatingOccupancyOnly
</code></pre><p>修改为：</p>
<pre><code>-XX:+UseG1GC

-XX:MaxGCPauseMillis=200
</code></pre><h4 id="53修改配置文件">5.3)、修改配置文件<a href="#53修改配置文件" class="anchor" aria-hidden="true"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M15 7h3a5 5 0 0 1 5 5 5 5 0 0 1-5 5h-3m-6 0H6a5 5 0 0 1-5-5 5 5 0 0 1 5-5h3"></path><line x1="8" y1="12" x2="16" y2="12"></line></svg></a></h4>
<p><code>$ sudo vim elasticsearch.yml</code></p>
<pre><code>cluster.name: elasticsearch-application                            # elasticsearch集群名称

node.name: node-1                                                 # node节点名称

node.master: true                                                   # 表示节点是否具有成为主节点的资格

node.data: true                                                      # 表示节点是否存储数据

node.attr.rack: r1                                                    # 将自定义的属性添加到节点·

path.data: /usr/local/programs/elasticsearch/data    # ES数据存放位置

path.logs: /usr/local/programs/elasticsearch/logs     # ES 日志存放位置

bootstrap.memory_lock: true                                         # 锁定物理内存地址, 防止elasticsearch内存被交换出去

# 备注

# Make sure that the heap size is set to about half the memory available on the system and that the owner of the process is allowed to use this limit.

# 确保ES_HEAP_SIZE参数设置为系统可用内存的一半左右

# Elasticsearch performs poorly when the system is swapping the memory

# 当系统进行内存交换的时候, es的性能很差

network.host: 192.168.2.6                                        # 为es设置IP绑定

http.port: 9200                                                       # 为es设置自定义端口，默认是9200

discovery.zen.ping.unicast.hosts: [&quot;172.31.2.6:9300&quot;, &quot;172.31.2.7:9300&quot;]

# 当启动新节点时, 通过ip列表进行节点发现, 组件集群

discovery.zen.minimum_master_nodes: 3                  # 防止集群脑裂现象(集群总节点数量/2+1)

gateway.recover_after_nodes: 3                               # 一个集群中的N各节点启动后, 才允许进行数据恢复处理

# x-pack和es-head插件配置参数

http.cors.enabled: true

http.cors.allow-origin: &quot;*&quot;

xpack.security.enabled: true (es登录通过x-pack插件验证)

xpack.security.transport.ssl.enabled: true

http.cors.allow-headers: Authorization,X-Requested-With,Content-Length,Content-Type

action.auto_create_index: .security,.monitoring*,.watches,.triggered_watches,.watcher-history*,.ml*,.security,.security-6

将elasticsearch的配置文件同步到另外一台服务器(172.31.2.7)

修改配置文件：

node.name: node-2                                                 # node节点名称

network.host: 192.168.2.7                                        # es设置IP绑定

</code></pre><h4 id="54启动elasticsearch服务">5.4)、启动elasticsearch服务<a href="#54启动elasticsearch服务" class="anchor" aria-hidden="true"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M15 7h3a5 5 0 0 1 5 5 5 5 0 0 1-5 5h-3m-6 0H6a5 5 0 0 1-5-5 5 5 0 0 1 5-5h3"></path><line x1="8" y1="12" x2="16" y2="12"></line></svg></a></h4>
<p>Elasticsearch默认前台启动：</p>
<p><code>$ sudo /usr/local/programs/elasticsearch/bin/elasticsearch</code></p>
<h4 id="55elasticsearch-head插件安装">5.5)、elasticsearch head插件安装<a href="#55elasticsearch-head插件安装" class="anchor" aria-hidden="true"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M15 7h3a5 5 0 0 1 5 5 5 5 0 0 1-5 5h-3m-6 0H6a5 5 0 0 1-5-5 5 5 0 0 1 5-5h3"></path><line x1="8" y1="12" x2="16" y2="12"></line></svg></a></h4>
<p>5.5.1)、下载elasticsearch-head插件</p>
<p><code>$ cd /usr/local/programs &amp;&amp; sudo git clone https://github.com/mobz/elasticsearch-head.git</code></p>
<p>5.5.2)、elasticsearch-head配置文件修改</p>
<pre><code>$ cd elasticsearch-head

$ sudo vim Gruntfile.js

connect: {

        server: {

              options: {

                     port: 9100,

                     hostname: '*',

                     base: '.',

                     keepalive: true

              }

       }

}
</code></pre><p><code>$ sudo vim _site/app.js</code></p>
<p>修改如下地方：</p>
<p>this.base_uri = this.config.base_uri || this.prefs.get(&ldquo;app-base_uri&rdquo;) || &ldquo;http://192.168.2.6:9200&rdquo;;</p>
<p>Enable CORS in elasticsearch</p>
<p>1)、add http.cors.enabled: true</p>
<p>2)、you must also set http.cors.allow-origin because no origin allowed by default. http.cors.allow-origin: &ldquo;*&rdquo; is valid value, however it&rsquo;s considered as a security risk as your cluster is open to cross origin from anywhere</p>
<pre><code>$ sudo apt-get update &amp;&amp; $ sudo apt-get install nodejs

$ sudo apt-get install npm

$ sudo ln -s /usr/bin/nodejs /usr/bin/node
</code></pre><p>5.5.3)、elasticsearch-head插件服务启动方式</p>
<pre><code>$ cd /usr/local/programs/elasticsearch/elasticsearch-head

$ npm install

$ npm run start
</code></pre><p>此时elasticsearch head插件安装完成</p>
<h4 id="56elasticsearch-x-pack插件安装">5.6)、elasticsearch x-pack插件安装<a href="#56elasticsearch-x-pack插件安装" class="anchor" aria-hidden="true"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M15 7h3a5 5 0 0 1 5 5 5 5 0 0 1-5 5h-3m-6 0H6a5 5 0 0 1-5-5 5 5 0 0 1 5-5h3"></path><line x1="8" y1="12" x2="16" y2="12"></line></svg></a></h4>
<p><code>$ cd /usr/local/programs/elasticsearch</code></p>
<p><code>$ sudo bin/elasticsearch-plugin install x-pack</code></p>
<p>安装完成后，再次登录 <a href="http://xxx.xxx.xxx.xxx">http://xxx.xxx.xxx.xxx</a>:9200时，提示需要输入密码</p>
<p>默认账户密码：elastic，changeme</p>
<h4 id="57elasticsearch-x-pack插件破解">5.7)、elasticsearch x-pack插件破解<a href="#57elasticsearch-x-pack插件破解" class="anchor" aria-hidden="true"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M15 7h3a5 5 0 0 1 5 5 5 5 0 0 1-5 5h-3m-6 0H6a5 5 0 0 1-5-5 5 5 0 0 1 5-5h3"></path><line x1="8" y1="12" x2="16" y2="12"></line></svg></a></h4>
<p>反编译class文件：</p>
<p>在elasticsearch安装目录plugins/x-pack/找到x-pack-5.5.2.jar文件</p>
<p>新建测试目录test</p>
<p><code>$ cd /usr/local/programs/elasticsearch/plugins/x-pack/ &amp;&amp; sudo mkdir test</code></p>
<p>剪切x-pack-5.5.2.jar文件到测试目录test文件夹里面</p>
<p><code>$ sudo mv /usr/local/programs/elasticsearch/plugins/x-pack/x-pack-5.5.2.jar test/</code></p>
<p>切换到test目录，解压jar包</p>
<pre><code>$ cd /usr/local/programs/elasticsearch/plugins/x-pack/test &amp;&amp; jar –xvf x-pack-5.5.2.jar

$ sudo rm -rf /usr/local/programs/elasticsearch/plugins/x-pack/test/x-pack-5.5.2.jar
</code></pre><p>找到文件org.elasticsearch/license/LicenseVerifier.class，并用Luyten反编译，</p>
<p>新建文件LicenseVerifier.java，内容如下：</p>
<pre><code>package org.elasticsearch.license;

import java.nio.*;

import java.util.*;

import java.security.*;

import org.elasticsearch.common.xcontent.*;

import org.apache.lucene.util.*;

import org.elasticsearch.common.io.*;

import java.io.*;

public class LicenseVerifier

{

    public static boolean verifyLicense(final License license, final byte[] encryptedPublicKeyData) {

        return true;

    }

    public static boolean verifyLicense(final License license) {

        return true;

    }

}
</code></pre><p>在当前系统上的任意目录上重新编译LicenseVerifier.java文件</p>
<p><code>$ javac -cp &quot;/usr/local/programs/elasticsearch/lib/elasticsearch-5.2.2.jar:/usr/local/programs/elasticsearch/lib/lucene-core-6.0.1.jar:/usr/local/programs/elasticsearch/plugins/x-pack/x-pack-5.5.2.jar&quot; LicenseVerifier.java</code></p>
<p>此时会生成一个LicenseVerifier.class的文件</p>
<p>替换原来的class文件</p>
<p><code>$ sudo cp LicenseVerifier.class /usr/local/programs/elasticsearch/plugins/x-pack/test/org/elasticsearch/license/</code></p>
<p>重新打包jar包</p>
<p><code>$ cd /usr/local/programs/elasticsearch/plugins/x-pack/test &amp;&amp; jar -cvf x-pack-5.5.2.jar ./*</code></p>
<p>覆盖原来的x-pack的jar包</p>
<p><code>$ sudo mv /usr/local/programs/elasticsearch/plugins/x-pack/test/x-pack-5.5.2.jar /usr/local/programs/elasticsearch/plugins/x-pack</code></p>
<p>获取license文件</p>
<p>获取地址：https://license.elastic.co/registration</p>
<p>将下载下来的license文件重命名为license.json</p>
<p>修改文件内容的两处：</p>
<pre><code>&quot;type&quot;: &quot;platinum&quot;,

&quot;expiry_date_in_millis&quot;: 2524579200999,
</code></pre><p>在更新license文件之前,需要修改elasticsearch配置文件elasticsearch.yml</p>
<p><code>xpack.security.enabled: false</code></p>
<p>导入修改好的license文件</p>
<p><code>$ curl -XPUT -u elastic 'http://192.168.2.6:9200/_xpack/license?acknowledge=true' -H &quot;Content-Type: application/json&quot; -d @license.json</code></p>
<p>生效之后，再开启security，并开启SSL\TLS：</p>
<pre><code>xpack.security.enabled: true

xpack.security.transport.ssl.enabled: true
</code></pre><p>最后重启elasticsearch：</p>
<p>查看License状态：</p>
<p><code>$ curl -XGET -u elastic http://192.168.2.6:9200/_license</code></p>
<h3 id="6kibana安装配置">6)、Kibana安装配置<a href="#6kibana安装配置" class="anchor" aria-hidden="true"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M15 7h3a5 5 0 0 1 5 5 5 5 0 0 1-5 5h-3m-6 0H6a5 5 0 0 1-5-5 5 5 0 0 1 5-5h3"></path><line x1="8" y1="12" x2="16" y2="12"></line></svg></a></h3>
<h4 id="61解压软件包至指定目录">6.1)、解压软件包至指定目录<a href="#61解压软件包至指定目录" class="anchor" aria-hidden="true"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M15 7h3a5 5 0 0 1 5 5 5 5 0 0 1-5 5h-3m-6 0H6a5 5 0 0 1-5-5 5 5 0 0 1 5-5h3"></path><line x1="8" y1="12" x2="16" y2="12"></line></svg></a></h4>
<p><code>$ sudo tar -zxvf kibana-5.5.2-linux-x86_64.tar.gz -C /usr/local/programs/kibana</code></p>
<h4 id="62修改配置文件">6.2)、修改配置文件<a href="#62修改配置文件" class="anchor" aria-hidden="true"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M15 7h3a5 5 0 0 1 5 5 5 5 0 0 1-5 5h-3m-6 0H6a5 5 0 0 1-5-5 5 5 0 0 1 5-5h3"></path><line x1="8" y1="12" x2="16" y2="12"></line></svg></a></h4>
<pre><code>server.port: 5601

server.host: &quot;0.0.0.0&quot;

server.name: &quot;elk-es1&quot;

elasticsearch.url: http://172.31.2.6:9200

kibana.index: &quot;.kibana&quot;

elasticsearch.username: &quot;kibana&quot;

elasticsearch.password: &quot;changeme&quot;

</code></pre><h4 id="63kibana-x-pack插件安装">6.3)、kibana x-pack插件安装<a href="#63kibana-x-pack插件安装" class="anchor" aria-hidden="true"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M15 7h3a5 5 0 0 1 5 5 5 5 0 0 1-5 5h-3m-6 0H6a5 5 0 0 1-5-5 5 5 0 0 1 5-5h3"></path><line x1="8" y1="12" x2="16" y2="12"></line></svg></a></h4>
<pre><code>$ cd /usr/local/programs/kibana

$ bin/kibana-plugin install x-pack

# Update Kibana to use the new password for the built-in kibana user, which you set up along with the other built-in users when you installed X-Pack on Elasticsearch. You must configure the elasticsearch.password setting in the kibana.yml configuration file with the new password for the kibana user

elasticsearch.username: &quot;kibana&quot;

elasticsearch.password: &quot;changeme&quot;

备注： kibana安装选择在从节点的进行安装就可以了，主节点上无需安装！

####################################################################################

### 7)、Elasticsearch+logstash+kibana5.5密码重置

https://www.elastic.co/guide/en/x-pack/5.5/setting-up-authentication.html

elastic：A built-in superuser. See Built-in Roles.

kibana：The user Kibana uses to connect and communicate with Elasticsearch.

logstash_system：The user Logstash uses when storing monitoring information in Elasticsearch.

You must reset the default passwords for all built-in users, and then disable default password support. You can update passwords from the Management &gt; Users UI in Kibana or with the Reset Password API：

PUT _xpack/security/user/elastic/_password

{

  &quot;password&quot;: &quot;elasticpassword&quot;

}

PUT _xpack/security/user/kibana/_password

{

  &quot;password&quot;: &quot;kibanapassword&quot;

}

PUT _xpack/security/user/logstash_system/_password

{

  &quot;password&quot;: &quot;logstashpassword&quot;

}
</code></pre><p>备注： 当密码被更改后，请将kibana配置文件中连接elasticsearch的密码也进行更换</p>
<h3 id="服务安装目录以及配置文件位置说明">服务安装目录以及配置文件位置说明<a href="#服务安装目录以及配置文件位置说明" class="anchor" aria-hidden="true"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M15 7h3a5 5 0 0 1 5 5 5 5 0 0 1-5 5h-3m-6 0H6a5 5 0 0 1-5-5 5 5 0 0 1 5-5h3"></path><line x1="8" y1="12" x2="16" y2="12"></line></svg></a></h3>
<p>kafka安装目录： /usr/local/programs/kafka</p>
<p>kafka配置文件： /usr/local/programs/kafka/config/server.properties</p>
<p>kafka jvm配置文件： /usr/local/programs/kafka/bin/kafka-server-start.sh</p>
<p>kafka monitor安装目录： /usr/local/programs/kafka_monitor</p>
<p>zookeeper安装目录： /usr/local/programs/zookeeper</p>
<p>zookeeper配置文件： /usr/local/programs/zookeeper/conf/zoo.cfg</p>
<p>logstash安装目录： /usr/local/programs/logstash</p>
<p>logstash配置文件： /usr/local/programs/logstash/config/logstash.yml</p>
<p>logstash生产配置文件目录文件存放位置： /usr/local/programs/logstash/config/conf.d   #里面文件为.yml结尾</p>
<p>logstash jvm配置文件： /usr/local/programs/logstash/config/jvm.options</p>
<p>elasticsearch安装目录： /usr/local/programs/elasticsearch</p>
<p>elasticsearch配置文件：/usr/local/programs/elasticsearch/config/elasticsearch.yml</p>
<p>elasticsearch jvm配置文件： /usr/local/programs/elasticsearch/config/jvm.options</p>
<p>kibana安装目录： /usr/local/programs/kibana</p>
<p>kibana 配置文件： /usr/local/programs/kibana/config/kibana.yml</p>
<p>备注：</p>
<p>所有elk服务启动都采用supervisor进程管理的方式维护</p>
<p>ELK中相关服务端口说明</p>
<p>9092： kafka监听的端口</p>
<p>2181： zookeeper提供给client连接的端口</p>
<p>2888： zookeeper集群内部通讯使用端口(Leader监听此端口)，意思是此端口不在集群哪台服务器上监听，就是Leader</p>
<p>3888： zookeeper选举Leader使用的端口</p>
<p>5044： logstash监听端口</p>
<p>5601：kibana监听访问端口</p>
<p>9200：elasticsearch监听访问端口</p>
<p>9300：elasticsearch集群内部通讯端口</p>
<h3 id="elk集群架构常用维护命令">ELK集群架构常用维护命令<a href="#elk集群架构常用维护命令" class="anchor" aria-hidden="true"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M15 7h3a5 5 0 0 1 5 5 5 5 0 0 1-5 5h-3m-6 0H6a5 5 0 0 1-5-5 5 5 0 0 1 5-5h3"></path><line x1="8" y1="12" x2="16" y2="12"></line></svg></a></h3>
<h4 id="1kafka常用操作命令">1)、Kafka常用操作命令<a href="#1kafka常用操作命令" class="anchor" aria-hidden="true"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M15 7h3a5 5 0 0 1 5 5 5 5 0 0 1-5 5h-3m-6 0H6a5 5 0 0 1-5-5 5 5 0 0 1 5-5h3"></path><line x1="8" y1="12" x2="16" y2="12"></line></svg></a></h4>
<p>1、创建kafka topic：</p>
<p><code>$ sudo bin/kafka-topics.sh --zookeeper zoo1.example.com:2181/kafka-cluster --create --topic my-topic --replication-factor 2 --partitions 8</code></p>
<p>备注：partitions指定topic分区数，replication-factor指定topic每个分区的副本数</p>
<p>partitions分区数：控制topic将分片成多少个log；可以显示指定，如果不指定则会使用broker(server.properties)中的num.partitions配置的数量</p>
<p>replication-factor副本：replication-factor控制消息保存在几个broker(服务器)上，一般情况下等于broker的个数</p>
<p>如果没有在创建时显示指定或通过API向一个不存在的topic生产消息时会使用broker(server.properties)中的default.replication.factor配置的数量</p>
<p>For example, increase the number of partitions for a topic named &ldquo;my-topic&rdquo; to 16：</p>
<p><code>$ sudo bin/kafka-topics.sh --zookeeper 172.31.2.2:2181,172.31.2.3:2181 --alter --topic my-topic --partitions 16</code></p>
<p>2、Deleting a Topic：</p>
<p>For example, delete the topic named &ldquo;my-topic&rdquo;：</p>
<p><code>$ sudo bin/kafka-topics.sh --zookeeper 172.31.2.2:2181,172.31.2.3:2181 --delete --topic my-topic</code></p>
<p>3、Listing All Topics in a Cluster</p>
<p><code>$ sudo bin/kafka-topics.sh --zookeeper 172.31.2.2:2181,172.31.2.3:2181 --list</code></p>
<p>4、Describing Topic Details</p>
<p><code>$ sudo bin/kafka-topics.sh --zookeeper 172.31.2.2:2181,172.31.2.3:2181 --describe --topic my-topic</code></p>
<p>5、分区监控指标(查找有问题的分区)</p>
<p>There are two filters used to find partitions that have problems. The &ndash;under-replicated-partitions argument</p>
<p>will show all partitions where one or more of the replicas for the partition are not in-sync with the leader. The &ndash;unavailable-partitions argument shows all partitions without a leader. This is a more serious situation</p>
<p>that means that the partition is currently offline and unavailable for produce or consume clients.</p>
<p><code>$ sudo bin/kafka-topics.sh --zookeeper 172.31.2.2:2181,172.31.2.3:2181 –describe –under-replicated-partitions</code></p>
<p>6、查看topic消费进度</p>
<p>这个会显示出consumer group的offset情况，必须参数为&ndash;group，不指定&ndash;topic，默认为所有topic</p>
<p>Displays the: Consumer Group，Topic，Partitions，Offset，logSize，Lag，Owner for the specified set of Topics and Consumer Group</p>
<p><code>$ sudo bin/kafka-run-class.sh kafka.tools.ConsumerOffsetChecker --group pv</code></p>
<p>7、Describing Configuration Overrides</p>
<p>For example, show all configuration overrides for the topic named &ldquo;my-topic&rdquo;：</p>
<p><code>$ kafka-configs.sh --zookeeper 172.31.2.2:2181,172.31.2.3:2181 --describe --entity-type topics --entity-name my-topic</code></p>
<p>8、Removing Configuration Overrides</p>
<p><code>$ kafka-configs.sh --zookeeper 172.31.2.2:2181,172.31.2.3:2181 --alter --entity-type topics --entity-name my-topic --delete-config retention.ms</code></p>
<h4 id="2zookeeper常用操作命令">2)、Zookeeper常用操作命令<a href="#2zookeeper常用操作命令" class="anchor" aria-hidden="true"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M15 7h3a5 5 0 0 1 5 5 5 5 0 0 1-5 5h-3m-6 0H6a5 5 0 0 1-5-5 5 5 0 0 1 5-5h3"></path><line x1="8" y1="12" x2="16" y2="12"></line></svg></a></h4>
<p>Zookeeper支持某些特定的四字命令字母与其的交互；它们大多是查询的命令，用来获取Zookeeper服务的当前状态及相关信息；用户在客户端可以通过telnet或nc向Zookeeper提交相应的命令</p>
<pre><code>echo stat | nc localhost 2181              # 查看哪个节点被选择作为follower或者leader

echo ruok | nc localhost 2181      # 测试是否启动了该server，若回复imok表示已经启动

echo dump | nc localhost 2181    # 列出未经处理的会话和临时节点

echo kill | nc localhost 2181         # 关掉server

echo conf | nc localhost 2181              # 输出相关服务配置的详细信息

echo cons | nc localhost 2181      # 列出所有连接到服务器的客户端的完全的连接/会话的详细信息

echo envi | nc localhost 2181              # 输出关于服务环境的详细信息(区别于conf命令)

echo reqs | nc localhost 2181             # 列出未经处理的请求

echo wchs | nc localhost 2181      # 列出服务器watch的详细信息

echo wchc | nc localhost 2181      # 通过session列出服务器watch的详细信息，输出与watch相关的会话的列表

echo wchp | nc localhost 2181     # 通过路径列出服务器watch的详细信息；它输出一个与session相关的路径上

</code></pre><p>ZooKeeper命令行工具类似于Linux的shell环境，不过功能肯定不及shell，但是使用它我们可以简单的对ZooKeeper进行访问，数据创建，数据修改等操作</p>
<p>当启动ZooKeeper服务成功之后，输入下述命令，连接到ZooKeeper服务：</p>
<p><code>zkCli.sh -server zkserver: 2181</code></p>
<p>命令行工具的一些简单操作如下：</p>
<p>使用ls命令来查看当前ZooKeeper中所包含的内容</p>
<p>[zk: zkserverIP:2181(CONNECTED) 1] ls /</p>
<p>创建一个新的znode，使用create /zk myData；这个命令创建了一个新的znode节点“zk”以及与它关联的字符串</p>
<p><code>[zk: zkserverIP:2181(CONNECTED) 2] create /zk &quot;myData&quot;</code></p>
<p>我们运行get 命令来确认znode 是否包含我们所创建的字符串：</p>
<p><code>[zk: zkserverIP:2181(CONNECTED) 3] get /zk</code></p>
<p>下面我们通过set 命令来对zk 所关联的字符串进行设置：</p>
<p><code>[zk: zkserverIP:2181(CONNECTED) 4] set /zk &quot;zsl&quot;</code></p>
<p>下面我们将刚才创建的znode 删除：</p>
<p><code>[zk: zkserverIP:2181(CONNECTED) 5] delete /zk</code></p>
<h4 id="3elasticsearch常用操作命令">3)、Elasticsearch常用操作命令<a href="#3elasticsearch常用操作命令" class="anchor" aria-hidden="true"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M15 7h3a5 5 0 0 1 5 5 5 5 0 0 1-5 5h-3m-6 0H6a5 5 0 0 1-5-5 5 5 0 0 1 5-5h3"></path><line x1="8" y1="12" x2="16" y2="12"></line></svg></a></h4>
<p>1、查看索引文件</p>
<p><code>$ curl -XGET &quot;http://elastic:changeme@172.31.2.6:9200/_cat/indices?v&quot;</code></p>
<p>2、打开或关闭指定的索引文件</p>
<p><code>$ curl -XPOST 'http://elastic:changeme@172.31.2.6:9200/.monitoring-es-6-2018.05.21/_open'</code></p>
<p><code>$ curl -XPOST 'http://elastic:changeme@172.31.2.6:9200/.monitoring-es-6-2018.05.21/_close'</code></p>
<p>3、检索索引文件是否存在</p>
<p><code>$ curl --head http://elastic:changeme@172.31.2.6:9200/logstash-oc-nginx-access-2018.06.01</code></p>
<p>4、删除指定的索引</p>
<p><code>$ curl -XDELETE http://elastic:changeme@172.31.2.6:9200/.monitoring-es-6-2018.05.21</code></p>
<p>使用通配符批量删除索引文件：</p>
<p><code>$ curl -XDELETE 'http://elastic:changeme@172.31.2.6:9200/.monitoring-es-6-2018.05.*'</code></p>
<p>5、清空索引缓存</p>
<p><code>$ curl -XPOST 'http://elastic:changeme@172.31.2.6:9200/.monitoring-es-6-2018.05.21/_cache/clear'</code></p>
<p><code>$ curl -XPOST 'http://elastic:changeme@172.31.2.6:9200/.monitoring-es-6-2018.05.21, .monitoring-es-6-2018.05.22/_cache/clear'</code></p>
<p>6、刷新索引数据</p>
<p><code>$ curl -XPOST 'http://elastic:changeme@172.31.2.6:9200/.monitoring-es-6-2018.05.21/_refresh'</code></p>
<p>7、优化索引数据</p>
<p><code>$ curl -XPOST 'http://elastic:changeme@172.31.2.6:9200/.monitoring-es-6-2018.05.21/_optimize'</code></p>
<p>8、信息检索与结果过滤</p>
<p>在Elasticsearch中的RESTful接口方式中，完成信息检索功能的关键词是_search，通过POST的方式发送到</p>
<p>Elasticsearch，其后再跟“?q=查询词”等，其形式表现为：</p>
<p>http://ip address:port/index_name/type_name/_search?q=</p>
<p>可以以<code>curl -XGET 'http://localhost:9200/_search?q=hello+world'</code> 的方式完成简单的检索</p>
<p>输出结果带缩进：http://ip address:9200/index_file_name/type_name/_search?q=field_name:Hello &amp; pretty=true</p>
<p>上述方法是可以在指定的索引文件index_file_name、指定的类型文件type_name中，在指定的字段field_name中，查找包含Hello字符串的结果集</p>
<p>(1)、查询指定索引和指定类型下的信息(指定一个index和一个type名)</p>
<p><code>$ curl -XGET 'elastic:changeme@172.31.2.6:9200/page/pages/_search?q=field_name: Hello&amp;pretty=true'</code></p>
<p>(2)、查询指定索引下所有类型中的信息(指定一个index名,没指定type)</p>
<p><code>$ curl -XGET 'elastic:changeme@172.31.2.6:9200/page/_search?q=field_name:Hello&amp;pretty=true'</code></p>
<p>(3)、查询所有索引中的信息(没指定index和type名)</p>
<p><code>$ curl -XGET 'elastic:changeme@172.31.2.6:9200/_search?q=field_name:Hello&amp;pretty=true'</code></p>
<p>(4)、查询多个索引下所有类型中的信息(指定多个index名,没指定type名)</p>
<p><code>$ curl -XGET 'elastic:changeme@172.31.2.6:9200/page, whale/_search?q=field_name:Hello&amp;pretty=true'</code></p>
<p>(5)、查询多个索引下多个类型中的信息(指定多个index名和多个type名)</p>
<p><code>$ curl -XGET 'elastic:changeme@172.31.2.6:9200/page, whale/pages, log/_search?q=field_name:Hello&amp;pretty=true'</code></p>
<p>在索引过程中,可以控制结果的规模以及从哪个结果开始返回，在请求中可以设置相应的属性，其中：</p>
<p>from：该属性指定了从那个结果开始返回</p>
<p>size：该属性指定了查询的结果集中包含的最大文档数</p>
<p>基本查询：基本查询涉及term查询、terms查询、match查询、match_all查询、query_string查询、prefix查询、range查询、more_like_this查询等</p>
<p>9、elasticsearch集群查看：</p>
<p><code>$ curl -XGET -u elastic &quot;http://172.31.2.6:9200/_cat/nodes?pretty&quot;</code></p>
<p>访问地址</p>
<p>Kibana：http://x.x.x.x:5601</p>
<p>Elasticsearch： <a href="http://x.x.x.x">http://x.x.x.x</a>:9200</p>
<p>Elasticsearch-head：http://x.x.x.x:9100/?auth_user=elastic&amp;auth_password=changeme</p>

			</div>
			<hr class="post-end">
			<footer class="post-info">
				<p>
					<svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-tag meta-icon"><path d="M20.59 13.41l-7.17 7.17a2 2 0 0 1-2.83 0L2 12V2h10l8.59 8.59a2 2 0 0 1 0 2.82z"></path><line x1="7" y1="7" x2="7" y2="7"></line></svg><span class="tag"><a href="http://www.heyuan110.com/tags/elasticsearch">elasticsearch</a></span><span class="tag"><a href="http://www.heyuan110.com/tags/log">log</a></span><span class="tag"><a href="http://www.heyuan110.com/tags/elk">elk</a></span><span class="tag"><a href="http://www.heyuan110.com/tags/kibana">kibana</a></span><span class="tag"><a href="http://www.heyuan110.com/tags/kafaka">kafaka</a></span><span class="tag"><a href="http://www.heyuan110.com/tags/logstash">logstash</a></span>
				</p>
				<p><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-file-text"><path d="M14 2H6a2 2 0 0 0-2 2v16a2 2 0 0 0 2 2h12a2 2 0 0 0 2-2V8z"></path><polyline points="14 2 14 8 20 8"></polyline><line x1="16" y1="13" x2="8" y2="13"></line><line x1="16" y1="17" x2="8" y2="17"></line><polyline points="10 9 9 9 8 9"></polyline></svg>1769 Words</p>
				<p><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-calendar"><rect x="3" y="4" width="18" height="18" rx="2" ry="2"></rect><line x1="16" y1="2" x2="16" y2="6"></line><line x1="8" y1="2" x2="8" y2="6"></line><line x1="3" y1="10" x2="21" y2="10"></line></svg>2018-09-12 04:02 &#43;0800</p>
			</footer>
		</article>
		<aside id="toc" class="show-toc">
			<div class="toc-title">Table of Contents</div>
			<nav id="TableOfContents">
  <ul>
    <li><a href="#架构">架构</a></li>
    <li><a href="#资源列表">资源列表</a></li>
    <li><a href="#硬件配置">硬件配置</a></li>
    <li><a href="#部署前的准备工作">部署前的准备工作</a>
      <ul>
        <li><a href="#1主机名设置">1)、主机名设置</a></li>
        <li><a href="#2系统优化">2)、系统优化</a></li>
        <li><a href="#3软件包准备">3)、软件包准备</a></li>
        <li><a href="#4安装配置supervisor">4)、安装配置supervisor</a></li>
      </ul>
    </li>
    <li><a href="#部署过程">部署过程</a>
      <ul>
        <li><a href="#1jdk安装">1)、jdk安装</a></li>
        <li><a href="#2zookeeper安装配置">2)、zookeeper安装配置</a></li>
        <li><a href="#3kafka集群安装配置">3)、kafka集群安装配置</a></li>
        <li><a href="#4logstash安装配置">4)、logstash安装配置</a></li>
        <li><a href="#5elasticsearch集群安装配置">5)、Elasticsearch集群安装配置</a></li>
      </ul>
    </li>
    <li><a href="#gc-configuration">GC configuration</a>
      <ul>
        <li></li>
        <li><a href="#6kibana安装配置">6)、Kibana安装配置</a></li>
        <li><a href="#服务安装目录以及配置文件位置说明">服务安装目录以及配置文件位置说明</a></li>
        <li><a href="#elk集群架构常用维护命令">ELK集群架构常用维护命令</a></li>
      </ul>
    </li>
  </ul>
</nav>
		</aside>
		<div class="post-nav thin">
			<a class="next-post" href="http://www.heyuan110.com/posts/elasticsearch/2018-09-12-log-ekk/">
				<span class="post-nav-label"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-arrow-left"><line x1="19" y1="12" x2="5" y2="12"></line><polyline points="12 19 5 12 12 5"></polyline></svg>&nbsp;Newer</span><br><span>搭建EKK日志收集分析系统</span>
			</a>
			<a class="prev-post" href="http://www.heyuan110.com/posts/datawarehouse/2018-08-09-dw-redshift/">
				<span class="post-nav-label">Older&nbsp;<svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-arrow-right"><line x1="5" y1="12" x2="19" y2="12"></line><polyline points="12 5 19 12 12 19"></polyline></svg></span><br><span>数据仓库Amazon Redshift</span>
			</a>
		</div>
		<div id="comments" class="thin">
						<script src="https://utteranc.es/client.js"
							repo="heyuan110/heyuan110.github.com"
							issue-term="pathname"
							theme="github-light"
							crossorigin="anonymous"
							async>
			</script>


		</div>
	</main>

	<footer id="site-footer" class="section-inner thin animated fadeIn faster">
		<p>&copy; 2015 - 2020 <a href="http://www.heyuan110.com">Bruce&#39;s Blog</a> &#183; 版权所有</p>
		<p>
			Made with <a href="https://gohugo.io/" target="_blank" rel="noopener">Hugo</a> &#183; Theme <a href="https://github.com/Track3/hermit" target="_blank" rel="noopener">Hermit</a> &#183; <a href="http://www.heyuan110.com/post/index.xml" target="_blank" title="rss"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-rss"><path d="M4 11a9 9 0 0 1 9 9"></path><path d="M4 4a16 16 0 0 1 16 16"></path><circle cx="5" cy="19" r="1"></circle></svg></a>
		</p>
	</footer>


	<script src="http://www.heyuan110.com/js/main.min.784417f5847151f848c339cf0acb13a06cbb648b1483435a28ed4556c4ead69b.js"></script>

</body>

</html>
