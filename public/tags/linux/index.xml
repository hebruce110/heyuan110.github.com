<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>linux on Bruce&#39;s Blog</title>
    <link>http://www.heyuan110.com/tags/linux/</link>
    <description>Recent content in linux on Bruce&#39;s Blog</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>zh-hans</language>
    <copyright>This work is licensed under a Creative Commons Attribution-NonCommercial 4.0 International License.</copyright>
    <lastBuildDate>Sat, 04 Jul 2020 00:16:54 +0000</lastBuildDate><atom:link href="http://www.heyuan110.com/tags/linux/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>AWS CLI常用命令</title>
      <link>http://www.heyuan110.com/posts/linux/2020-07-04-aws-cli/</link>
      <pubDate>Sat, 04 Jul 2020 00:16:54 +0000</pubDate>
      
      <guid>http://www.heyuan110.com/posts/linux/2020-07-04-aws-cli/</guid>
      <description>AWS CLI常用命令
S3 官方参考https://docs.amazonaws.cn/cli/latest/userguide/cli-services-s3-commands.html
##查看默认的bucket aws s3 ls ##查看默认环境的abert-test内容 aws s3 ls s3://abert-test ##查看目录大小,列出每个文件大小 aws s3 ls --summarize --human-readable --recursive s3://bucket-name ##上传本地文件 aws s3 cp bstest.txt s3://abert-test ##复制文件 aws s3 cp s3://mybucket/test.txt s3://mybucket/test2.txt ##递归拷贝 aws s3 cp s3://mybucket . --recursive ##排除拷贝 aws s3 cp myDir s3://mybucket/ --recursive --exclude &amp;#34;*.jpg&amp;#34; ##拷贝并添加ACL权限控制 aws s3 cp s3://mybucket/test.txt s3://mybucket/test2.txt --acl public-read-write ## 移动 ## 将桶testbucket下面所有文件移动到testbucket2 aws s3 mv s3://testbucket/ s3//testbucket2/ --recursive #rm ##删除对象 aws s3 rm s3://mybucket/test.</description>
    </item>
    
    <item>
      <title>Nginx报No route to host错误</title>
      <link>http://www.heyuan110.com/posts/linux/nginx/nginx-error-noroutetohost/</link>
      <pubDate>Fri, 03 Jul 2020 13:19:44 +0800</pubDate>
      
      <guid>http://www.heyuan110.com/posts/linux/nginx/nginx-error-noroutetohost/</guid>
      <description>最近调整了后端站点架构为：user-------&amp;gt;nginx proxy server--------》internal host ------(cname)----》elb host，跑一段时间后经常出现诡异的情况，访问时不时会挂掉，只要重启nginx proxy集群里所有机器的nginx就能恢复， 经过检查发现集群里部分机器往后转发时报如下错误:
2020/06/08 16:31:20 [error] 13741#0: *116374839 connect() failed (113: No route to host) while connecting to upstream, client: 2607:xxxx:969:f1f0:c3d:70ec:178f:fd24, server: localhost, request: &amp;#34;POST /v1.4/source HTTP/1.1&amp;#34;, upstream: &amp;#34;http://172.31.xx.xx:80/v1.4/source&amp;#34;, host: &amp;#34;api.xxxx.com&amp;#34; 网上搜索找到的资料都讲防火墙原因，经过仔细排查排除了。通过仔细分析出现异常时的监控发现，在异常时间点aws elb的ip发生了变化，于是将症状和云服务的SA沟通，他说AWS ELB的IP是会变化的（之前以为是固定的）， 建议nginx上的upstream需要动态去刷新，并建议使用nginx的jdomain模块来做动态解析，参考地址https://www.nginx.com/resources/wiki/modules/domain_resolve/，我们加上这个模块后重新部署nginx问题就没再出现。
其实原因很简单，nginx proxy指向域名时，nginx会缓存域名解析到的ip，如果域名对应的ip改变了而proxy nginx又没刷新缓存的ip，后面流量继续往旧ip转发，就会报错了，增加的动态解析模块指定dns和时间间隔去获取最新的ip并更新到缓存里，这样就保证了域名指向的ip变更proxy nginx能及时更新缓存ip。</description>
    </item>
    
    <item>
      <title>Curl命令</title>
      <link>http://www.heyuan110.com/posts/linux/2020-06-29-curl/</link>
      <pubDate>Mon, 29 Jun 2020 20:36:04 +0000</pubDate>
      
      <guid>http://www.heyuan110.com/posts/linux/2020-06-29-curl/</guid>
      <description>curl是linux下必备神器，例如：
指定IP访问URL，HTTP和HTTPS的区别：
curl -vosa &amp;quot;http://hikpai.hikvision.com/dashboard/workplace&amp;quot; -x 125.77.145.14:80
curl -vosa &amp;quot;https://125.77.145.14/dashboard/workplace&amp;quot; -H &amp;quot;host:hikpai.hikvision.com&amp;quot; -k
curl -vo /dev/null &amp;quot;https://125.77.145.14/dashboard/workplace&amp;quot; -H &amp;quot;host:hikpai.hikvision.com&amp;quot; -k
在以下选项中，(H) 表示仅适用 HTTP/HTTPS ，(F) 表示仅适用于 FTP
更多相关参数解释：
--anyauth 选择 &amp;#34;any&amp;#34; 认证方法 (H) -a, --append 添加要上传的文件 (F/SFTP) --basic 使用HTTP基础认证（Basic Authentication）(H) --cacert FILE CA 证书，用于每次请求认证 (SSL) --capath DIR CA 证书目录 (SSL) -E, --cert CERT[:PASSWD] 客户端证书文件及密码 (SSL) --cert-type TYPE 证书文件类型 (DER/PEM/ENG) (SSL) --ciphers LIST SSL 秘钥 (SSL) --compressed 请求压缩 (使用 deflate 或 gzip) -K, --config FILE 指定配置文件 --connect-timeout SECONDS 连接超时设置 -C, --continue-at OFFSET 断点续转 -b, --cookie STRING/FILE Cookies字符串或读取Cookies的文件位置 (H) -c, --cookie-jar FILE 操作结束后，要写入 Cookies 的文件位置 (H) --create-dirs 创建必要的本地目录层次结构 --crlf 在上传时将 LF 转写为 CRLF --crlfile FILE 从指定的文件获得PEM格式CRL列表 -d, --data DATA HTTP POST 数据 (H) --data-ascii DATA ASCII 编码 HTTP POST 数据 (H) --data-binary DATA binary 编码 HTTP POST 数据 (H) --data-urlencode DATA url 编码 HTTP POST 数据 (H) --delegation STRING GSS-API 委托权限 --digest 使用数字身份验证 (H) --disable-eprt 禁止使用 EPRT 或 LPRT (F) --disable-epsv 禁止使用 EPSV (F) -D, --dump-header FILE 将头信息写入指定的文件 --egd-file FILE 为随机数据设置EGD socket路径(SSL) --engine ENGINGE 加密引擎 (SSL).</description>
    </item>
    
    <item>
      <title>Traceroute命令</title>
      <link>http://www.heyuan110.com/posts/linux/2020-06-28-traceroute/</link>
      <pubDate>Sun, 28 Jun 2020 12:12:04 +0000</pubDate>
      
      <guid>http://www.heyuan110.com/posts/linux/2020-06-28-traceroute/</guid>
      <description>1. 简介 通过traceroute我们可以知道信息从你的计算机到互联网另一端的主机是走的什么路径。当然每次数据包由某一同样的出发点（source）到达某一同样的目的地(destination)走的路径可能会不一样，但基本上来说大部分时候所走的路由是相同的。linux系统中，我们称之为traceroute,在MS Windows中为tracert。 traceroute通过发送小的数据包到目的设备直到其返回，来测量其需要多长时间。一条路径上的每个设备traceroute要测3次。输出结果中包括每次测试的时间(ms)和设备的名称（如有的话）及其IP地址。
在大多数情况下，我们会在linux主机系统下，直接执行命令行：
traceroute hostname
而在Windows系统下是执行tracert的命令：
tracert hostname
2. 命令格式 traceroute[参数][主机]
3. 命令功能 traceroute指令让你追踪网络数据包的路由途径，预设数据包大小是40Bytes，用户可另行设置。
具体参数格式：traceroute [-dFlnrvx][-f&amp;lt;存活数值&amp;gt;][-g&amp;lt;网关&amp;gt;&amp;hellip;][-i&amp;lt;网络界面&amp;gt;][-m&amp;lt;存活数值&amp;gt;][-p&amp;lt;通信端口&amp;gt;][-s&amp;lt;来源地址&amp;gt;][-t&amp;lt;服务类型&amp;gt;][-w&amp;lt;超时秒数&amp;gt;][主机名称或IP地址][数据包大小]
4. 命令参数 -d 使用Socket层级的排错功能。
-f 设置第一个检测数据包的存活数值TTL的大小。
-F 设置勿离断位。
-g 设置来源路由网关，最多可设置8个。
-i 使用指定的网络界面送出数据包。
-I 使用ICMP回应取代UDP资料信息。
-m 设置检测数据包的最大存活数值TTL的大小。
-n 直接使用IP地址而非主机名称。
-p 设置UDP传输协议的通信端口。
-r 忽略普通的Routing Table，直接将数据包送到远端主机上。
-s 设置本地主机送出数据包的IP地址。
-t 设置检测数据包的TOS数值。
-v 详细显示指令的执行过程。
-w 设置等待远端主机回报的时间。
-x 开启或关闭数据包的正确性检验。
5. 工作原理 Traceroute最简单的基本用法是：traceroute hostname
Traceroute程序的设计是利用ICMP及IP header的TTL（Time To Live）栏位（field）。首先，traceroute送出一个TTL是1的IP datagram（其实，每次送出的为3个40字节的包，包括源地址，目的地址和包发出的时间标签）到目的地，当路径上的第一个路由器（router）收到这个datagram时，它将TTL减1。此时，TTL变为0了，所以该路由器会将此datagram丢掉，并送回一个「ICMP time exceeded」消息（包括发IP包的源地址，IP包的所有内容及路由器的IP地址），traceroute 收到这个消息后，便知道这个路由器存在于这个路径上，接着traceroute 再送出另一个TTL是2 的datagram，发现第2 个路由器&amp;hellip;&amp;hellip; traceroute 每次将送出的datagram的TTL 加1来发现另一个路由器，这个重复的动作一直持续到某个datagram 抵达目的地。当datagram到达目的地后，该主机并不会送回ICMP time exceeded消息，因为它已是目的地了，那么traceroute如何得知目的地到达了呢？</description>
    </item>
    
    <item>
      <title>Linux(MacOS)命令笔记</title>
      <link>http://www.heyuan110.com/posts/linux/2020-03-19-linux-mac-commands/</link>
      <pubDate>Thu, 19 Mar 2020 10:55:52 +0000</pubDate>
      
      <guid>http://www.heyuan110.com/posts/linux/2020-03-19-linux-mac-commands/</guid>
      <description>&lt;p&gt;linux中许多常用命令是必须掌握的，很多用过没有记录下来很快就忘记，再次使用又到处搜索，本文主要列出我日常使用过的一些命令，会持续更新。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Docker常用命令</title>
      <link>http://www.heyuan110.com/posts/docker/2019-11-14-docker-commands/</link>
      <pubDate>Thu, 14 Nov 2019 20:37:13 +0000</pubDate>
      
      <guid>http://www.heyuan110.com/posts/docker/2019-11-14-docker-commands/</guid>
      <description>Docker常用命令记录
1. 启动、重启或停止docker服务 启动： service docker start
停止：service docker stop
重启：service docker restart
2.镜像(images) 获取镜像 docker pull [OPTIONS] NAME[:TAG|@DIGEST]
例如：docker pull ubuntu:16.04
列出镜像 查看所有镜像: docker images或docker image ls, 显示摘要docker images --digests 查看特定镜像:docker image ls xxxx或docker image xxxx 查看镜像、容器、数据卷所占用的空间:docker system df 列出虚悬镜像（仓库名和标签名为）:docker image ls -f dangling=true,清楚此类镜像docker image prune 删除镜像 命令docker image rm [OPTIONS] IMAGE [IMAGE...] 或 docker rmi -f xxxx 例如：
root@ubuntu:~# docker image ls redis REPOSITORY TAG IMAGE ID CREATED SIZE redis latest ce25c7293564 5 days ago 95MB 根据完整ID删除：docker image rm 578c3e61a98c 根据短ID删除：docker image rm 578c3 根据镜像名删除：docker image rm redis docker image ls配合删除：删除所有镜像docker image rm $(docker image ls -q),删除所有仓库名为redis的镜像docker image rm $(docker image ls -q redis) 删除所有未打 dangling 标签的镜像docker rmi $(docker images -q -f dangling=true) docker ps -a | grep &amp;ldquo;Exited&amp;rdquo; | awk &amp;lsquo;{print $1 }&amp;rsquo;|xargs docker stop docker ps -a | grep &amp;ldquo;Exited&amp;rdquo; | awk &amp;lsquo;{print $1 }&amp;rsquo;|xargs docker rm docker images|grep none|awk &amp;lsquo;{print $3 }&amp;rsquo;|xargs docker rmi</description>
    </item>
    
    <item>
      <title>Nexus3构建Docker私服</title>
      <link>http://www.heyuan110.com/posts/docker/2019-06-12-next3-dockerhub/</link>
      <pubDate>Wed, 12 Jun 2019 20:50:36 +0000</pubDate>
      
      <guid>http://www.heyuan110.com/posts/docker/2019-06-12-next3-dockerhub/</guid>
      <description>Nexus是有名的Maven仓库管理器。如果你使用Maven，你可以从Maven中央仓库下载所需要的构件（artifact），但这通常不是一个好的做法，你应该在本地架设一个Maven仓库服务器，在代理远程仓库的同时维护本地仓库，以节省带宽和时间，Nexus就可以满足这样的需要。此外，他还提供了强大的仓库管理功能，构件搜索功能，它基于REST，友好的UI是一个extjs的REST客户端，它占用较少的内存，基于简单文件系统而非数据库。这些优点使其日趋成为最流行的Maven仓库管理器。除此之外，最新Nexus3还可以管理多种格式的镜像，如下：
1.环境 系统：ubuntu16.04 docker：18.02.0-ce
2.获取nexus3镜像 docker pull sonatype/nexus3
3.启动镜像 docker run -id --privileged=true --name=nexus3 --restart=always -p 9500:8081 -p 9501:9501 -p 9502:9502 -p 9503:9503 -v /usr/local/programs/nexus3/nexus-data:/nexus-data sonatype/nexus3:latest 端口(注意映射了多个端口)：
9500: nexus3网页端 9501：docker(hosted)私有仓库，可以pull和push 9502：docker(proxy)代理远程仓，只能pull 9503：docker(group)私有仓库和代理的组，只能pull 运维人员维护镜像试用9501端口，项目pull镜像使用9503端口，全部可匿名pull。
数据：在宿主机创建目录/usr/local/programs/nexus3/nexus-data，/nexus-data为docker容器数据存储目录。所以-v设置映射关系后数据将会存到宿主机/usr/local/programs/nexus3/nexus-data
4.配置私有仓库 访问http://localhost:9500默认账号admin/admin123
几种repository的类型
hosted，本地仓库，自己创建的镜像上传到这一类型的仓库。 proxy，代理仓库，它们被用来代理远程的公共仓库，如dockerhub官方仓库。 group，仓库组，用来合并多个hosted/proxy仓库，当你的项目希望在多个repository使用资源时就不需要多次引用了，只需要引用一个group即可。 创建仓库前先创建对应的blob stores，在创建仓库时选择对应的blob，创建group组时调整好优先级，一般是host高于proxy。
注意：创建仓库时如果勾选匿名可pull项，需找到security-&amp;gt;realms页面(http://localhost:9500/#admin/security/realms)，将docker bearer token realm项添加到右边激活，否则匿名docker pull会报错无权限.
5. 用户侧docker添加私有仓 mac和win 打开docker的设置，选择daemon，在insecure registries里添加
http://localhost:9503 如果是运维人员，要push镜像，再添加一条 http://localhost:9501
重启docker。
ubuntu 命令vi /etc/docker/daemon.json，插入下面内容:
{ &amp;#34;insecure-registries&amp;#34;: [ &amp;#34;http://localhost:9501&amp;#34;, &amp;#34;http://localhost:9503&amp;#34; ] } 执行sudo service docker restart重启docker。</description>
    </item>
    
    <item>
      <title>Docker学习笔记</title>
      <link>http://www.heyuan110.com/posts/docker/2019-05-13-learn-docker/</link>
      <pubDate>Mon, 13 May 2019 20:33:33 +0000</pubDate>
      
      <guid>http://www.heyuan110.com/posts/docker/2019-05-13-learn-docker/</guid>
      <description>Docker 是一个开源的应用容器引擎，基于 Go 语言 并遵从Apache2.0协议开源。Docker 可以让开发者打包他们的应用以及依赖包到一个轻量级、可移植的容器中，然后发布到任何流行的 Linux 机器上，也可以实现虚拟化。
1.Docker 包括三个基本概念 镜像(Image)
容器(Container)
仓库(Repository)
2.镜像(Image) Docker 镜像是一个特殊的文件系统，除了提供容器运行时所需的程序、库、资 源、配置等文件外，还包含了一些为运行时准备的一些配置参数(如匿名卷、环境 变量、用户等)。镜像不包含任何动态数据，其内容在构建之后也不会被改变。
镜像并非是像一个 ISO 那样的打包文件，镜像只是一个虚拟的概念，其 实际体现并非由一个文件组成，而是由一组文件系统组成，或者说，由多层文件系 统联合组成。
镜像构建时，会一层层构建，前一层是后一层的基础。每一层构建完就不会再发生改变，后一层上的任何改变只发生在自己这一层。在构建镜像的时候，需要额外小心，每一层尽量只包含该层需要添加的东西，任何额外的东西应该在该层构建结束前清理掉。
3.Docker 容器 镜像(Image)和容器(Container)的关系，就像是面向对象程序设计中的类和实例一样，镜像是静态的定义，容器是镜像运行时的实体。容器可以被 创建、启动、停止、删除、暂停等。
容器也是分层存储。每一个容器运行时，是以镜像为基础层，在其上创建一个当前容器的存储层，我们可以称这个为容器运行时读写而准备的存储层为容器存储层。
容器存储层的生存周期和容器一样，容器消亡时，容器存储层也随之消亡。因此，任何保存于容器存储层的信息都会随容器删除而丢失。容器不应该向其存储层内写入任何数据，容器存储 层要保持无状态化。所有的文件写入操作，都应该使用 数据卷(Volume)、或者 绑定宿主目录，在这些位置的读写会跳过容器存储层，直接对宿主(或网络存储)发 生读写，其性能和稳定性更高。
4.Docker Registry 镜像构建完成后，可以很容易的在当前宿主上运行，但是，如果需要在其它服务器 上使用这个镜像，我们就需要一个集中的存储、分发镜像的服务，Docker Registry 就是这样的服务。 一个 Docker Registry 中可以包含多个仓库(Repository);每个仓库可以包含多 个标签(Tag);每个标签对应一个镜像。
5. Docker commit docker commit 的语法格式为:
docker commit [选项] &amp;lt;容器ID或容器名&amp;gt; [&amp;lt;仓库名&amp;gt;[:&amp;lt;标签&amp;gt;]] 例如：
$ docker commit \ --author &amp;#34;Tao Wang &amp;lt;twang2218@gmail.com&amp;gt;&amp;#34; \ --message &amp;#34;修改了默认网页&amp;#34; \ webserver \ nginx:v2 sha256:07e33465974800ce65751acc279adc6ed2dc5ed4e0838f8b86f0c87aa 1795214 docker commit会让制作的image越来越臃肿，不方便追溯，所以一般不用来制作镜像。commit命令除了学习之外，还有一些特殊的应用场合，比如被入侵后保 存现场等。但是，不要使用 docker commit 定制镜像，定制行为应该使用Dockerfile 来完成</description>
    </item>
    
    <item>
      <title>Shell脚本中$符开头变量解释</title>
      <link>http://www.heyuan110.com/posts/linux/2019-05-13-linux-shell-vars/</link>
      <pubDate>Mon, 13 May 2019 20:16:54 +0000</pubDate>
      
      <guid>http://www.heyuan110.com/posts/linux/2019-05-13-linux-shell-vars/</guid>
      <description>shell脚本中经常会看到$开头的特殊变量，那怎么理解它们呢？
变量 $$ Shell本身的PID（ProcessID）
$! Shell最后运行的后台Process的PID
$? 最后运行的命令的结束代码（返回值）
$- 使用Set命令设定的Flag一览
$* 所有参数列表。如&amp;quot;$*&amp;ldquo;用「&amp;quot;」括起来的情况、以&amp;rdquo;$1 $2 … $n&amp;quot;的形式输出所有参数。
$@ 所有参数列表。如&amp;quot;$@&amp;ldquo;用「&amp;quot;」括起来的情况、以&amp;rdquo;$1&amp;quot; &amp;ldquo;$2&amp;rdquo; … &amp;ldquo;$n&amp;rdquo; 的形式输出所有参数。
$# 添加到Shell的参数个数
$0 Shell本身的文件名
$1～$n 添加到Shell的各参数值。$1是第1参数、$2是第2参数…。
示例 1 #!/bin/bash 2 # 3 printf &amp;#34;The complete list is %s\n&amp;#34; &amp;#34;$$&amp;#34; 4 printf &amp;#34;The complete list is %s\n&amp;#34; &amp;#34;$!&amp;#34; 5 printf &amp;#34;The complete list is %s\n&amp;#34; &amp;#34;$?&amp;#34; 6 printf &amp;#34;The complete list is %s\n&amp;#34; &amp;#34;$*&amp;#34; 7 printf &amp;#34;The complete list is %s\n&amp;#34; &amp;#34;$@&amp;#34; 8 printf &amp;#34;The complete list is %s\n&amp;#34; &amp;#34;$#&amp;#34; 9 printf &amp;#34;The complete list is %s\n&amp;#34; &amp;#34;$0&amp;#34; 10 printf &amp;#34;The complete list is %s\n&amp;#34; &amp;#34;$1&amp;#34; 11 printf &amp;#34;The complete list is %s\n&amp;#34; &amp;#34;$2 结果 [Aric@localhost ~]$ bash params.</description>
    </item>
    
    <item>
      <title>Ubuntu16.04环境Jira和Confluence搭建</title>
      <link>http://www.heyuan110.com/posts/linux/2019-04-15-jira-confluence-install/</link>
      <pubDate>Mon, 15 Apr 2019 13:53:32 +0000</pubDate>
      
      <guid>http://www.heyuan110.com/posts/linux/2019-04-15-jira-confluence-install/</guid>
      <description>&lt;p&gt;jira和confluence都是Atlassian公司产品。jira是项目与事务跟踪工具，可以完成项目执行管理、敏捷开发管理、体系流程管理、产品Bug跟踪、提案跟踪、需求管理、客户服务等工作。confluence是一个专业的企业知识管理与协同软件，可以用于构建企业wiki，通过它可以实现团队成员之间的协作和知识共享。&lt;/p&gt;</description>
    </item>
    
  </channel>
</rss>
